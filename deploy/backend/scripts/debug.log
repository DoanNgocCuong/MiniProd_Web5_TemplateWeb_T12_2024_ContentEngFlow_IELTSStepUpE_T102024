2024-11-14 12:39:58,356 - __main__ - DEBUG - OpenAI API key loaded: ********************************************************************************************************************************************************************
2024-11-14 12:39:58,356 - __main__ - DEBUG - Upload folder path: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\uploads
2024-11-14 12:39:58,356 - __main__ - DEBUG - Output folder path: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output
2024-11-14 12:39:58,356 - __main__ - INFO - Starting main process
2024-11-14 12:39:58,356 - __main__ - INFO - Starting initial data processing
2024-11-14 12:39:58,731 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-11-14 12:39:58,732 - httpx - DEBUG - load_verify_locations cafile='C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\certifi\\cacert.pem'
2024-11-14 12:39:59,471 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-14 12:39:59,471 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-11-14 12:39:59,548 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001A2E48A4DD0>
2024-11-14 12:39:59,548 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A2E483CC50> server_hostname='api.openai.com' timeout=5.0
2024-11-14 12:39:59,584 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001A2E45B20F0>
2024-11-14 12:39:59,584 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-14 12:39:59,584 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-14 12:39:59,584 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-14 12:39:59,585 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-14 12:39:59,585 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-14 12:40:07,486 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 14 Nov 2024 05:40:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'step-up-ognepk'), (b'openai-processing-ms', b'7279'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'448148'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'246ms'), (b'x-request-id', b'req_5de362015eaa62d52e341fa141bc0c32'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=CDu1bZVHnsx3EatyHTAIKV1LDgcYkS0SXSO2co2q7dc-1731562803-1.0.1.1-KF4rPiXpEUzWLnIJWq7OxjPl6U_geBfogMQTu7aciPMea6bV9_smctfE3uRq73kKqBYmwNYpHSjmTES_s1JdAw; path=/; expires=Thu, 14-Nov-24 06:10:03 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=W7FKn4MIFZBGcMHlpNfzKhuqxIZGQjovUOmzKYxFKys-1731562803376-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e24a9efeecf097c-HKG'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-14 12:40:07,487 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-14 12:40:07,487 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-14 12:40:07,488 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-14 12:40:07,488 - httpcore.http11 - DEBUG - response_closed.started
2024-11-14 12:40:07,488 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-14 12:40:07,488 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 14 Nov 2024 05:40:03 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'step-up-ognepk'), ('openai-processing-ms', '7279'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '500'), ('x-ratelimit-limit-tokens', '450000'), ('x-ratelimit-remaining-requests', '499'), ('x-ratelimit-remaining-tokens', '448148'), ('x-ratelimit-reset-requests', '120ms'), ('x-ratelimit-reset-tokens', '246ms'), ('x-request-id', 'req_5de362015eaa62d52e341fa141bc0c32'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=CDu1bZVHnsx3EatyHTAIKV1LDgcYkS0SXSO2co2q7dc-1731562803-1.0.1.1-KF4rPiXpEUzWLnIJWq7OxjPl6U_geBfogMQTu7aciPMea6bV9_smctfE3uRq73kKqBYmwNYpHSjmTES_s1JdAw; path=/; expires=Thu, 14-Nov-24 06:10:03 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=W7FKn4MIFZBGcMHlpNfzKhuqxIZGQjovUOmzKYxFKys-1731562803376-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8e24a9efeecf097c-HKG'), ('content-encoding', 'br'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-11-14 12:40:07,488 - openai._base_client - DEBUG - request_id: req_5de362015eaa62d52e341fa141bc0c32
2024-11-14 12:40:07,494 - __main__ - DEBUG - Order 1, Input: 'Topic: talk about your family - Family size and type
Given vocabulary: Nuclear family
Situation: Sarah and Tom, neighbors, at a community park', Response received in 8.76s
2024-11-14 12:40:07,494 - __main__ - DEBUG - Processed row - Order: 1
2024-11-14 12:40:07,501 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-14 12:40:07,502 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-14 12:40:07,502 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-14 12:40:07,502 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-14 12:40:07,503 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-14 12:40:07,503 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-14 12:40:18,830 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 14 Nov 2024 05:40:14 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'step-up-ognepk'), (b'openai-processing-ms', b'11005'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'448146'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'247ms'), (b'x-request-id', b'req_7a5a1ac61a5e87ac11c189ace7105b31'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e24aa216d83097c-HKG'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-14 12:40:18,831 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-14 12:40:18,831 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-14 12:40:18,831 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-14 12:40:18,831 - httpcore.http11 - DEBUG - response_closed.started
2024-11-14 12:40:18,832 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-14 12:40:18,832 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 14 Nov 2024 05:40:14 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'step-up-ognepk', 'openai-processing-ms': '11005', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '450000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '448146', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '247ms', 'x-request-id': 'req_7a5a1ac61a5e87ac11c189ace7105b31', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8e24aa216d83097c-HKG', 'content-encoding': 'br', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-14 12:40:18,832 - openai._base_client - DEBUG - request_id: req_7a5a1ac61a5e87ac11c189ace7105b31
2024-11-14 12:40:18,833 - __main__ - DEBUG - Order 2, Input: 'Topic: talk about your family - Family size and type
Given vocabulary: Generational family
Situation: Aubrey and Isaac, engineers, at a construction site', Response received in 11.34s
2024-11-14 12:40:18,833 - __main__ - DEBUG - Processed row - Order: 2
2024-11-14 12:40:18,947 - __main__ - INFO - Output saved to D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output.xlsx
2024-11-14 12:40:18,947 - __main__ - INFO - Starting story data processing
2024-11-14 12:40:18,968 - __main__ - DEBUG - Processing story data for order 1
2024-11-14 12:40:18,968 - __main__ - DEBUG - Processing story data for order 2
2024-11-14 12:40:19,031 - __main__ - INFO - Story data processing complete, saved to D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story.xlsx
2024-11-14 12:40:19,032 - __main__ - INFO - Starting audio generation
2024-11-14 12:40:19,045 - __main__ - DEBUG - Generating audio for order 1
2024-11-14 12:40:19,046 - __main__ - DEBUG - Sending TTS request for order 1, role female_1
2024-11-14 12:40:19,050 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 12:40:19,061 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 12:40:20,500 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 178254
2024-11-14 12:40:20,517 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\1\female_1.wav
2024-11-14 12:40:20,518 - __main__ - DEBUG - Sending TTS request for order 1, role male_1
2024-11-14 12:40:20,519 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 12:40:20,529 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 12:40:21,751 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 191566
2024-11-14 12:40:21,767 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\1\male_1.wav
2024-11-14 12:40:21,767 - __main__ - DEBUG - Sending TTS request for order 1, role female_2
2024-11-14 12:40:21,769 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 12:40:21,778 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 12:40:23,346 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 276046
2024-11-14 12:40:23,368 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\1\female_2.wav
2024-11-14 12:40:23,368 - __main__ - DEBUG - Sending TTS request for order 1, role male_2
2024-11-14 12:40:23,369 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 12:40:23,378 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 12:40:25,023 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 222798
2024-11-14 12:40:25,046 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\1\male_2.wav
2024-11-14 12:40:25,047 - __main__ - DEBUG - Generating audio for order 2
2024-11-14 12:40:25,047 - __main__ - DEBUG - Sending TTS request for order 2, role female_1
2024-11-14 12:40:25,048 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 12:40:25,059 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 12:40:26,155 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 171598
2024-11-14 12:40:26,170 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\2\female_1.wav
2024-11-14 12:40:26,171 - __main__ - DEBUG - Sending TTS request for order 2, role male_1
2024-11-14 12:40:26,172 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 12:40:26,181 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 12:40:27,350 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 184910
2024-11-14 12:40:27,367 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\2\male_1.wav
2024-11-14 12:40:27,368 - __main__ - DEBUG - Sending TTS request for order 2, role female_2
2024-11-14 12:40:27,369 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 12:40:27,382 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 12:40:29,164 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 289358
2024-11-14 12:40:29,182 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\2\female_2.wav
2024-11-14 12:40:29,182 - __main__ - DEBUG - Sending TTS request for order 2, role male_2
2024-11-14 12:40:29,183 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 12:40:29,193 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 12:40:30,772 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 254030
2024-11-14 12:40:30,795 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\2\male_2.wav
2024-11-14 12:40:30,795 - __main__ - INFO - Audio generation complete
2024-11-14 12:40:30,795 - __main__ - INFO - Processing complete. Final output saved to: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story.xlsx
2024-11-14 12:40:30,874 - httpcore.connection - DEBUG - close.started
2024-11-14 12:40:30,875 - httpcore.connection - DEBUG - close.complete
2024-11-14 14:44:31,782 - __main__ - DEBUG - OpenAI API key loaded: ********************************************************************************************************************************************************************
2024-11-14 14:44:31,782 - __main__ - DEBUG - Upload folder path: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\uploads
2024-11-14 14:44:31,782 - __main__ - DEBUG - Output folder path: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output
2024-11-14 14:44:31,782 - __main__ - INFO - Starting main process
2024-11-14 14:44:31,782 - __main__ - INFO - Starting initial data processing
2024-11-14 14:44:32,154 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-11-14 14:44:32,155 - httpx - DEBUG - load_verify_locations cafile='C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\certifi\\cacert.pem'
2024-11-14 14:44:32,686 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-14 14:44:32,686 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-11-14 14:44:32,813 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001E5AA1AC830>
2024-11-14 14:44:32,813 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001E5AA43CC50> server_hostname='api.openai.com' timeout=5.0
2024-11-14 14:44:33,201 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001E5AA1B2750>
2024-11-14 14:44:33,202 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-14 14:44:33,202 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-14 14:44:33,202 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-14 14:44:33,202 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-14 14:44:33,202 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-14 14:44:42,378 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 14 Nov 2024 07:44:38 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'step-up-ognepk'), (b'openai-processing-ms', b'8504'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'448148'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'246ms'), (b'x-request-id', b'req_18e155275a37488cf302576f4c474259'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=TfRuYtC6s5zaanY30pnYgrWi85GVwkF4UNcyAgMmhBo-1731570278-1.0.1.1-O1fnLQY7K2rNezinxMGYHYNt5xxKClHVJtihHW9I1pP6fChdYKoW73pbixiOeNkCCjk_xwgw.c9AsAWSmwp4wA; path=/; expires=Thu, 14-Nov-24 08:14:38 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=lbNF.yD_mT3ex0__kwNQ4lPeKA8kwNSbBnEYKgTJUgU-1731570278393-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e256066fbf85feb-SIN'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-14 14:44:42,379 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-14 14:44:42,379 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-14 14:44:42,381 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-14 14:44:42,381 - httpcore.http11 - DEBUG - response_closed.started
2024-11-14 14:44:42,381 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-14 14:44:42,381 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 14 Nov 2024 07:44:38 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'step-up-ognepk'), ('openai-processing-ms', '8504'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '500'), ('x-ratelimit-limit-tokens', '450000'), ('x-ratelimit-remaining-requests', '499'), ('x-ratelimit-remaining-tokens', '448148'), ('x-ratelimit-reset-requests', '120ms'), ('x-ratelimit-reset-tokens', '246ms'), ('x-request-id', 'req_18e155275a37488cf302576f4c474259'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=TfRuYtC6s5zaanY30pnYgrWi85GVwkF4UNcyAgMmhBo-1731570278-1.0.1.1-O1fnLQY7K2rNezinxMGYHYNt5xxKClHVJtihHW9I1pP6fChdYKoW73pbixiOeNkCCjk_xwgw.c9AsAWSmwp4wA; path=/; expires=Thu, 14-Nov-24 08:14:38 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=lbNF.yD_mT3ex0__kwNQ4lPeKA8kwNSbBnEYKgTJUgU-1731570278393-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8e256066fbf85feb-SIN'), ('content-encoding', 'br'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-11-14 14:44:42,382 - openai._base_client - DEBUG - request_id: req_18e155275a37488cf302576f4c474259
2024-11-14 14:44:42,386 - __main__ - DEBUG - Order 1, Input: 'Topic: talk about your family - Family size and type
Given vocabulary: Nuclear family
Situation: Sarah and Tom, neighbors, at a community park', Response received in 10.23s
2024-11-14 14:44:42,386 - __main__ - DEBUG - Processed row - Order: 1
2024-11-14 14:44:42,391 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-14 14:44:42,391 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-14 14:44:42,391 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-14 14:44:42,391 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-14 14:44:42,392 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-14 14:44:42,392 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-14 14:44:54,155 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 14 Nov 2024 07:44:50 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'step-up-ognepk'), (b'openai-processing-ms', b'11427'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'448146'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'247ms'), (b'x-request-id', b'req_402a3189a49c40c9296e3832da269977'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e2560a068d15feb-SIN'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-14 14:44:54,155 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-14 14:44:54,155 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-14 14:44:54,156 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-14 14:44:54,156 - httpcore.http11 - DEBUG - response_closed.started
2024-11-14 14:44:54,156 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-14 14:44:54,156 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 14 Nov 2024 07:44:50 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'step-up-ognepk', 'openai-processing-ms': '11427', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '450000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '448146', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '247ms', 'x-request-id': 'req_402a3189a49c40c9296e3832da269977', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8e2560a068d15feb-SIN', 'content-encoding': 'br', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-14 14:44:54,156 - openai._base_client - DEBUG - request_id: req_402a3189a49c40c9296e3832da269977
2024-11-14 14:44:54,157 - __main__ - DEBUG - Order 2, Input: 'Topic: talk about your family - Family size and type
Given vocabulary: Generational family
Situation: Aubrey and Isaac, engineers, at a construction site', Response received in 11.77s
2024-11-14 14:44:54,157 - __main__ - DEBUG - Processed row - Order: 2
2024-11-14 14:44:54,245 - __main__ - INFO - Output saved to D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output.xlsx
2024-11-14 14:44:54,245 - __main__ - INFO - Starting story data processing
2024-11-14 14:44:54,260 - __main__ - DEBUG - Processing story data for order 1
2024-11-14 14:44:54,261 - __main__ - DEBUG - Processing story data for order 2
2024-11-14 14:44:54,302 - __main__ - INFO - Story data processing complete, saved to D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story.xlsx
2024-11-14 14:44:54,303 - __main__ - INFO - Starting audio generation
2024-11-14 14:44:54,310 - __main__ - DEBUG - Generating audio for order 1
2024-11-14 14:44:54,310 - __main__ - DEBUG - Sending TTS request for order 1, role female_1
2024-11-14 14:44:54,314 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 14:44:54,327 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 14:44:55,527 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 142414
2024-11-14 14:44:55,549 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\1\female_1.wav
2024-11-14 14:44:55,549 - __main__ - DEBUG - Sending TTS request for order 1, role male_1
2024-11-14 14:44:55,550 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 14:44:55,565 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 14:44:57,031 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 231502
2024-11-14 14:44:57,061 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\1\male_1.wav
2024-11-14 14:44:57,062 - __main__ - DEBUG - Sending TTS request for order 1, role female_2
2024-11-14 14:44:57,063 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 14:44:57,076 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 14:44:58,927 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 267342
2024-11-14 14:44:58,957 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\1\female_2.wav
2024-11-14 14:44:58,957 - __main__ - DEBUG - Sending TTS request for order 1, role male_2
2024-11-14 14:44:58,958 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 14:44:58,973 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 14:45:00,300 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 216142
2024-11-14 14:45:00,321 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\1\male_2.wav
2024-11-14 14:45:00,322 - __main__ - DEBUG - Generating audio for order 2
2024-11-14 14:45:00,322 - __main__ - DEBUG - Sending TTS request for order 2, role female_1
2024-11-14 14:45:00,323 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 14:45:00,336 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 14:45:01,847 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 209486
2024-11-14 14:45:01,886 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\2\female_1.wav
2024-11-14 14:45:01,886 - __main__ - DEBUG - Sending TTS request for order 2, role male_1
2024-11-14 14:45:01,888 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 14:45:01,899 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 14:45:03,015 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 171598
2024-11-14 14:45:03,049 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\2\male_1.wav
2024-11-14 14:45:03,050 - __main__ - DEBUG - Sending TTS request for order 2, role female_2
2024-11-14 14:45:03,051 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 14:45:03,063 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 14:45:04,822 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 289358
2024-11-14 14:45:04,898 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\2\female_2.wav
2024-11-14 14:45:04,899 - __main__ - DEBUG - Sending TTS request for order 2, role male_2
2024-11-14 14:45:04,901 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 14:45:04,911 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 14:45:07,175 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 343118
2024-11-14 14:45:07,286 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\2\male_2.wav
2024-11-14 14:45:07,286 - __main__ - INFO - Audio generation complete
2024-11-14 14:45:07,287 - __main__ - INFO - Processing complete. Final output saved to: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story.xlsx
2024-11-14 14:45:07,377 - httpcore.connection - DEBUG - close.started
2024-11-14 14:45:07,377 - httpcore.connection - DEBUG - close.complete
2024-11-14 15:00:00,233 - __main__ - DEBUG - OpenAI API key loaded: ********************************************************************************************************************************************************************
2024-11-14 15:00:00,233 - __main__ - DEBUG - Upload folder path: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\uploads
2024-11-14 15:00:00,234 - __main__ - DEBUG - Output folder path: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output
2024-11-14 15:00:00,234 - __main__ - INFO - Starting main process
2024-11-14 15:00:00,234 - __main__ - INFO - Starting initial data processing
2024-11-14 15:00:00,515 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-11-14 15:00:00,516 - httpx - DEBUG - load_verify_locations cafile='C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\certifi\\cacert.pem'
2024-11-14 15:00:06,430 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-14 15:00:06,430 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-11-14 15:00:06,564 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021BEA661CD0>
2024-11-14 15:00:06,564 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000021BEAA3CC50> server_hostname='api.openai.com' timeout=5.0
2024-11-14 15:00:06,640 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021BEA662660>
2024-11-14 15:00:06,640 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-14 15:00:06,640 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-14 15:00:06,640 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-14 15:00:06,640 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-14 15:00:06,640 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-14 15:00:15,862 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 14 Nov 2024 08:00:11 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'step-up-ognepk'), (b'openai-processing-ms', b'8475'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'448148'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'246ms'), (b'x-request-id', b'req_ef5ca0c7caf9f82b179c27155d5de59f'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=xvJadCuVzBe_Z.LKGOgDZqwsnsbA677HBFYYA5XeQFo-1731571211-1.0.1.1-L7QyMZDvNAMMwLaNMUp3yx9XMEMKPLe4Sr5u66_dxaDHJv0qBhgC8Q4l7xH8lPO_DFWz2SaIoMfL86OIWBriZg; path=/; expires=Thu, 14-Nov-24 08:30:11 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=Ah0CW0MNoYgpgVo30aMCLwO2iBvoIQivTF8bGUvxOuE-1731571211874-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e257730ffe25fea-SIN'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-14 15:00:15,863 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-14 15:00:15,863 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-14 15:00:15,864 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-14 15:00:15,864 - httpcore.http11 - DEBUG - response_closed.started
2024-11-14 15:00:15,864 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-14 15:00:15,864 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 14 Nov 2024 08:00:11 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'step-up-ognepk'), ('openai-processing-ms', '8475'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '500'), ('x-ratelimit-limit-tokens', '450000'), ('x-ratelimit-remaining-requests', '499'), ('x-ratelimit-remaining-tokens', '448148'), ('x-ratelimit-reset-requests', '120ms'), ('x-ratelimit-reset-tokens', '246ms'), ('x-request-id', 'req_ef5ca0c7caf9f82b179c27155d5de59f'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=xvJadCuVzBe_Z.LKGOgDZqwsnsbA677HBFYYA5XeQFo-1731571211-1.0.1.1-L7QyMZDvNAMMwLaNMUp3yx9XMEMKPLe4Sr5u66_dxaDHJv0qBhgC8Q4l7xH8lPO_DFWz2SaIoMfL86OIWBriZg; path=/; expires=Thu, 14-Nov-24 08:30:11 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=Ah0CW0MNoYgpgVo30aMCLwO2iBvoIQivTF8bGUvxOuE-1731571211874-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8e257730ffe25fea-SIN'), ('content-encoding', 'br'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-11-14 15:00:15,864 - openai._base_client - DEBUG - request_id: req_ef5ca0c7caf9f82b179c27155d5de59f
2024-11-14 15:00:15,868 - __main__ - DEBUG - Order 1, Input: 'Topic: talk about your family - Family size and type
Given vocabulary: Nuclear family
Situation: Sarah and Tom, neighbors, at a community park', Response received in 15.35s
2024-11-14 15:00:15,868 - __main__ - DEBUG - Processed row - Order: 1
2024-11-14 15:00:15,873 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-14 15:00:15,873 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-14 15:00:15,873 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-14 15:00:15,873 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-14 15:00:15,873 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-14 15:00:15,873 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-14 15:00:27,992 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 14 Nov 2024 08:00:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'step-up-ognepk'), (b'openai-processing-ms', b'11770'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'448146'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'247ms'), (b'x-request-id', b'req_d918b506225925a79e19def6c2e01a62'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e25776abb085fea-SIN'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-14 15:00:27,992 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-14 15:00:27,992 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-14 15:00:27,993 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-14 15:00:27,993 - httpcore.http11 - DEBUG - response_closed.started
2024-11-14 15:00:27,993 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-14 15:00:27,993 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 14 Nov 2024 08:00:24 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'step-up-ognepk', 'openai-processing-ms': '11770', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '450000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '448146', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '247ms', 'x-request-id': 'req_d918b506225925a79e19def6c2e01a62', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8e25776abb085fea-SIN', 'content-encoding': 'br', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-14 15:00:27,993 - openai._base_client - DEBUG - request_id: req_d918b506225925a79e19def6c2e01a62
2024-11-14 15:00:27,994 - __main__ - DEBUG - Order 2, Input: 'Topic: talk about your family - Family size and type
Given vocabulary: Generational family
Situation: Aubrey and Isaac, engineers, at a construction site', Response received in 12.12s
2024-11-14 15:00:27,994 - __main__ - DEBUG - Processed row - Order: 2
2024-11-14 15:00:28,045 - __main__ - INFO - Output saved to D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output.xlsx
2024-11-14 15:00:28,045 - __main__ - INFO - Starting story data processing
2024-11-14 15:00:28,057 - __main__ - DEBUG - Processing story data for order 1
2024-11-14 15:00:28,057 - __main__ - DEBUG - Processing story data for order 2
2024-11-14 15:00:28,081 - __main__ - INFO - Story data processing complete, saved to D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story.xlsx
2024-11-14 15:00:28,081 - __main__ - INFO - Starting audio generation
2024-11-14 15:00:28,087 - __main__ - DEBUG - Generating audio for order 1
2024-11-14 15:00:28,087 - __main__ - DEBUG - Sending TTS request for order 1, role female_1
2024-11-14 15:00:28,089 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:00:28,106 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:00:29,132 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 147022
2024-11-14 15:00:29,162 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\1\female_1.wav
2024-11-14 15:00:29,162 - __main__ - DEBUG - Sending TTS request for order 1, role male_1
2024-11-14 15:00:29,163 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:00:29,178 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:00:30,519 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 209486
2024-11-14 15:00:30,556 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\1\male_1.wav
2024-11-14 15:00:30,557 - __main__ - DEBUG - Sending TTS request for order 1, role female_2
2024-11-14 15:00:30,558 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:00:30,571 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:00:31,770 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 184910
2024-11-14 15:00:31,808 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\1\female_2.wav
2024-11-14 15:00:31,809 - __main__ - DEBUG - Sending TTS request for order 1, role male_2
2024-11-14 15:00:31,810 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:00:31,825 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:00:33,236 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 220750
2024-11-14 15:00:33,542 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\1\male_2.wav
2024-11-14 15:00:33,543 - __main__ - DEBUG - Generating audio for order 2
2024-11-14 15:00:33,543 - __main__ - DEBUG - Sending TTS request for order 2, role female_1
2024-11-14 15:00:33,544 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:00:33,637 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:00:35,078 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 186958
2024-11-14 15:00:35,223 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\2\female_1.wav
2024-11-14 15:00:35,224 - __main__ - DEBUG - Sending TTS request for order 2, role male_1
2024-11-14 15:00:35,225 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:00:35,308 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:00:36,499 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 191566
2024-11-14 15:00:36,552 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\2\male_1.wav
2024-11-14 15:00:36,552 - __main__ - DEBUG - Sending TTS request for order 2, role female_2
2024-11-14 15:00:36,553 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:00:36,567 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:00:41,881 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 878158
2024-11-14 15:00:41,992 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\2\female_2.wav
2024-11-14 15:00:41,993 - __main__ - DEBUG - Sending TTS request for order 2, role male_2
2024-11-14 15:00:41,994 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:00:42,006 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:00:43,889 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 265294
2024-11-14 15:00:43,930 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\2\male_2.wav
2024-11-14 15:00:43,930 - __main__ - INFO - Audio generation complete
2024-11-14 15:00:43,931 - __main__ - INFO - Processing complete. Final output saved to: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story.xlsx
2024-11-14 15:00:44,001 - httpcore.connection - DEBUG - close.started
2024-11-14 15:00:44,002 - httpcore.connection - DEBUG - close.complete
2024-11-14 15:19:13,029 - __main__ - DEBUG - OpenAI API key loaded: ********************************************************************************************************************************************************************
2024-11-14 15:19:13,030 - __main__ - DEBUG - Upload folder path: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\uploads
2024-11-14 15:19:13,030 - __main__ - DEBUG - Output folder path: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output
2024-11-14 15:19:13,030 - __main__ - INFO - Starting main process
2024-11-14 15:19:13,030 - __main__ - INFO - Starting initial data processing
2024-11-14 15:19:13,306 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-11-14 15:19:13,307 - httpx - DEBUG - load_verify_locations cafile='C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\certifi\\cacert.pem'
2024-11-14 15:19:13,916 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-14 15:19:13,917 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-11-14 15:19:14,014 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001CFF7893A40>
2024-11-14 15:19:14,015 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001CFF7B5CC50> server_hostname='api.openai.com' timeout=5.0
2024-11-14 15:19:14,082 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001CFF78ABE30>
2024-11-14 15:19:14,082 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-14 15:19:14,082 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-14 15:19:14,082 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-14 15:19:14,083 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-14 15:19:14,083 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-14 15:19:26,920 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 14 Nov 2024 08:19:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'step-up-ognepk'), (b'openai-processing-ms', b'12476'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'448148'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'246ms'), (b'x-request-id', b'req_44fd1fb2dc33e3c39fe4e4215bf8439d'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Pgc1UVejshQGQWfiMqTwu5v6RkYyO4gU9GL2GJmsGAQ-1731572362-1.0.1.1-mbSE4pAkTmqFx7A224g9qX.yFiATUXgDD2c6G3O7ZJN3_.1CnuNw1lxiYt4T2rQZuxGJSyd_tR.Urla9i7TF2Q; path=/; expires=Thu, 14-Nov-24 08:49:22 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=TFtlwlrXffhTT3wTvfs7A_W4ipHSm_GRgxWDkYcHYbU-1731572362925-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e2593348966cdf9-SIN'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-14 15:19:26,921 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-14 15:19:26,921 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-14 15:19:26,922 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-14 15:19:26,922 - httpcore.http11 - DEBUG - response_closed.started
2024-11-14 15:19:26,922 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-14 15:19:26,922 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 14 Nov 2024 08:19:22 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'step-up-ognepk'), ('openai-processing-ms', '12476'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '500'), ('x-ratelimit-limit-tokens', '450000'), ('x-ratelimit-remaining-requests', '499'), ('x-ratelimit-remaining-tokens', '448148'), ('x-ratelimit-reset-requests', '120ms'), ('x-ratelimit-reset-tokens', '246ms'), ('x-request-id', 'req_44fd1fb2dc33e3c39fe4e4215bf8439d'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=Pgc1UVejshQGQWfiMqTwu5v6RkYyO4gU9GL2GJmsGAQ-1731572362-1.0.1.1-mbSE4pAkTmqFx7A224g9qX.yFiATUXgDD2c6G3O7ZJN3_.1CnuNw1lxiYt4T2rQZuxGJSyd_tR.Urla9i7TF2Q; path=/; expires=Thu, 14-Nov-24 08:49:22 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=TFtlwlrXffhTT3wTvfs7A_W4ipHSm_GRgxWDkYcHYbU-1731572362925-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8e2593348966cdf9-SIN'), ('content-encoding', 'br'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-11-14 15:19:26,922 - openai._base_client - DEBUG - request_id: req_44fd1fb2dc33e3c39fe4e4215bf8439d
2024-11-14 15:19:26,926 - __main__ - DEBUG - Order 1, Input: 'Topic: talk about your family - Family size and type
Given vocabulary: Nuclear family
Situation: Sarah and Tom, neighbors, at a community park', Response received in 13.62s
2024-11-14 15:19:26,926 - __main__ - DEBUG - Processed row - Order: 1
2024-11-14 15:19:26,932 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-14 15:19:26,932 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-14 15:19:26,933 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-14 15:19:26,933 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-14 15:19:26,933 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-14 15:19:26,933 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-14 15:19:38,132 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 14 Nov 2024 08:19:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'step-up-ognepk'), (b'openai-processing-ms', b'10869'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'448146'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'247ms'), (b'x-request-id', b'req_34583e4c9a3e8352eb90d38d29bb354b'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e259384e9f4cdf9-SIN'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-14 15:19:38,132 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-14 15:19:38,132 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-14 15:19:38,133 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-14 15:19:38,133 - httpcore.http11 - DEBUG - response_closed.started
2024-11-14 15:19:38,133 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-14 15:19:38,133 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 14 Nov 2024 08:19:34 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'step-up-ognepk', 'openai-processing-ms': '10869', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '450000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '448146', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '247ms', 'x-request-id': 'req_34583e4c9a3e8352eb90d38d29bb354b', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8e259384e9f4cdf9-SIN', 'content-encoding': 'br', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-14 15:19:38,133 - openai._base_client - DEBUG - request_id: req_34583e4c9a3e8352eb90d38d29bb354b
2024-11-14 15:19:38,134 - __main__ - DEBUG - Order 2, Input: 'Topic: talk about your family - Family size and type
Given vocabulary: Generational family
Situation: Aubrey and Isaac, engineers, at a construction site', Response received in 11.21s
2024-11-14 15:19:38,134 - __main__ - DEBUG - Processed row - Order: 2
2024-11-14 15:19:38,187 - __main__ - INFO - Output saved to D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output.xlsx
2024-11-14 15:19:38,187 - __main__ - INFO - Starting story data processing
2024-11-14 15:19:38,200 - __main__ - DEBUG - Processing story data for order 1
2024-11-14 15:19:38,200 - __main__ - DEBUG - Processing story data for order 2
2024-11-14 15:19:38,237 - __main__ - INFO - Story data processing complete, saved to D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story.xlsx
2024-11-14 15:19:38,237 - __main__ - INFO - Starting audio generation
2024-11-14 15:19:38,244 - __main__ - DEBUG - Generating audio for order 1
2024-11-14 15:19:38,244 - __main__ - DEBUG - Sending TTS request for order 1, role female_1
2024-11-14 15:19:38,246 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:19:38,262 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:19:40,066 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 240718
2024-11-14 15:19:40,111 - __main__ - DEBUG - Audio files saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\1\female_1.wav and D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\1\ipa_1.mp3
2024-11-14 15:19:40,112 - __main__ - DEBUG - Sending TTS request for order 1, role male_1
2024-11-14 15:19:40,113 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:19:40,130 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:19:41,856 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 236110
2024-11-14 15:19:41,901 - __main__ - DEBUG - Audio files saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\1\male_1.wav and D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\1\ipa_1.mp3
2024-11-14 15:19:41,902 - __main__ - DEBUG - Sending TTS request for order 1, role female_2
2024-11-14 15:19:41,903 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:19:41,915 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:19:43,641 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 282702
2024-11-14 15:19:43,684 - __main__ - DEBUG - Audio files saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\1\female_2.wav and D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\1\ipa_1.mp3
2024-11-14 15:19:43,685 - __main__ - DEBUG - Sending TTS request for order 1, role male_2
2024-11-14 15:19:43,686 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:19:43,696 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:19:45,481 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 249422
2024-11-14 15:19:45,517 - __main__ - DEBUG - Audio files saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\1\male_2.wav and D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\1\ipa_1.mp3
2024-11-14 15:19:45,518 - __main__ - DEBUG - Generating audio for order 2
2024-11-14 15:19:45,518 - __main__ - DEBUG - Sending TTS request for order 2, role female_1
2024-11-14 15:19:45,519 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:19:45,532 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:19:46,621 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 166990
2024-11-14 15:19:46,659 - __main__ - DEBUG - Audio files saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\2\female_1.wav and D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\2\ipa_2.mp3
2024-11-14 15:19:46,659 - __main__ - DEBUG - Sending TTS request for order 2, role male_1
2024-11-14 15:19:46,660 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:19:46,676 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:19:48,573 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 318542
2024-11-14 15:19:48,636 - __main__ - DEBUG - Audio files saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\2\male_1.wav and D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\2\ipa_2.mp3
2024-11-14 15:19:48,636 - __main__ - DEBUG - Sending TTS request for order 2, role female_2
2024-11-14 15:19:48,637 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:19:48,649 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:19:50,711 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 307278
2024-11-14 15:19:50,768 - __main__ - DEBUG - Audio files saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\2\female_2.wav and D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\2\ipa_2.mp3
2024-11-14 15:19:50,769 - __main__ - DEBUG - Sending TTS request for order 2, role male_2
2024-11-14 15:19:50,770 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:19:50,785 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:19:52,818 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 285262
2024-11-14 15:19:52,865 - __main__ - DEBUG - Audio files saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\2\male_2.wav and D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\2\ipa_2.mp3
2024-11-14 15:19:52,865 - __main__ - INFO - Audio generation complete
2024-11-14 15:19:52,865 - __main__ - INFO - Processing complete. Final output saved to: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story.xlsx
2024-11-14 15:19:52,922 - httpcore.connection - DEBUG - close.started
2024-11-14 15:19:52,923 - httpcore.connection - DEBUG - close.complete
2024-11-14 15:29:24,162 - __main__ - DEBUG - OpenAI API key loaded: ********************************************************************************************************************************************************************
2024-11-14 15:29:24,162 - __main__ - DEBUG - Upload folder path: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\uploads
2024-11-14 15:29:24,162 - __main__ - DEBUG - Output folder path: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output
2024-11-14 15:29:24,163 - __main__ - INFO - Starting main process
2024-11-14 15:29:24,163 - __main__ - INFO - Starting initial data processing
2024-11-14 15:29:24,463 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-11-14 15:29:24,463 - httpx - DEBUG - load_verify_locations cafile='C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\certifi\\cacert.pem'
2024-11-14 15:29:24,934 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-14 15:29:24,935 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-11-14 15:29:25,055 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000248F5593A40>
2024-11-14 15:29:25,056 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000248F583CC50> server_hostname='api.openai.com' timeout=5.0
2024-11-14 15:29:25,128 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000248F55A59D0>
2024-11-14 15:29:25,129 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-14 15:29:25,129 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-14 15:29:25,129 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-14 15:29:25,129 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-14 15:29:25,129 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-14 15:29:33,866 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 14 Nov 2024 08:29:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'step-up-ognepk'), (b'openai-processing-ms', b'8399'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'448148'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'246ms'), (b'x-request-id', b'req_eb2afa957ca577819eb596eb44fe64dc'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=ci_x7YMroNpeF0W.VXpw1QC.uyXj5l8gwLMcH7SyGaM-1731572969-1.0.1.1-Foevm1gQuKHZy9hx_SzaRjanjEjGJ7zLwzca0iZxwPj6AEDkXuXzIsIL7HlATM2GfMBmRsk1.oRyU1UQeIE6TA; path=/; expires=Thu, 14-Nov-24 08:59:29 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=9JXgRepxJb0QGUJ_W_QVebmuxkWTx3aEJhZZv4u4Jzs-1731572969888-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e25a21f9cd2ce41-SIN'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-14 15:29:33,866 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-14 15:29:33,866 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-14 15:29:33,867 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-14 15:29:33,867 - httpcore.http11 - DEBUG - response_closed.started
2024-11-14 15:29:33,867 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-14 15:29:33,867 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 14 Nov 2024 08:29:29 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'step-up-ognepk'), ('openai-processing-ms', '8399'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '500'), ('x-ratelimit-limit-tokens', '450000'), ('x-ratelimit-remaining-requests', '499'), ('x-ratelimit-remaining-tokens', '448148'), ('x-ratelimit-reset-requests', '120ms'), ('x-ratelimit-reset-tokens', '246ms'), ('x-request-id', 'req_eb2afa957ca577819eb596eb44fe64dc'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=ci_x7YMroNpeF0W.VXpw1QC.uyXj5l8gwLMcH7SyGaM-1731572969-1.0.1.1-Foevm1gQuKHZy9hx_SzaRjanjEjGJ7zLwzca0iZxwPj6AEDkXuXzIsIL7HlATM2GfMBmRsk1.oRyU1UQeIE6TA; path=/; expires=Thu, 14-Nov-24 08:59:29 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=9JXgRepxJb0QGUJ_W_QVebmuxkWTx3aEJhZZv4u4Jzs-1731572969888-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8e25a21f9cd2ce41-SIN'), ('content-encoding', 'br'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-11-14 15:29:33,867 - openai._base_client - DEBUG - request_id: req_eb2afa957ca577819eb596eb44fe64dc
2024-11-14 15:29:33,871 - __main__ - DEBUG - Order 1, Input: 'Topic: talk about your family - Family size and type
Given vocabulary: Nuclear family
Situation: Sarah and Tom, neighbors, at a community park', Response received in 9.41s
2024-11-14 15:29:33,871 - __main__ - DEBUG - Processed row - Order: 1
2024-11-14 15:29:33,876 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-14 15:29:33,876 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-14 15:29:33,877 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-14 15:29:33,877 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-14 15:29:33,877 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-14 15:29:33,877 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-14 15:29:44,377 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 14 Nov 2024 08:29:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'step-up-ognepk'), (b'openai-processing-ms', b'10161'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'448146'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'247ms'), (b'x-request-id', b'req_70a9395f501432767bc113234938559c'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e25a2564c2ece41-SIN'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-14 15:29:44,378 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-14 15:29:44,378 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-14 15:29:44,378 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-14 15:29:44,378 - httpcore.http11 - DEBUG - response_closed.started
2024-11-14 15:29:44,378 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-14 15:29:44,379 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 14 Nov 2024 08:29:40 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'step-up-ognepk', 'openai-processing-ms': '10161', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '450000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '448146', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '247ms', 'x-request-id': 'req_70a9395f501432767bc113234938559c', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8e25a2564c2ece41-SIN', 'content-encoding': 'br', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-14 15:29:44,379 - openai._base_client - DEBUG - request_id: req_70a9395f501432767bc113234938559c
2024-11-14 15:29:44,379 - __main__ - DEBUG - Order 2, Input: 'Topic: talk about your family - Family size and type
Given vocabulary: Generational family
Situation: Aubrey and Isaac, engineers, at a construction site', Response received in 10.51s
2024-11-14 15:29:44,379 - __main__ - DEBUG - Processed row - Order: 2
2024-11-14 15:29:44,446 - __main__ - INFO - Output saved to D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output.xlsx
2024-11-14 15:29:44,446 - __main__ - INFO - Starting story data processing
2024-11-14 15:29:44,465 - __main__ - DEBUG - Processing story data for order 1
2024-11-14 15:29:44,465 - __main__ - DEBUG - Processing story data for order 2
2024-11-14 15:29:44,501 - __main__ - INFO - Story data processing complete, saved to D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story.xlsx
2024-11-14 15:29:44,502 - __main__ - INFO - Starting audio generation
2024-11-14 15:29:44,509 - __main__ - DEBUG - Generating audio for order 1
2024-11-14 15:29:44,509 - __main__ - DEBUG - Sending TTS request for order 1, role female_1
2024-11-14 15:29:44,512 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:29:44,554 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:29:45,520 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 142414
2024-11-14 15:29:45,557 - __main__ - DEBUG - Audio files saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\1\female_1.wav and D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\1\ipa_1.mp3
2024-11-14 15:29:45,557 - __main__ - DEBUG - Sending TTS request for order 1, role male_1
2024-11-14 15:29:45,558 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:29:45,569 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:29:46,986 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 222798
2024-11-14 15:29:47,033 - __main__ - DEBUG - Audio files saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\1\male_1.wav and D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\1\ipa_1.mp3
2024-11-14 15:29:47,034 - __main__ - DEBUG - Sending TTS request for order 1, role female_2
2024-11-14 15:29:47,035 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:29:47,051 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:29:48,595 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 249422
2024-11-14 15:29:48,667 - __main__ - DEBUG - Audio files saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\1\female_2.wav and D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\1\ipa_1.mp3
2024-11-14 15:29:48,668 - __main__ - DEBUG - Sending TTS request for order 1, role male_2
2024-11-14 15:29:48,669 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:29:48,686 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:29:50,011 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 211534
2024-11-14 15:29:50,050 - __main__ - DEBUG - Audio files saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\1\male_2.wav and D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\1\ipa_1.mp3
2024-11-14 15:29:50,050 - __main__ - DEBUG - Generating audio for order 2
2024-11-14 15:29:50,050 - __main__ - DEBUG - Sending TTS request for order 2, role female_1
2024-11-14 15:29:50,051 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:29:50,066 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:29:51,543 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 240718
2024-11-14 15:29:51,587 - __main__ - DEBUG - Audio files saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\2\female_1.wav and D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\2\ipa_2.mp3
2024-11-14 15:29:51,587 - __main__ - DEBUG - Sending TTS request for order 2, role male_1
2024-11-14 15:29:51,589 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:29:51,610 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:29:53,364 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 280654
2024-11-14 15:29:53,472 - __main__ - DEBUG - Audio files saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\2\male_1.wav and D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\2\ipa_2.mp3
2024-11-14 15:29:53,473 - __main__ - DEBUG - Sending TTS request for order 2, role female_2
2024-11-14 15:29:53,474 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:29:53,492 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:29:55,585 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 343118
2024-11-14 15:29:55,636 - __main__ - DEBUG - Audio files saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\2\female_2.wav and D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\2\ipa_2.mp3
2024-11-14 15:29:55,636 - __main__ - DEBUG - Sending TTS request for order 2, role male_2
2024-11-14 15:29:55,637 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:29:55,649 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:29:58,110 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 430158
2024-11-14 15:29:58,172 - __main__ - DEBUG - Audio files saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\2\male_2.wav and D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\2\ipa_2.mp3
2024-11-14 15:29:58,173 - __main__ - INFO - Audio generation complete
2024-11-14 15:29:58,173 - __main__ - INFO - Processing complete. Final output saved to: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story.xlsx
2024-11-14 15:29:58,231 - httpcore.connection - DEBUG - close.started
2024-11-14 15:29:58,231 - httpcore.connection - DEBUG - close.complete
2024-11-14 15:33:18,746 - __main__ - DEBUG - OpenAI API key loaded: ********************************************************************************************************************************************************************
2024-11-14 15:33:18,746 - __main__ - DEBUG - Upload folder path: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\uploads
2024-11-14 15:33:18,746 - __main__ - DEBUG - Output folder path: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output
2024-11-14 15:33:18,746 - __main__ - INFO - Starting main process
2024-11-14 15:33:18,747 - __main__ - INFO - Starting initial data processing
2024-11-14 15:33:19,099 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-11-14 15:33:19,100 - httpx - DEBUG - load_verify_locations cafile='C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\certifi\\cacert.pem'
2024-11-14 15:33:20,840 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-14 15:33:20,841 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-11-14 15:33:20,966 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001E6E3ADEE40>
2024-11-14 15:33:20,966 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001E6E3D8CC50> server_hostname='api.openai.com' timeout=5.0
2024-11-14 15:33:21,103 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001E6E3ADD310>
2024-11-14 15:33:21,103 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-14 15:33:21,104 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-14 15:33:21,104 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-14 15:33:21,104 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-14 15:33:21,104 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-14 15:33:33,244 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 14 Nov 2024 08:33:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'step-up-ognepk'), (b'openai-processing-ms', b'11796'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'448148'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'246ms'), (b'x-request-id', b'req_964c18101941972fea4e4cb7ed215d3e'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=LNaFQbFXfc1fc70mj_cMOrWAWpzVrqUXSy_8wb7R6AE-1731573209-1.0.1.1-Iq3wTYMwoBnnOFeSwvgJW5XKB8yb5Ztfp_U3aCknOtt1hhTcxhEWMSunluWKHY6F47XnpHaK3_otoOuIOjr7KQ; path=/; expires=Thu, 14-Nov-24 09:03:29 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=uO9TQZ9cXjjR8HgWIv_IFM7AGH4QUZmhGvEzKx.sPXk-1731573209272-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e25a7e279778343-SIN'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-14 15:33:33,244 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-14 15:33:33,245 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-14 15:33:33,245 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-14 15:33:33,245 - httpcore.http11 - DEBUG - response_closed.started
2024-11-14 15:33:33,245 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-14 15:33:33,245 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 14 Nov 2024 08:33:29 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'step-up-ognepk'), ('openai-processing-ms', '11796'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '500'), ('x-ratelimit-limit-tokens', '450000'), ('x-ratelimit-remaining-requests', '499'), ('x-ratelimit-remaining-tokens', '448148'), ('x-ratelimit-reset-requests', '120ms'), ('x-ratelimit-reset-tokens', '246ms'), ('x-request-id', 'req_964c18101941972fea4e4cb7ed215d3e'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=LNaFQbFXfc1fc70mj_cMOrWAWpzVrqUXSy_8wb7R6AE-1731573209-1.0.1.1-Iq3wTYMwoBnnOFeSwvgJW5XKB8yb5Ztfp_U3aCknOtt1hhTcxhEWMSunluWKHY6F47XnpHaK3_otoOuIOjr7KQ; path=/; expires=Thu, 14-Nov-24 09:03:29 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=uO9TQZ9cXjjR8HgWIv_IFM7AGH4QUZmhGvEzKx.sPXk-1731573209272-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8e25a7e279778343-SIN'), ('content-encoding', 'br'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-11-14 15:33:33,245 - openai._base_client - DEBUG - request_id: req_964c18101941972fea4e4cb7ed215d3e
2024-11-14 15:33:33,249 - __main__ - DEBUG - Order 1, Input: 'Topic: talk about your family - Family size and type
Given vocabulary: Nuclear family
Situation: Sarah and Tom, neighbors, at a community park', Response received in 14.15s
2024-11-14 15:33:33,249 - __main__ - DEBUG - Processed row - Order: 1
2024-11-14 15:33:33,254 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-14 15:33:33,254 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-14 15:33:33,255 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-14 15:33:33,255 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-14 15:33:33,255 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-14 15:33:33,255 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-14 15:33:44,292 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 14 Nov 2024 08:33:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'step-up-ognepk'), (b'openai-processing-ms', b'10683'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'448146'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'247ms'), (b'x-request-id', b'req_7f9af4ee1300156342332dfe0a6cd7a9'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e25a82e6b0e8343-SIN'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-14 15:33:44,292 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-14 15:33:44,292 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-14 15:33:44,607 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-14 15:33:44,607 - httpcore.http11 - DEBUG - response_closed.started
2024-11-14 15:33:44,607 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-14 15:33:44,607 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 14 Nov 2024 08:33:40 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'step-up-ognepk', 'openai-processing-ms': '10683', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '450000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '448146', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '247ms', 'x-request-id': 'req_7f9af4ee1300156342332dfe0a6cd7a9', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8e25a82e6b0e8343-SIN', 'content-encoding': 'br', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-14 15:33:44,607 - openai._base_client - DEBUG - request_id: req_7f9af4ee1300156342332dfe0a6cd7a9
2024-11-14 15:33:44,608 - __main__ - DEBUG - Order 2, Input: 'Topic: talk about your family - Family size and type
Given vocabulary: Generational family
Situation: Aubrey and Isaac, engineers, at a construction site', Response received in 11.36s
2024-11-14 15:33:44,608 - __main__ - DEBUG - Processed row - Order: 2
2024-11-14 15:33:44,668 - __main__ - INFO - Output saved to D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output.xlsx
2024-11-14 15:33:44,668 - __main__ - INFO - Starting story data processing
2024-11-14 15:33:44,684 - __main__ - DEBUG - Processing story data for order 1
2024-11-14 15:33:44,685 - __main__ - DEBUG - Processing story data for order 2
2024-11-14 15:33:44,714 - __main__ - INFO - Story data processing complete, saved to D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story.xlsx
2024-11-14 15:33:44,715 - __main__ - INFO - Starting audio generation
2024-11-14 15:33:44,722 - __main__ - DEBUG - Generating audio for order 1
2024-11-14 15:33:44,722 - __main__ - DEBUG - Sending TTS request for order 1, role female_1
2024-11-14 15:33:44,725 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:33:44,745 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:33:45,935 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 175694
2024-11-14 15:33:45,971 - __main__ - DEBUG - Audio files saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\1\female_1.wav and D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\1\ipa_1.mp3
2024-11-14 15:33:45,972 - __main__ - DEBUG - Sending TTS request for order 1, role male_1
2024-11-14 15:33:45,974 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:33:45,987 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:33:47,210 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 196174
2024-11-14 15:33:47,243 - __main__ - DEBUG - Audio files saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\1\male_1.wav and D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\1\ipa_1.mp3
2024-11-14 15:33:47,243 - __main__ - DEBUG - Sending TTS request for order 1, role female_2
2024-11-14 15:33:47,244 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:33:47,259 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:33:48,616 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 216142
2024-11-14 15:33:48,662 - __main__ - DEBUG - Audio files saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\1\female_2.wav and D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\1\ipa_1.mp3
2024-11-14 15:33:48,663 - __main__ - DEBUG - Sending TTS request for order 1, role male_2
2024-11-14 15:33:48,664 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:33:48,680 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:33:50,085 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 227406
2024-11-14 15:33:50,127 - __main__ - DEBUG - Audio files saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\1\male_2.wav and D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\1\ipa_1.mp3
2024-11-14 15:33:50,127 - __main__ - DEBUG - Generating audio for order 2
2024-11-14 15:33:50,127 - __main__ - DEBUG - Sending TTS request for order 2, role female_1
2024-11-14 15:33:50,129 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:33:50,144 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:33:51,285 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 171598
2024-11-14 15:33:51,336 - __main__ - DEBUG - Audio files saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\2\female_1.wav and D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\2\ipa_2.mp3
2024-11-14 15:33:51,336 - __main__ - DEBUG - Sending TTS request for order 2, role male_1
2024-11-14 15:33:51,338 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:33:51,359 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:33:52,623 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 200270
2024-11-14 15:33:52,662 - __main__ - DEBUG - Audio files saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\2\male_1.wav and D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\2\ipa_2.mp3
2024-11-14 15:33:52,662 - __main__ - DEBUG - Sending TTS request for order 2, role female_2
2024-11-14 15:33:52,664 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:33:52,683 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:33:54,293 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 265294
2024-11-14 15:33:54,336 - __main__ - DEBUG - Audio files saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\2\female_2.wav and D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\2\ipa_2.mp3
2024-11-14 15:33:54,336 - __main__ - DEBUG - Sending TTS request for order 2, role male_2
2024-11-14 15:33:54,337 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:33:54,350 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:33:55,745 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 224846
2024-11-14 15:33:55,798 - __main__ - DEBUG - Audio files saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\2\male_2.wav and D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\2\ipa_2.mp3
2024-11-14 15:33:55,798 - __main__ - INFO - Audio generation complete
2024-11-14 15:33:55,798 - __main__ - INFO - Processing complete. Final output saved to: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story.xlsx
2024-11-14 15:33:55,881 - httpcore.connection - DEBUG - close.started
2024-11-14 15:33:55,881 - httpcore.connection - DEBUG - close.complete
2024-11-14 15:36:01,443 - __main__ - DEBUG - OpenAI API key loaded: ********************************************************************************************************************************************************************
2024-11-14 15:36:01,443 - __main__ - DEBUG - Upload folder path: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\uploads
2024-11-14 15:36:01,443 - __main__ - DEBUG - Output folder path: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output
2024-11-14 15:36:01,443 - __main__ - INFO - Starting main process
2024-11-14 15:36:01,443 - __main__ - INFO - Starting initial data processing
2024-11-14 15:36:01,737 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-11-14 15:36:01,737 - httpx - DEBUG - load_verify_locations cafile='C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\certifi\\cacert.pem'
2024-11-14 15:36:02,277 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-14 15:36:02,278 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-11-14 15:36:02,393 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000165647B2600>
2024-11-14 15:36:02,393 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000016564A4CC50> server_hostname='api.openai.com' timeout=5.0
2024-11-14 15:36:02,551 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000016564662660>
2024-11-14 15:36:02,552 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-14 15:36:02,552 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-14 15:36:02,552 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-14 15:36:02,552 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-14 15:36:02,552 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-14 15:36:13,152 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 14 Nov 2024 08:36:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'step-up-ognepk'), (b'openai-processing-ms', b'10062'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'448148'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'246ms'), (b'x-request-id', b'req_6c96bc2d2f08f7445d921c8ec412f15c'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=m5Ivhw0H1jto8VWqX0xbAmp1lodBrPY9al9LUIWR0Kw-1731573369-1.0.1.1-7JZQk9MkK8NRuhuRlAczhdf4OCisJfhsCOD9pibyzqmFmnMsmAkCPDze.qcnHSAswNd7KTyk9bqYnjO9gAGQog; path=/; expires=Thu, 14-Nov-24 09:06:09 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=kRm2CsybGmMmZ3OXCSsaOkD5AOdzCkD7rJbCy5A2uqw-1731573369003-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e25abd38a289ba2-SIN'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-14 15:36:13,153 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-14 15:36:13,153 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-14 15:36:13,154 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-14 15:36:13,154 - httpcore.http11 - DEBUG - response_closed.started
2024-11-14 15:36:13,154 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-14 15:36:13,154 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 14 Nov 2024 08:36:09 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'step-up-ognepk'), ('openai-processing-ms', '10062'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '500'), ('x-ratelimit-limit-tokens', '450000'), ('x-ratelimit-remaining-requests', '499'), ('x-ratelimit-remaining-tokens', '448148'), ('x-ratelimit-reset-requests', '120ms'), ('x-ratelimit-reset-tokens', '246ms'), ('x-request-id', 'req_6c96bc2d2f08f7445d921c8ec412f15c'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=m5Ivhw0H1jto8VWqX0xbAmp1lodBrPY9al9LUIWR0Kw-1731573369-1.0.1.1-7JZQk9MkK8NRuhuRlAczhdf4OCisJfhsCOD9pibyzqmFmnMsmAkCPDze.qcnHSAswNd7KTyk9bqYnjO9gAGQog; path=/; expires=Thu, 14-Nov-24 09:06:09 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=kRm2CsybGmMmZ3OXCSsaOkD5AOdzCkD7rJbCy5A2uqw-1731573369003-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8e25abd38a289ba2-SIN'), ('content-encoding', 'br'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-11-14 15:36:13,154 - openai._base_client - DEBUG - request_id: req_6c96bc2d2f08f7445d921c8ec412f15c
2024-11-14 15:36:13,157 - __main__ - DEBUG - Order 1, Input: 'Topic: talk about your family - Family size and type
Given vocabulary: Nuclear family
Situation: Sarah and Tom, neighbors, at a community park', Response received in 11.42s
2024-11-14 15:36:13,158 - __main__ - DEBUG - Processed row - Order: 1
2024-11-14 15:36:13,163 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-14 15:36:13,163 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-14 15:36:13,163 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-14 15:36:13,163 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-14 15:36:13,163 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-14 15:36:13,163 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-14 15:36:24,067 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 14 Nov 2024 08:36:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'step-up-ognepk'), (b'openai-processing-ms', b'10492'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'448146'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'247ms'), (b'x-request-id', b'req_33f1d84e57e019829aa08c4957fcf8bf'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e25ac16186d9ba2-SIN'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-14 15:36:24,067 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-14 15:36:24,067 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-14 15:36:24,068 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-14 15:36:24,068 - httpcore.http11 - DEBUG - response_closed.started
2024-11-14 15:36:24,068 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-14 15:36:24,068 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 14 Nov 2024 08:36:20 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'step-up-ognepk', 'openai-processing-ms': '10492', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '450000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '448146', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '247ms', 'x-request-id': 'req_33f1d84e57e019829aa08c4957fcf8bf', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8e25ac16186d9ba2-SIN', 'content-encoding': 'br', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-14 15:36:24,068 - openai._base_client - DEBUG - request_id: req_33f1d84e57e019829aa08c4957fcf8bf
2024-11-14 15:36:24,069 - __main__ - DEBUG - Order 2, Input: 'Topic: talk about your family - Family size and type
Given vocabulary: Generational family
Situation: Aubrey and Isaac, engineers, at a construction site', Response received in 10.91s
2024-11-14 15:36:24,069 - __main__ - DEBUG - Processed row - Order: 2
2024-11-14 15:36:24,121 - __main__ - INFO - Output saved to D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output.xlsx
2024-11-14 15:36:24,121 - __main__ - INFO - Starting story data processing
2024-11-14 15:36:24,137 - __main__ - DEBUG - Processing story data for order 1
2024-11-14 15:36:24,137 - __main__ - DEBUG - Processing story data for order 2
2024-11-14 15:36:24,164 - __main__ - INFO - Story data processing complete, saved to D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story.xlsx
2024-11-14 15:36:24,164 - __main__ - INFO - Starting audio generation
2024-11-14 15:36:24,171 - __main__ - DEBUG - Generating audio for order 1
2024-11-14 15:36:24,171 - __main__ - DEBUG - Sending TTS request for order 1, role female_1
2024-11-14 15:36:24,173 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:36:24,238 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:36:25,281 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 153678
2024-11-14 15:36:25,314 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\1\female_1.wav
2024-11-14 15:36:25,315 - __main__ - DEBUG - Sending TTS request for order 1, role male_1
2024-11-14 15:36:25,316 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:36:25,327 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:36:26,668 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 216142
2024-11-14 15:36:26,711 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\1\male_1.wav
2024-11-14 15:36:26,711 - __main__ - DEBUG - Sending TTS request for order 1, role female_2
2024-11-14 15:36:26,712 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:36:26,725 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:36:28,436 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 238158
2024-11-14 15:36:28,479 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\1\female_2.wav
2024-11-14 15:36:28,479 - __main__ - DEBUG - Sending TTS request for order 1, role male_2
2024-11-14 15:36:28,480 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:36:28,492 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:36:30,325 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 298574
2024-11-14 15:36:30,369 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\1\male_2.wav
2024-11-14 15:36:30,370 - __main__ - DEBUG - Generating audio for order 2
2024-11-14 15:36:30,370 - __main__ - DEBUG - Sending TTS request for order 2, role female_1
2024-11-14 15:36:30,371 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:36:30,389 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:36:31,698 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 211534
2024-11-14 15:36:31,739 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\2\female_1.wav
2024-11-14 15:36:31,740 - __main__ - DEBUG - Sending TTS request for order 2, role male_1
2024-11-14 15:36:31,741 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:36:31,755 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:36:33,027 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 200270
2024-11-14 15:36:33,059 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\2\male_1.wav
2024-11-14 15:36:33,059 - __main__ - DEBUG - Sending TTS request for order 2, role female_2
2024-11-14 15:36:33,061 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:36:33,073 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:36:35,413 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 356430
2024-11-14 15:36:35,487 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\2\female_2.wav
2024-11-14 15:36:35,487 - __main__ - DEBUG - Sending TTS request for order 2, role male_2
2024-11-14 15:36:35,489 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:36:35,502 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:36:37,890 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 365646
2024-11-14 15:36:37,954 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\2\male_2.wav
2024-11-14 15:36:37,954 - __main__ - INFO - Audio generation complete
2024-11-14 15:36:37,954 - __main__ - INFO - Processing complete. Final output saved to: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story.xlsx
2024-11-14 15:36:38,011 - httpcore.connection - DEBUG - close.started
2024-11-14 15:36:38,012 - httpcore.connection - DEBUG - close.complete
2024-11-14 15:37:45,143 - __main__ - DEBUG - OpenAI API key loaded: ********************************************************************************************************************************************************************
2024-11-14 15:37:45,143 - __main__ - DEBUG - Upload folder path: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\uploads
2024-11-14 15:37:45,143 - __main__ - DEBUG - Output folder path: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output
2024-11-14 15:37:45,143 - __main__ - INFO - Starting main process
2024-11-14 15:37:45,144 - __main__ - INFO - Starting initial data processing
2024-11-14 15:37:45,434 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-11-14 15:37:45,435 - httpx - DEBUG - load_verify_locations cafile='C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\certifi\\cacert.pem'
2024-11-14 15:37:47,809 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-14 15:37:47,810 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-11-14 15:37:47,872 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000208AF0AC890>
2024-11-14 15:37:47,872 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000208AF33CC50> server_hostname='api.openai.com' timeout=5.0
2024-11-14 15:37:47,933 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000208AF366F60>
2024-11-14 15:37:47,933 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-14 15:37:47,933 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-14 15:37:47,933 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-14 15:37:47,933 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-14 15:37:47,933 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-14 15:37:58,352 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 14 Nov 2024 08:37:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'step-up-ognepk'), (b'openai-processing-ms', b'10061'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'448148'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'246ms'), (b'x-request-id', b'req_6632ac1c4c37a63264baaf9815ad8440'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=0l8IeUyLK4.__j.a1TQRX6bFdennt9Zt4EV2lpEv6Go-1731573474-1.0.1.1-g3zU5kJCQuOM7gUe49xRy1CtDPlj5HrBmwHkCzfGHkv3jZPUkM70rQf9xcil2TKLAWt2rDCm9.84iA85fe66Zw; path=/; expires=Thu, 14-Nov-24 09:07:54 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=DKMYnvnyakGTSKgvehpIzuVdmywr_1aF4zs42A8nGxU-1731573474389-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e25ae662e7681ef-SIN'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-14 15:37:58,353 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-14 15:37:58,353 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-14 15:37:58,353 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-14 15:37:58,353 - httpcore.http11 - DEBUG - response_closed.started
2024-11-14 15:37:58,353 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-14 15:37:58,354 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 14 Nov 2024 08:37:54 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'step-up-ognepk'), ('openai-processing-ms', '10061'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '500'), ('x-ratelimit-limit-tokens', '450000'), ('x-ratelimit-remaining-requests', '499'), ('x-ratelimit-remaining-tokens', '448148'), ('x-ratelimit-reset-requests', '120ms'), ('x-ratelimit-reset-tokens', '246ms'), ('x-request-id', 'req_6632ac1c4c37a63264baaf9815ad8440'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=0l8IeUyLK4.__j.a1TQRX6bFdennt9Zt4EV2lpEv6Go-1731573474-1.0.1.1-g3zU5kJCQuOM7gUe49xRy1CtDPlj5HrBmwHkCzfGHkv3jZPUkM70rQf9xcil2TKLAWt2rDCm9.84iA85fe66Zw; path=/; expires=Thu, 14-Nov-24 09:07:54 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=DKMYnvnyakGTSKgvehpIzuVdmywr_1aF4zs42A8nGxU-1731573474389-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8e25ae662e7681ef-SIN'), ('content-encoding', 'br'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-11-14 15:37:58,354 - openai._base_client - DEBUG - request_id: req_6632ac1c4c37a63264baaf9815ad8440
2024-11-14 15:37:58,358 - __main__ - DEBUG - Order 1, Input: 'Topic: talk about your family - Family size and type
Given vocabulary: Nuclear family
Situation: Sarah and Tom, neighbors, at a community park', Response received in 12.92s
2024-11-14 15:37:58,358 - __main__ - DEBUG - Processed row - Order: 1
2024-11-14 15:37:58,366 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-14 15:37:58,367 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-14 15:37:58,367 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-14 15:37:58,367 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-14 15:37:58,367 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-14 15:37:58,367 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-14 15:38:09,413 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 14 Nov 2024 08:38:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'step-up-ognepk'), (b'openai-processing-ms', b'10711'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'448146'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'247ms'), (b'x-request-id', b'req_92d26cb46be7b86eaa819b6ecfc33cde'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e25aea76fd681ef-SIN'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-14 15:38:09,414 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-14 15:38:09,414 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-14 15:38:09,414 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-14 15:38:09,414 - httpcore.http11 - DEBUG - response_closed.started
2024-11-14 15:38:09,415 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-14 15:38:09,415 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 14 Nov 2024 08:38:05 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'step-up-ognepk', 'openai-processing-ms': '10711', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '450000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '448146', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '247ms', 'x-request-id': 'req_92d26cb46be7b86eaa819b6ecfc33cde', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8e25aea76fd681ef-SIN', 'content-encoding': 'br', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-14 15:38:09,415 - openai._base_client - DEBUG - request_id: req_92d26cb46be7b86eaa819b6ecfc33cde
2024-11-14 15:38:09,415 - __main__ - DEBUG - Order 2, Input: 'Topic: talk about your family - Family size and type
Given vocabulary: Generational family
Situation: Aubrey and Isaac, engineers, at a construction site', Response received in 11.05s
2024-11-14 15:38:09,416 - __main__ - DEBUG - Processed row - Order: 2
2024-11-14 15:38:09,471 - __main__ - INFO - Output saved to D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_draft.xlsx
2024-11-14 15:38:09,472 - __main__ - INFO - Starting story data processing
2024-11-14 15:38:09,484 - __main__ - DEBUG - Processing story data for order 1
2024-11-14 15:38:09,484 - __main__ - DEBUG - Processing story data for order 2
2024-11-14 15:38:09,507 - __main__ - INFO - Story data processing complete, saved to D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story.xlsx
2024-11-14 15:38:09,507 - __main__ - INFO - Starting audio generation
2024-11-14 15:38:09,513 - __main__ - DEBUG - Generating audio for order 1
2024-11-14 15:38:09,513 - __main__ - DEBUG - Sending TTS request for order 1, role female_1
2024-11-14 15:38:09,515 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:38:09,527 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:38:10,678 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 135758
2024-11-14 15:38:10,717 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\1\female_1.wav
2024-11-14 15:38:10,718 - __main__ - DEBUG - Sending TTS request for order 1, role male_1
2024-11-14 15:38:10,719 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:38:10,729 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:38:12,331 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 265294
2024-11-14 15:38:12,373 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\1\male_1.wav
2024-11-14 15:38:12,373 - __main__ - DEBUG - Sending TTS request for order 1, role female_2
2024-11-14 15:38:12,375 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:38:12,388 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:38:13,951 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 249422
2024-11-14 15:38:14,002 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\1\female_2.wav
2024-11-14 15:38:14,003 - __main__ - DEBUG - Sending TTS request for order 1, role male_2
2024-11-14 15:38:14,005 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:38:14,020 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:38:16,207 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 331854
2024-11-14 15:38:16,297 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\1\male_2.wav
2024-11-14 15:38:16,298 - __main__ - DEBUG - Generating audio for order 2
2024-11-14 15:38:16,298 - __main__ - DEBUG - Sending TTS request for order 2, role female_1
2024-11-14 15:38:16,299 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:38:16,369 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:38:17,336 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 147022
2024-11-14 15:38:17,364 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\2\female_1.wav
2024-11-14 15:38:17,364 - __main__ - DEBUG - Sending TTS request for order 2, role male_1
2024-11-14 15:38:17,365 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:38:17,380 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:38:18,893 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 244814
2024-11-14 15:38:18,938 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\2\male_1.wav
2024-11-14 15:38:18,939 - __main__ - DEBUG - Sending TTS request for order 2, role female_2
2024-11-14 15:38:18,940 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:38:18,952 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:38:21,174 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 323150
2024-11-14 15:38:21,229 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\2\female_2.wav
2024-11-14 15:38:21,229 - __main__ - DEBUG - Sending TTS request for order 2, role male_2
2024-11-14 15:38:21,230 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:38:21,244 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:38:23,043 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 298574
2024-11-14 15:38:23,096 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\2\male_2.wav
2024-11-14 15:38:23,096 - __main__ - INFO - Audio generation complete
2024-11-14 15:38:23,096 - __main__ - INFO - Processing complete. Final output saved to: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story.xlsx
2024-11-14 15:38:23,165 - httpcore.connection - DEBUG - close.started
2024-11-14 15:38:23,166 - httpcore.connection - DEBUG - close.complete
2024-11-14 15:53:50,751 - __main__ - DEBUG - OpenAI API key loaded: ********************************************************************************************************************************************************************
2024-11-14 15:53:50,751 - __main__ - DEBUG - Upload folder path: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\uploads
2024-11-14 15:53:50,751 - __main__ - DEBUG - Output folder path: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output
2024-11-14 15:53:50,751 - __main__ - INFO - Starting main process
2024-11-14 15:53:50,751 - __main__ - INFO - Starting initial data processing
2024-11-14 15:53:51,065 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-11-14 15:53:51,065 - httpx - DEBUG - load_verify_locations cafile='C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\certifi\\cacert.pem'
2024-11-14 15:53:55,474 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-14 15:53:55,474 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-11-14 15:53:56,620 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EBE0C92060>
2024-11-14 15:53:56,620 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001EBE0F3CC50> server_hostname='api.openai.com' timeout=5.0
2024-11-14 15:53:56,682 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EBE0D89B50>
2024-11-14 15:53:56,682 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-14 15:53:56,682 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-14 15:53:56,682 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-14 15:53:56,682 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-14 15:53:56,683 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-14 15:54:06,000 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 14 Nov 2024 08:54:02 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'step-up-ognepk'), (b'openai-processing-ms', b'8971'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'448148'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'246ms'), (b'x-request-id', b'req_f77ea075b409c221d1adf0d2992d1b8e'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Bt.rLHVCPFFJcPPH9rtap0PoXXvdhkKje3FRiPk4sfM-1731574442-1.0.1.1-f4A61I6d9OBqPKvnV6bm5TiNlqfLyD1CVxUim7sxJ1GZuS1oeWYIxem1o5bwnr3Yqt8sZuyeNn.OYiHSNL1zIQ; path=/; expires=Thu, 14-Nov-24 09:24:02 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=07GH4lYSWA1at.HCmLVzgOaV5PXIpGBF2ZA0wiWhqKQ-1731574442039-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e25c60cec3a4b56-SIN'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-14 15:54:06,001 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-14 15:54:06,001 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-14 15:54:06,001 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-14 15:54:06,001 - httpcore.http11 - DEBUG - response_closed.started
2024-11-14 15:54:06,001 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-14 15:54:06,001 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 14 Nov 2024 08:54:02 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'step-up-ognepk'), ('openai-processing-ms', '8971'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '500'), ('x-ratelimit-limit-tokens', '450000'), ('x-ratelimit-remaining-requests', '499'), ('x-ratelimit-remaining-tokens', '448148'), ('x-ratelimit-reset-requests', '120ms'), ('x-ratelimit-reset-tokens', '246ms'), ('x-request-id', 'req_f77ea075b409c221d1adf0d2992d1b8e'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=Bt.rLHVCPFFJcPPH9rtap0PoXXvdhkKje3FRiPk4sfM-1731574442-1.0.1.1-f4A61I6d9OBqPKvnV6bm5TiNlqfLyD1CVxUim7sxJ1GZuS1oeWYIxem1o5bwnr3Yqt8sZuyeNn.OYiHSNL1zIQ; path=/; expires=Thu, 14-Nov-24 09:24:02 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=07GH4lYSWA1at.HCmLVzgOaV5PXIpGBF2ZA0wiWhqKQ-1731574442039-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8e25c60cec3a4b56-SIN'), ('content-encoding', 'br'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-11-14 15:54:06,002 - openai._base_client - DEBUG - request_id: req_f77ea075b409c221d1adf0d2992d1b8e
2024-11-14 15:54:06,005 - __main__ - DEBUG - Order 1, Input: 'Topic: talk about your family - Family size and type
Given vocabulary: Nuclear family
Situation: Sarah and Tom, neighbors, at a community park', Response received in 14.94s
2024-11-14 15:54:06,006 - __main__ - DEBUG - Processed row - Order: 1
2024-11-14 15:54:06,011 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-14 15:54:06,011 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-14 15:54:06,012 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-14 15:54:06,012 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-14 15:54:06,012 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-14 15:54:06,012 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-14 15:54:14,840 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 14 Nov 2024 08:54:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'step-up-ognepk'), (b'openai-processing-ms', b'8337'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'448146'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'247ms'), (b'x-request-id', b'req_60ebbb698b941c24cd5fb4c820d53653'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e25c6473b344b56-SIN'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-14 15:54:14,841 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-14 15:54:14,841 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-14 15:54:14,842 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-14 15:54:14,842 - httpcore.http11 - DEBUG - response_closed.started
2024-11-14 15:54:14,842 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-14 15:54:14,842 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 14 Nov 2024 08:54:10 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'step-up-ognepk', 'openai-processing-ms': '8337', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '450000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '448146', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '247ms', 'x-request-id': 'req_60ebbb698b941c24cd5fb4c820d53653', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8e25c6473b344b56-SIN', 'content-encoding': 'br', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-14 15:54:14,842 - openai._base_client - DEBUG - request_id: req_60ebbb698b941c24cd5fb4c820d53653
2024-11-14 15:54:14,843 - __main__ - DEBUG - Order 2, Input: 'Topic: talk about your family - Family size and type
Given vocabulary: Generational family
Situation: Aubrey and Isaac, engineers, at a construction site', Response received in 8.84s
2024-11-14 15:54:14,843 - __main__ - DEBUG - Processed row - Order: 2
2024-11-14 15:54:14,921 - __main__ - INFO - Output saved to D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_draft.xlsx
2024-11-14 15:54:14,922 - __main__ - INFO - Starting story data processing
2024-11-14 15:54:14,936 - __main__ - DEBUG - Processing story data for order 1
2024-11-14 15:54:14,937 - __main__ - DEBUG - Processing story data for order 2
2024-11-14 15:54:14,964 - __main__ - INFO - Story data processing complete, saved to D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story.xlsx
2024-11-14 15:54:14,964 - __main__ - INFO - Starting audio generation
2024-11-14 15:54:14,971 - __main__ - DEBUG - Generating audio for order 1
2024-11-14 15:54:14,972 - __main__ - DEBUG - Sending TTS request for order 1, role female_1
2024-11-14 15:54:14,974 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:54:15,056 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:54:16,083 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 153678
2024-11-14 15:54:16,135 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\1\female_1.wav
2024-11-14 15:54:16,135 - __main__ - DEBUG - Sending TTS request for order 1, role male_1
2024-11-14 15:54:16,136 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:54:16,273 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:54:17,759 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 198222
2024-11-14 15:54:17,981 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\1\male_1.wav
2024-11-14 15:54:17,982 - __main__ - DEBUG - Sending TTS request for order 1, role female_2
2024-11-14 15:54:17,983 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:54:18,165 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:54:20,042 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 289358
2024-11-14 15:54:20,091 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\1\female_2.wav
2024-11-14 15:54:20,091 - __main__ - DEBUG - Sending TTS request for order 1, role male_2
2024-11-14 15:54:20,092 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:54:20,103 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:54:21,674 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 254030
2024-11-14 15:54:21,709 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\1\male_2.wav
2024-11-14 15:54:21,710 - __main__ - DEBUG - Generating audio for order 2
2024-11-14 15:54:21,710 - __main__ - DEBUG - Sending TTS request for order 2, role female_1
2024-11-14 15:54:21,711 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:54:21,724 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:54:22,872 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 133710
2024-11-14 15:54:22,910 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\2\female_1.wav
2024-11-14 15:54:22,911 - __main__ - DEBUG - Sending TTS request for order 2, role male_1
2024-11-14 15:54:22,912 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:54:22,924 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:54:24,344 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 224846
2024-11-14 15:54:24,384 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\2\male_1.wav
2024-11-14 15:54:24,384 - __main__ - DEBUG - Sending TTS request for order 2, role female_2
2024-11-14 15:54:24,385 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:54:24,400 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:54:25,812 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 220750
2024-11-14 15:54:25,858 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\2\female_2.wav
2024-11-14 15:54:25,858 - __main__ - DEBUG - Sending TTS request for order 2, role male_2
2024-11-14 15:54:25,860 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 15:54:25,875 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 15:54:27,776 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 307278
2024-11-14 15:54:27,825 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\2\male_2.wav
2024-11-14 15:54:27,826 - __main__ - INFO - Audio generation complete
2024-11-14 15:54:27,826 - __main__ - INFO - Processing complete. Final output saved to: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story.xlsx
2024-11-14 15:54:27,936 - httpcore.connection - DEBUG - close.started
2024-11-14 15:54:27,937 - httpcore.connection - DEBUG - close.complete
2024-11-14 16:14:30,568 - __main__ - DEBUG - OpenAI API key loaded: ********************************************************************************************************************************************************************
2024-11-14 16:14:30,568 - __main__ - DEBUG - Upload folder path: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\uploads
2024-11-14 16:14:30,568 - __main__ - DEBUG - Output folder path: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output
2024-11-14 16:14:30,569 - __main__ - INFO - Starting main process
2024-11-14 16:14:30,569 - __main__ - INFO - Starting initial data processing
2024-11-14 16:14:30,814 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-11-14 16:14:30,815 - httpx - DEBUG - load_verify_locations cafile='C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\certifi\\cacert.pem'
2024-11-14 16:14:31,311 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-14 16:14:31,311 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-11-14 16:14:31,424 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000201534AC830>
2024-11-14 16:14:31,424 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002015375CC50> server_hostname='api.openai.com' timeout=5.0
2024-11-14 16:14:31,483 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000201536E5E50>
2024-11-14 16:14:31,483 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-14 16:14:31,483 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-14 16:14:31,484 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-14 16:14:31,484 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-14 16:14:31,484 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-14 16:14:44,322 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 14 Nov 2024 09:14:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'step-up-ognepk'), (b'openai-processing-ms', b'12142'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'448148'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'246ms'), (b'x-request-id', b'req_278306c311118a751c7f55c096073de8'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=F7CiY1eqi1D1X6kA42UyqVBaa6uAzRUcKpoEaJ0UH.k-1731575680-1.0.1.1-cHaHbUF2tgKsNP8xDEntgCrncgbU.mEkQlIGs7S6T_JQAC6q0YNCTUp.d1H_MA5zm_zek_hGeWbkUZxQzgV3zQ; path=/; expires=Thu, 14-Nov-24 09:44:40 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=M_oj3LUDQg8OF_5dcQVEJBL2OaohZmrQo2M8g2IzkwY-1731575680373-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e25e432784d4026-SIN'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-14 16:14:44,322 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-14 16:14:44,323 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-14 16:14:44,323 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-14 16:14:44,323 - httpcore.http11 - DEBUG - response_closed.started
2024-11-14 16:14:44,323 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-14 16:14:44,323 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 14 Nov 2024 09:14:40 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'step-up-ognepk'), ('openai-processing-ms', '12142'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '500'), ('x-ratelimit-limit-tokens', '450000'), ('x-ratelimit-remaining-requests', '499'), ('x-ratelimit-remaining-tokens', '448148'), ('x-ratelimit-reset-requests', '120ms'), ('x-ratelimit-reset-tokens', '246ms'), ('x-request-id', 'req_278306c311118a751c7f55c096073de8'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=F7CiY1eqi1D1X6kA42UyqVBaa6uAzRUcKpoEaJ0UH.k-1731575680-1.0.1.1-cHaHbUF2tgKsNP8xDEntgCrncgbU.mEkQlIGs7S6T_JQAC6q0YNCTUp.d1H_MA5zm_zek_hGeWbkUZxQzgV3zQ; path=/; expires=Thu, 14-Nov-24 09:44:40 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=M_oj3LUDQg8OF_5dcQVEJBL2OaohZmrQo2M8g2IzkwY-1731575680373-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8e25e432784d4026-SIN'), ('content-encoding', 'br'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-11-14 16:14:44,323 - openai._base_client - DEBUG - request_id: req_278306c311118a751c7f55c096073de8
2024-11-14 16:14:44,327 - __main__ - DEBUG - Order 1, Input: 'Topic: talk about your family - Family size and type
Given vocabulary: Nuclear family
Situation: Sarah and Tom, neighbors, at a community park', Response received in 13.51s
2024-11-14 16:14:44,327 - __main__ - DEBUG - Processed row - Order: 1
2024-11-14 16:14:44,333 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-14 16:14:44,333 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-14 16:14:44,333 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-14 16:14:44,333 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-14 16:14:44,333 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-14 16:14:44,334 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-14 16:14:55,482 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 14 Nov 2024 09:14:51 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'step-up-ognepk'), (b'openai-processing-ms', b'10714'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'448146'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'247ms'), (b'x-request-id', b'req_b7cacfd69e93e306114142d378c32ec8'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e25e482c8b84026-SIN'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-14 16:14:55,483 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-14 16:14:55,483 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-14 16:14:55,483 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-14 16:14:55,484 - httpcore.http11 - DEBUG - response_closed.started
2024-11-14 16:14:55,484 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-14 16:14:55,484 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 14 Nov 2024 09:14:51 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'step-up-ognepk', 'openai-processing-ms': '10714', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '450000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '448146', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '247ms', 'x-request-id': 'req_b7cacfd69e93e306114142d378c32ec8', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8e25e482c8b84026-SIN', 'content-encoding': 'br', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-14 16:14:55,484 - openai._base_client - DEBUG - request_id: req_b7cacfd69e93e306114142d378c32ec8
2024-11-14 16:14:55,485 - __main__ - DEBUG - Order 2, Input: 'Topic: talk about your family - Family size and type
Given vocabulary: Generational family
Situation: Aubrey and Isaac, engineers, at a construction site', Response received in 11.16s
2024-11-14 16:14:55,485 - __main__ - DEBUG - Processed row - Order: 2
2024-11-14 16:14:55,565 - __main__ - INFO - Output saved to D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_draft.xlsx
2024-11-14 16:14:55,565 - __main__ - INFO - Starting story data processing
2024-11-14 16:14:55,578 - __main__ - DEBUG - Processing story data for order 1
2024-11-14 16:14:55,578 - __main__ - DEBUG - Processing story data for order 2
2024-11-14 16:14:55,608 - __main__ - INFO - Story data processing complete, saved to D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story.xlsx
2024-11-14 16:14:55,608 - __main__ - INFO - Starting audio generation
2024-11-14 16:14:55,614 - __main__ - DEBUG - Generating audio for order 1
2024-11-14 16:14:55,615 - __main__ - DEBUG - Sending TTS request for order 1, role female_1
2024-11-14 16:14:55,617 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 16:14:55,635 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 16:14:56,642 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 147022
2024-11-14 16:14:56,673 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\1\female_1.wav
2024-11-14 16:14:56,673 - __main__ - DEBUG - Sending TTS request for order 1, role male_1
2024-11-14 16:14:56,674 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 16:14:56,690 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 16:14:58,002 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 204878
2024-11-14 16:14:58,047 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\1\male_1.wav
2024-11-14 16:14:58,048 - __main__ - DEBUG - Sending TTS request for order 1, role female_2
2024-11-14 16:14:58,049 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 16:14:58,070 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 16:14:59,710 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 267342
2024-11-14 16:14:59,758 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\1\female_2.wav
2024-11-14 16:14:59,759 - __main__ - DEBUG - Sending TTS request for order 1, role male_2
2024-11-14 16:14:59,760 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 16:14:59,773 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 16:15:01,340 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 251470
2024-11-14 16:15:01,388 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\1\male_2.wav
2024-11-14 16:15:01,389 - __main__ - DEBUG - Generating audio for order 2
2024-11-14 16:15:01,389 - __main__ - DEBUG - Sending TTS request for order 2, role female_1
2024-11-14 16:15:01,391 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 16:15:01,408 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 16:15:02,799 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 224846
2024-11-14 16:15:02,846 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\2\female_1.wav
2024-11-14 16:15:02,846 - __main__ - DEBUG - Sending TTS request for order 2, role male_1
2024-11-14 16:15:02,847 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 16:15:02,862 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 16:15:03,970 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 175694
2024-11-14 16:15:04,002 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\2\male_1.wav
2024-11-14 16:15:04,003 - __main__ - DEBUG - Sending TTS request for order 2, role female_2
2024-11-14 16:15:04,004 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 16:15:04,020 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 16:15:06,693 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 405582
2024-11-14 16:15:06,765 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\2\female_2.wav
2024-11-14 16:15:06,766 - __main__ - DEBUG - Sending TTS request for order 2, role male_2
2024-11-14 16:15:06,768 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 16:15:06,785 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 16:15:08,926 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 313934
2024-11-14 16:15:09,001 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\2\male_2.wav
2024-11-14 16:15:09,001 - __main__ - INFO - Audio generation complete
2024-11-14 16:15:09,001 - __main__ - INFO - Processing complete. Final output saved to: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story.xlsx
2024-11-14 16:15:09,067 - httpcore.connection - DEBUG - close.started
2024-11-14 16:15:09,067 - httpcore.connection - DEBUG - close.complete
2024-11-14 16:40:21,675 - __main__ - DEBUG - OpenAI API key loaded: ********************************************************************************************************************************************************************
2024-11-14 16:40:21,676 - __main__ - DEBUG - Upload folder path: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\uploads
2024-11-14 16:40:21,676 - __main__ - DEBUG - Output folder path: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output
2024-11-14 16:40:21,676 - __main__ - INFO - Starting main process
2024-11-14 16:40:21,676 - __main__ - INFO - Starting initial data processing
2024-11-14 16:40:21,992 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-11-14 16:40:21,993 - httpx - DEBUG - load_verify_locations cafile='C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\certifi\\cacert.pem'
2024-11-14 16:40:22,600 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-14 16:40:22,600 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-11-14 16:40:23,024 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256C2B644A0>
2024-11-14 16:40:23,024 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256C2B3CC50> server_hostname='api.openai.com' timeout=5.0
2024-11-14 16:40:23,097 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000256C2B67860>
2024-11-14 16:40:23,098 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-14 16:40:23,098 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-14 16:40:23,098 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-14 16:40:23,098 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-14 16:40:23,098 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-14 16:40:34,123 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 14 Nov 2024 09:40:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'step-up-ognepk'), (b'openai-processing-ms', b'10510'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'448148'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'246ms'), (b'x-request-id', b'req_03397b9f86c51ea99e48b17334cbd646'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=R.f_Esn5eXjXa6S41QYtmduBkual.w.mHaYhMVzRKJs-1731577230-1.0.1.1-plaMfu432.HLtvHVYuXMtFP1SQRiTTWCMGBHux_8ENDivUuSUI7UO2ZmqNdG4u9xdasDSrvXM2Y9LWxUxnPcyQ; path=/; expires=Thu, 14-Nov-24 10:10:30 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=1bs8O6Mj48izxNsrRA8a2ytE5xCtx__.E9AWmzTeHiM-1731577230179-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e260a141e89405a-SIN'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-14 16:40:34,124 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-14 16:40:34,124 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-14 16:40:34,124 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-14 16:40:34,124 - httpcore.http11 - DEBUG - response_closed.started
2024-11-14 16:40:34,124 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-14 16:40:34,125 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 14 Nov 2024 09:40:30 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'step-up-ognepk'), ('openai-processing-ms', '10510'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '500'), ('x-ratelimit-limit-tokens', '450000'), ('x-ratelimit-remaining-requests', '499'), ('x-ratelimit-remaining-tokens', '448148'), ('x-ratelimit-reset-requests', '120ms'), ('x-ratelimit-reset-tokens', '246ms'), ('x-request-id', 'req_03397b9f86c51ea99e48b17334cbd646'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=R.f_Esn5eXjXa6S41QYtmduBkual.w.mHaYhMVzRKJs-1731577230-1.0.1.1-plaMfu432.HLtvHVYuXMtFP1SQRiTTWCMGBHux_8ENDivUuSUI7UO2ZmqNdG4u9xdasDSrvXM2Y9LWxUxnPcyQ; path=/; expires=Thu, 14-Nov-24 10:10:30 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=1bs8O6Mj48izxNsrRA8a2ytE5xCtx__.E9AWmzTeHiM-1731577230179-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8e260a141e89405a-SIN'), ('content-encoding', 'br'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-11-14 16:40:34,125 - openai._base_client - DEBUG - request_id: req_03397b9f86c51ea99e48b17334cbd646
2024-11-14 16:40:34,129 - __main__ - DEBUG - Order 1, Input: 'Topic: talk about your family - Family size and type
Given vocabulary: Nuclear family
Situation: Sarah and Tom, neighbors, at a community park', Response received in 12.14s
2024-11-14 16:40:34,129 - __main__ - DEBUG - Processed row - Order: 1
2024-11-14 16:40:34,134 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-14 16:40:34,135 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-14 16:40:34,135 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-14 16:40:34,135 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-14 16:40:34,135 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-14 16:40:34,135 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-14 16:40:43,114 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 14 Nov 2024 09:40:39 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'step-up-ognepk'), (b'openai-processing-ms', b'8632'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'448146'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'247ms'), (b'x-request-id', b'req_48e23b0f7f084d2618f9c6d0794d2fba'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e260a5919d0405a-SIN'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-14 16:40:43,115 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-14 16:40:43,115 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-14 16:40:43,115 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-14 16:40:43,116 - httpcore.http11 - DEBUG - response_closed.started
2024-11-14 16:40:43,116 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-14 16:40:43,116 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 14 Nov 2024 09:40:39 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'step-up-ognepk', 'openai-processing-ms': '8632', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '450000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '448146', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '247ms', 'x-request-id': 'req_48e23b0f7f084d2618f9c6d0794d2fba', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8e260a5919d0405a-SIN', 'content-encoding': 'br', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-14 16:40:43,116 - openai._base_client - DEBUG - request_id: req_48e23b0f7f084d2618f9c6d0794d2fba
2024-11-14 16:40:43,116 - __main__ - DEBUG - Order 2, Input: 'Topic: talk about your family - Family size and type
Given vocabulary: Generational family
Situation: Aubrey and Isaac, engineers, at a construction site', Response received in 8.99s
2024-11-14 16:40:43,116 - __main__ - DEBUG - Processed row - Order: 2
2024-11-14 16:40:43,183 - __main__ - INFO - Output saved to D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_draft.xlsx
2024-11-14 16:40:43,184 - __main__ - INFO - Starting story data processing
2024-11-14 16:40:43,197 - __main__ - DEBUG - Processing story data for order 1
2024-11-14 16:40:43,197 - __main__ - DEBUG - Processing story data for order 2
2024-11-14 16:40:43,221 - __main__ - INFO - Story data processing complete, saved to D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story.xlsx
2024-11-14 16:40:43,222 - __main__ - INFO - Starting audio generation
2024-11-14 16:40:43,228 - __main__ - DEBUG - Generating audio for order 1
2024-11-14 16:40:43,228 - __main__ - DEBUG - Sending TTS request for order 1, role female_1
2024-11-14 16:40:43,230 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 16:40:43,241 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 16:40:44,213 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 147022
2024-11-14 16:40:44,245 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\1\female_1.wav
2024-11-14 16:40:44,245 - __main__ - DEBUG - Sending TTS request for order 1, role male_1
2024-11-14 16:40:44,246 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 16:40:44,257 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 16:40:45,400 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 171598
2024-11-14 16:40:45,529 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\1\male_1.wav
2024-11-14 16:40:45,529 - __main__ - DEBUG - Sending TTS request for order 1, role female_2
2024-11-14 16:40:45,530 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 16:40:45,549 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 16:40:46,890 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 211534
2024-11-14 16:40:46,927 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\1\female_2.wav
2024-11-14 16:40:46,927 - __main__ - DEBUG - Sending TTS request for order 1, role male_2
2024-11-14 16:40:46,929 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 16:40:46,940 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 16:40:48,343 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 224846
2024-11-14 16:40:48,379 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\1\male_2.wav
2024-11-14 16:40:48,379 - __main__ - DEBUG - Generating audio for order 2
2024-11-14 16:40:48,379 - __main__ - DEBUG - Sending TTS request for order 2, role female_1
2024-11-14 16:40:48,380 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 16:40:48,394 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 16:40:49,727 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 213582
2024-11-14 16:40:49,762 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\2\female_1.wav
2024-11-14 16:40:49,762 - __main__ - DEBUG - Sending TTS request for order 2, role male_1
2024-11-14 16:40:49,763 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 16:40:49,775 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 16:40:50,686 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 133710
2024-11-14 16:40:50,710 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\2\male_1.wav
2024-11-14 16:40:50,710 - __main__ - DEBUG - Sending TTS request for order 2, role female_2
2024-11-14 16:40:50,711 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 16:40:50,722 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 16:40:53,159 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 372302
2024-11-14 16:40:53,216 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\2\female_2.wav
2024-11-14 16:40:53,217 - __main__ - DEBUG - Sending TTS request for order 2, role male_2
2024-11-14 16:40:53,218 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 16:40:53,231 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 16:40:54,761 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 244814
2024-11-14 16:40:54,807 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\2\male_2.wav
2024-11-14 16:40:54,807 - __main__ - INFO - Audio generation complete
2024-11-14 16:40:54,807 - __main__ - INFO - Processing complete. Final output saved to: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story.xlsx
2024-11-14 16:40:54,874 - httpcore.connection - DEBUG - close.started
2024-11-14 16:40:54,875 - httpcore.connection - DEBUG - close.complete
2024-11-14 16:49:39,415 - __main__ - DEBUG - OpenAI API key loaded: ********************************************************************************************************************************************************************
2024-11-14 16:49:39,415 - __main__ - DEBUG - Upload folder path: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\uploads
2024-11-14 16:49:39,416 - __main__ - DEBUG - Output folder path: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output
2024-11-14 16:49:39,416 - __main__ - INFO - Starting main process
2024-11-14 16:49:39,416 - __main__ - INFO - Starting initial data processing
2024-11-14 16:49:39,874 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-11-14 16:49:39,875 - httpx - DEBUG - load_verify_locations cafile='C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\certifi\\cacert.pem'
2024-11-14 16:49:40,575 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-14 16:49:40,575 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-11-14 16:49:40,720 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001BDE64A4830>
2024-11-14 16:49:40,720 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001BDE675CC50> server_hostname='api.openai.com' timeout=5.0
2024-11-14 16:49:40,796 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001BDE64AF920>
2024-11-14 16:49:40,815 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-14 16:49:40,816 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-14 16:49:40,816 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-14 16:49:40,816 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-14 16:49:40,816 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-14 16:49:52,734 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 14 Nov 2024 09:49:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'step-up-ognepk'), (b'openai-processing-ms', b'11539'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'448148'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'246ms'), (b'x-request-id', b'req_cf8f1e1aa769889eccc672aa5d007532'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=tWezjC3LFms.riqsOKPpVrrUsz_pt3FruJw2J4wXTrk-1731577788-1.0.1.1-MKzR.wysMq0UIvMgnWu7fu_6BJw6RF7O3jnFIXpGJGjUF8qw.LLXBky9CHRb1Zp12fQ31j2gqHaxdMOk9kwWLw; path=/; expires=Thu, 14-Nov-24 10:19:48 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=gxRwMkHZ9yoyDvDYnvp1ZlVhws8EExAW.Ko.pIA33vs-1731577788758-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e2617b1df65a8e1-SIN'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-14 16:49:52,737 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-14 16:49:52,737 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-14 16:49:52,738 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-14 16:49:52,738 - httpcore.http11 - DEBUG - response_closed.started
2024-11-14 16:49:52,738 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-14 16:49:52,738 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 14 Nov 2024 09:49:48 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'step-up-ognepk'), ('openai-processing-ms', '11539'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '500'), ('x-ratelimit-limit-tokens', '450000'), ('x-ratelimit-remaining-requests', '499'), ('x-ratelimit-remaining-tokens', '448148'), ('x-ratelimit-reset-requests', '120ms'), ('x-ratelimit-reset-tokens', '246ms'), ('x-request-id', 'req_cf8f1e1aa769889eccc672aa5d007532'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=tWezjC3LFms.riqsOKPpVrrUsz_pt3FruJw2J4wXTrk-1731577788-1.0.1.1-MKzR.wysMq0UIvMgnWu7fu_6BJw6RF7O3jnFIXpGJGjUF8qw.LLXBky9CHRb1Zp12fQ31j2gqHaxdMOk9kwWLw; path=/; expires=Thu, 14-Nov-24 10:19:48 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=gxRwMkHZ9yoyDvDYnvp1ZlVhws8EExAW.Ko.pIA33vs-1731577788758-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8e2617b1df65a8e1-SIN'), ('content-encoding', 'br'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-11-14 16:49:52,739 - openai._base_client - DEBUG - request_id: req_cf8f1e1aa769889eccc672aa5d007532
2024-11-14 16:49:52,745 - __main__ - DEBUG - Order 1, Input: 'Topic: talk about your family - Family size and type
Given vocabulary: Nuclear family
Situation: Sarah and Tom, neighbors, at a community park', Response received in 12.87s
2024-11-14 16:49:52,745 - __main__ - DEBUG - Processed row - Order: 1
2024-11-14 16:49:52,758 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-14 16:49:52,758 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-14 16:49:52,759 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-14 16:49:52,759 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-14 16:49:52,760 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-14 16:49:52,760 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-14 16:50:06,693 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 14 Nov 2024 09:50:02 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'step-up-ognepk'), (b'openai-processing-ms', b'13583'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'448146'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'247ms'), (b'x-request-id', b'req_4677d5941391c32f076b017b0fda25c4'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e2617fc8e19a8e1-SIN'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-14 16:50:06,694 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-14 16:50:06,694 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-14 16:50:06,694 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-14 16:50:06,695 - httpcore.http11 - DEBUG - response_closed.started
2024-11-14 16:50:06,695 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-14 16:50:06,695 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 14 Nov 2024 09:50:02 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'step-up-ognepk', 'openai-processing-ms': '13583', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '450000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '448146', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '247ms', 'x-request-id': 'req_4677d5941391c32f076b017b0fda25c4', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8e2617fc8e19a8e1-SIN', 'content-encoding': 'br', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-14 16:50:06,695 - openai._base_client - DEBUG - request_id: req_4677d5941391c32f076b017b0fda25c4
2024-11-14 16:50:06,696 - __main__ - DEBUG - Order 2, Input: 'Topic: talk about your family - Family size and type
Given vocabulary: Generational family
Situation: Aubrey and Isaac, engineers, at a construction site', Response received in 13.95s
2024-11-14 16:50:06,696 - __main__ - DEBUG - Processed row - Order: 2
2024-11-14 16:50:06,801 - __main__ - INFO - Output saved to D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_draft.xlsx
2024-11-14 16:50:06,801 - __main__ - INFO - Starting story data processing
2024-11-14 16:50:06,823 - __main__ - DEBUG - Processing story data for order 1
2024-11-14 16:50:06,823 - __main__ - DEBUG - Processing story data for order 2
2024-11-14 16:50:06,877 - __main__ - INFO - Story data processing complete, saved to D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story.xlsx
2024-11-14 16:50:06,878 - __main__ - INFO - Starting audio generation
2024-11-14 16:50:06,895 - __main__ - DEBUG - Generating audio for order 1
2024-11-14 16:50:06,895 - __main__ - DEBUG - Sending TTS request for order 1, role female_1
2024-11-14 16:50:06,900 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 16:50:06,916 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 16:50:08,164 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 175694
2024-11-14 16:50:08,200 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\1\female_1.wav
2024-11-14 16:50:08,200 - __main__ - DEBUG - Sending TTS request for order 1, role male_1
2024-11-14 16:50:08,202 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 16:50:08,214 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 16:50:09,574 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 180302
2024-11-14 16:50:09,615 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\1\male_1.wav
2024-11-14 16:50:09,615 - __main__ - DEBUG - Sending TTS request for order 1, role female_2
2024-11-14 16:50:09,618 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 16:50:09,642 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 16:50:10,938 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 211534
2024-11-14 16:50:10,998 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\1\female_2.wav
2024-11-14 16:50:10,998 - __main__ - DEBUG - Sending TTS request for order 1, role male_2
2024-11-14 16:50:11,001 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 16:50:11,015 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 16:50:12,567 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 224846
2024-11-14 16:50:12,608 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\1\male_2.wav
2024-11-14 16:50:12,609 - __main__ - DEBUG - Generating audio for order 2
2024-11-14 16:50:12,609 - __main__ - DEBUG - Sending TTS request for order 2, role female_1
2024-11-14 16:50:12,610 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 16:50:12,624 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 16:50:13,876 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 158286
2024-11-14 16:50:13,919 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\2\female_1.wav
2024-11-14 16:50:13,919 - __main__ - DEBUG - Sending TTS request for order 2, role male_1
2024-11-14 16:50:13,921 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 16:50:13,933 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 16:50:15,199 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 186958
2024-11-14 16:50:15,233 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\2\male_1.wav
2024-11-14 16:50:15,233 - __main__ - DEBUG - Sending TTS request for order 2, role female_2
2024-11-14 16:50:15,235 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 16:50:15,251 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 16:50:17,061 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 298574
2024-11-14 16:50:17,110 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\2\female_2.wav
2024-11-14 16:50:17,110 - __main__ - DEBUG - Sending TTS request for order 2, role male_2
2024-11-14 16:50:17,112 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 16:50:17,123 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 16:50:19,408 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 329806
2024-11-14 16:50:19,458 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\2\male_2.wav
2024-11-14 16:50:19,458 - __main__ - INFO - Audio generation complete
2024-11-14 16:50:19,459 - __main__ - INFO - Processing complete. Final output saved to: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story.xlsx
2024-11-14 16:50:19,555 - httpcore.connection - DEBUG - close.started
2024-11-14 16:50:19,556 - httpcore.connection - DEBUG - close.complete
2024-11-14 16:57:01,159 - __main__ - DEBUG - OpenAI API key loaded: ********************************************************************************************************************************************************************
2024-11-14 16:57:01,160 - __main__ - DEBUG - Upload folder path: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\uploads
2024-11-14 16:57:01,160 - __main__ - DEBUG - Output folder path: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output
2024-11-14 16:57:01,160 - __main__ - INFO - Starting main process
2024-11-14 16:57:01,160 - __main__ - INFO - Starting initial data processing
2024-11-14 16:57:01,574 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-11-14 16:57:01,575 - httpx - DEBUG - load_verify_locations cafile='C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\certifi\\cacert.pem'
2024-11-14 16:57:02,446 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-14 16:57:02,447 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-11-14 16:57:02,574 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001FBB4267B90>
2024-11-14 16:57:02,574 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001FBB423CC50> server_hostname='api.openai.com' timeout=5.0
2024-11-14 16:57:02,651 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001FBB3FA6750>
2024-11-14 16:57:02,651 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-14 16:57:02,652 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-14 16:57:02,652 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-14 16:57:02,652 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-14 16:57:02,653 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-14 16:57:15,526 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 14 Nov 2024 09:57:11 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'step-up-ognepk'), (b'openai-processing-ms', b'11962'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'448148'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'246ms'), (b'x-request-id', b'req_414671a1585bc40e6bd771b4a8ad0a50'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=NhdO4nEP2s_uOBx5ioqVZkTp5u84IMaSyhHXxD6kbbs-1731578231-1.0.1.1-MAsblV0aTzBuug0K4j.n.DE3XoDRQfJXJ_kaFCaeo9V53mN4jW2W7ptCDBEfiKO4S9A9oMcSZ5QlK8GQ.DQQ8g; path=/; expires=Thu, 14-Nov-24 10:27:11 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=6ZsBSP9C9J_tIdvksRa79sWth3.WP2rRYFw3590WY9g-1731578231592-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e26227b5b97ce5d-SIN'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-14 16:57:15,527 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-14 16:57:15,528 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-14 16:57:15,528 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-14 16:57:15,528 - httpcore.http11 - DEBUG - response_closed.started
2024-11-14 16:57:15,528 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-14 16:57:15,529 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 14 Nov 2024 09:57:11 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'step-up-ognepk'), ('openai-processing-ms', '11962'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '500'), ('x-ratelimit-limit-tokens', '450000'), ('x-ratelimit-remaining-requests', '499'), ('x-ratelimit-remaining-tokens', '448148'), ('x-ratelimit-reset-requests', '120ms'), ('x-ratelimit-reset-tokens', '246ms'), ('x-request-id', 'req_414671a1585bc40e6bd771b4a8ad0a50'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=NhdO4nEP2s_uOBx5ioqVZkTp5u84IMaSyhHXxD6kbbs-1731578231-1.0.1.1-MAsblV0aTzBuug0K4j.n.DE3XoDRQfJXJ_kaFCaeo9V53mN4jW2W7ptCDBEfiKO4S9A9oMcSZ5QlK8GQ.DQQ8g; path=/; expires=Thu, 14-Nov-24 10:27:11 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=6ZsBSP9C9J_tIdvksRa79sWth3.WP2rRYFw3590WY9g-1731578231592-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8e26227b5b97ce5d-SIN'), ('content-encoding', 'br'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-11-14 16:57:15,529 - openai._base_client - DEBUG - request_id: req_414671a1585bc40e6bd771b4a8ad0a50
2024-11-14 16:57:15,535 - __main__ - DEBUG - Order 1, Input: 'Topic: talk about your family - Family size and type
Given vocabulary: Nuclear family
Situation: Sarah and Tom, neighbors, at a community park', Response received in 13.96s
2024-11-14 16:57:15,535 - __main__ - DEBUG - Processed row - Order: 1
2024-11-14 16:57:15,547 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-14 16:57:15,548 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-14 16:57:15,548 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-14 16:57:15,548 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-14 16:57:15,549 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-14 16:57:15,549 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-14 16:57:35,890 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 14 Nov 2024 09:57:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'step-up-ognepk'), (b'openai-processing-ms', b'19808'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'448146'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'247ms'), (b'x-request-id', b'req_e24d450407d71653d621cb90a1b5c6c1'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e2622cbf9fece5d-SIN'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-14 16:57:35,891 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-14 16:57:35,891 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-14 16:57:35,892 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-14 16:57:35,892 - httpcore.http11 - DEBUG - response_closed.started
2024-11-14 16:57:35,893 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-14 16:57:35,893 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 14 Nov 2024 09:57:31 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'step-up-ognepk', 'openai-processing-ms': '19808', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '450000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '448146', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '247ms', 'x-request-id': 'req_e24d450407d71653d621cb90a1b5c6c1', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8e2622cbf9fece5d-SIN', 'content-encoding': 'br', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-14 16:57:35,893 - openai._base_client - DEBUG - request_id: req_e24d450407d71653d621cb90a1b5c6c1
2024-11-14 16:57:35,894 - __main__ - DEBUG - Order 2, Input: 'Topic: talk about your family - Family size and type
Given vocabulary: Generational family
Situation: Aubrey and Isaac, engineers, at a construction site', Response received in 20.36s
2024-11-14 16:57:35,894 - __main__ - DEBUG - Processed row - Order: 2
2024-11-14 16:57:35,999 - __main__ - INFO - Output saved to D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_draft.xlsx
2024-11-14 16:57:35,999 - __main__ - INFO - Starting story data processing
2024-11-14 16:57:36,023 - __main__ - DEBUG - Processing story data for order 1
2024-11-14 16:57:36,024 - __main__ - DEBUG - Processing story data for order 2
2024-11-14 16:57:36,104 - __main__ - INFO - Story data processing complete, saved to D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story.xlsx
2024-11-14 16:57:36,104 - __main__ - INFO - Starting audio generation
2024-11-14 16:57:36,116 - __main__ - DEBUG - Generating audio for order 1
2024-11-14 16:57:36,116 - __main__ - DEBUG - Sending TTS request for order 1, role female_1
2024-11-14 16:57:36,119 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 16:57:36,160 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 16:57:37,270 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 166990
2024-11-14 16:57:37,306 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\1\female_1.wav
2024-11-14 16:57:37,306 - __main__ - DEBUG - Sending TTS request for order 1, role male_1
2024-11-14 16:57:37,308 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 16:57:37,320 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 16:57:38,939 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 254030
2024-11-14 16:57:39,007 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\1\male_1.wav
2024-11-14 16:57:39,008 - __main__ - DEBUG - Sending TTS request for order 1, role female_2
2024-11-14 16:57:39,009 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 16:57:39,022 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 16:57:40,369 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 216142
2024-11-14 16:57:40,407 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\1\female_2.wav
2024-11-14 16:57:40,408 - __main__ - DEBUG - Sending TTS request for order 1, role male_2
2024-11-14 16:57:40,410 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 16:57:40,422 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 16:57:44,888 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 726606
2024-11-14 16:57:45,027 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\1\male_2.wav
2024-11-14 16:57:45,028 - __main__ - DEBUG - Generating audio for order 2
2024-11-14 16:57:45,028 - __main__ - DEBUG - Sending TTS request for order 2, role female_1
2024-11-14 16:57:45,029 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 16:57:45,042 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 16:57:46,062 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 158286
2024-11-14 16:57:46,091 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\2\female_1.wav
2024-11-14 16:57:46,091 - __main__ - DEBUG - Sending TTS request for order 2, role male_1
2024-11-14 16:57:46,093 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 16:57:46,127 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 16:57:47,385 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 196174
2024-11-14 16:57:47,422 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\2\male_1.wav
2024-11-14 16:57:47,422 - __main__ - DEBUG - Sending TTS request for order 2, role female_2
2024-11-14 16:57:47,424 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 16:57:47,437 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 16:57:49,297 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 305230
2024-11-14 16:57:49,378 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\2\female_2.wav
2024-11-14 16:57:49,379 - __main__ - DEBUG - Sending TTS request for order 2, role male_2
2024-11-14 16:57:49,381 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 16:57:49,398 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 16:57:51,076 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 282702
2024-11-14 16:57:51,129 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story_audio\2\male_2.wav
2024-11-14 16:57:51,130 - __main__ - INFO - Audio generation complete
2024-11-14 16:57:51,131 - __main__ - INFO - Processing complete. Final output saved to: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story.xlsx
2024-11-14 16:57:51,256 - httpcore.connection - DEBUG - close.started
2024-11-14 16:57:51,257 - httpcore.connection - DEBUG - close.complete
2024-11-14 17:14:32,409 - __main__ - DEBUG - OpenAI API key loaded: ********************************************************************************************************************************************************************
2024-11-14 17:14:32,410 - __main__ - DEBUG - Upload folder path: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\uploads
2024-11-14 17:14:32,410 - __main__ - DEBUG - Output folder path: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output
2024-11-14 17:14:32,410 - __main__ - INFO - Starting main process
2024-11-14 17:14:32,410 - __main__ - INFO - Starting initial data processing
2024-11-14 17:14:32,900 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-11-14 17:14:32,901 - httpx - DEBUG - load_verify_locations cafile='C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\certifi\\cacert.pem'
2024-11-14 17:14:33,823 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-14 17:14:33,823 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-11-14 17:14:33,939 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001CFEFD93AD0>
2024-11-14 17:14:33,939 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001CFF003CC50> server_hostname='api.openai.com' timeout=5.0
2024-11-14 17:14:34,006 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001CFF00A4EF0>
2024-11-14 17:14:34,007 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-14 17:14:34,008 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-14 17:14:34,008 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-14 17:14:34,008 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-14 17:14:34,008 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-14 17:14:45,248 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 14 Nov 2024 10:14:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'step-up-ognepk'), (b'openai-processing-ms', b'10891'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'448148'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'246ms'), (b'x-request-id', b'req_c4dbcf915b8def88e4cebfe156f78f32'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=q0EWnFqWXduahm1JP.dJ2bbB4YNHLJZF8I2XFA8yGs0-1731579281-1.0.1.1-q3DMB4EFfWDnoqwTYH_mKqEUmVYCI4KuZcyKet0fPdVGnojfS5jJdwsi7J1gQ8LWQCjC2tg764j.dIR.QPq_5Q; path=/; expires=Thu, 14-Nov-24 10:44:41 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=DtUtxR72QxD0_ekY_y5RIAS6zyo.Yycee7iH6wW7AGo-1731579281318-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e263c265bfe821f-SIN'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-14 17:14:45,250 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-14 17:14:45,250 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-14 17:14:45,251 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-14 17:14:45,251 - httpcore.http11 - DEBUG - response_closed.started
2024-11-14 17:14:45,251 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-14 17:14:45,252 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 14 Nov 2024 10:14:41 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'step-up-ognepk'), ('openai-processing-ms', '10891'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '500'), ('x-ratelimit-limit-tokens', '450000'), ('x-ratelimit-remaining-requests', '499'), ('x-ratelimit-remaining-tokens', '448148'), ('x-ratelimit-reset-requests', '120ms'), ('x-ratelimit-reset-tokens', '246ms'), ('x-request-id', 'req_c4dbcf915b8def88e4cebfe156f78f32'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=q0EWnFqWXduahm1JP.dJ2bbB4YNHLJZF8I2XFA8yGs0-1731579281-1.0.1.1-q3DMB4EFfWDnoqwTYH_mKqEUmVYCI4KuZcyKet0fPdVGnojfS5jJdwsi7J1gQ8LWQCjC2tg764j.dIR.QPq_5Q; path=/; expires=Thu, 14-Nov-24 10:44:41 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=DtUtxR72QxD0_ekY_y5RIAS6zyo.Yycee7iH6wW7AGo-1731579281318-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8e263c265bfe821f-SIN'), ('content-encoding', 'br'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-11-14 17:14:45,252 - openai._base_client - DEBUG - request_id: req_c4dbcf915b8def88e4cebfe156f78f32
2024-11-14 17:14:45,264 - __main__ - DEBUG - Order 1, Input: 'Topic: talk about your family - Family size and type
Given vocabulary: Nuclear family
Situation: Sarah and Tom, neighbors, at a community park', Response received in 12.36s
2024-11-14 17:14:45,264 - __main__ - DEBUG - Processed row - Order: 1
2024-11-14 17:14:45,278 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-14 17:14:45,279 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-14 17:14:45,280 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-14 17:14:45,281 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-14 17:14:45,281 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-14 17:14:45,281 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-14 17:14:57,364 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 14 Nov 2024 10:14:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'step-up-ognepk'), (b'openai-processing-ms', b'11612'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'448146'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'247ms'), (b'x-request-id', b'req_a580cfee7d11f0f0843e2306e0ab07f7'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e263c6cdd70821f-SIN'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-14 17:14:57,365 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-14 17:14:57,365 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-14 17:14:57,366 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-14 17:14:57,366 - httpcore.http11 - DEBUG - response_closed.started
2024-11-14 17:14:57,366 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-14 17:14:57,366 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 14 Nov 2024 10:14:53 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'step-up-ognepk', 'openai-processing-ms': '11612', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '450000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '448146', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '247ms', 'x-request-id': 'req_a580cfee7d11f0f0843e2306e0ab07f7', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8e263c6cdd70821f-SIN', 'content-encoding': 'br', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-14 17:14:57,368 - openai._base_client - DEBUG - request_id: req_a580cfee7d11f0f0843e2306e0ab07f7
2024-11-14 17:14:57,369 - __main__ - DEBUG - Order 2, Input: 'Topic: talk about your family - Family size and type
Given vocabulary: Generational family
Situation: Aubrey and Isaac, engineers, at a construction site', Response received in 12.10s
2024-11-14 17:14:57,369 - __main__ - DEBUG - Processed row - Order: 2
2024-11-14 17:14:57,554 - __main__ - INFO - Output saved to D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_draft.xlsx
2024-11-14 17:14:57,555 - __main__ - INFO - Starting story data processing
2024-11-14 17:14:57,584 - __main__ - DEBUG - Processing story data for order 1
2024-11-14 17:14:57,585 - __main__ - DEBUG - Processing story data for order 2
2024-11-14 17:14:57,668 - __main__ - INFO - Story data processing complete, saved to D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story.xlsx
2024-11-14 17:14:57,668 - __main__ - INFO - Starting audio generation
2024-11-14 17:14:57,687 - __main__ - DEBUG - Generating audio for order 1
2024-11-14 17:14:57,688 - __main__ - DEBUG - Sending TTS request for order 1, role female_1
2024-11-14 17:14:57,694 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 17:14:57,879 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 17:14:58,798 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 133710
2024-11-14 17:14:58,892 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_audio\1\female_1.wav
2024-11-14 17:14:58,893 - __main__ - DEBUG - Sending TTS request for order 1, role male_1
2024-11-14 17:14:58,895 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 17:14:58,911 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 17:14:59,612 - __main__ - DEBUG - OpenAI API key loaded: ********************************************************************************************************************************************************************
2024-11-14 17:14:59,613 - __main__ - DEBUG - Upload folder path: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\uploads
2024-11-14 17:14:59,613 - __main__ - DEBUG - Output folder path: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output
2024-11-14 17:14:59,613 - __main__ - INFO - Starting main process
2024-11-14 17:14:59,613 - __main__ - INFO - Starting initial data processing
2024-11-14 17:15:00,240 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 216142
2024-11-14 17:15:00,293 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-11-14 17:15:00,295 - httpx - DEBUG - load_verify_locations cafile='C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\certifi\\cacert.pem'
2024-11-14 17:15:00,295 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_audio\1\male_1.wav
2024-11-14 17:15:00,296 - __main__ - DEBUG - Sending TTS request for order 1, role female_2
2024-11-14 17:15:00,298 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 17:15:00,313 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 17:15:01,268 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-14 17:15:01,268 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-11-14 17:15:01,795 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 229454
2024-11-14 17:15:01,834 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_audio\1\female_2.wav
2024-11-14 17:15:01,835 - __main__ - DEBUG - Sending TTS request for order 1, role male_2
2024-11-14 17:15:01,837 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 17:15:01,849 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 17:15:02,342 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000016A56893A40>
2024-11-14 17:15:02,343 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000016A56B40C50> server_hostname='api.openai.com' timeout=5.0
2024-11-14 17:15:02,419 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000016A56AEB7D0>
2024-11-14 17:15:02,420 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-14 17:15:02,421 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-14 17:15:02,421 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-14 17:15:02,421 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-14 17:15:02,422 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-14 17:15:03,746 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 313934
2024-11-14 17:15:03,799 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_audio\1\male_2.wav
2024-11-14 17:15:03,800 - __main__ - DEBUG - Generating audio for order 2
2024-11-14 17:15:03,801 - __main__ - DEBUG - Sending TTS request for order 2, role female_1
2024-11-14 17:15:03,804 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 17:15:03,819 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 17:15:05,152 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 204878
2024-11-14 17:15:05,187 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_audio\2\female_1.wav
2024-11-14 17:15:05,188 - __main__ - DEBUG - Sending TTS request for order 2, role male_1
2024-11-14 17:15:05,190 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 17:15:05,203 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 17:15:06,816 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 202830
2024-11-14 17:15:06,844 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_audio\2\male_1.wav
2024-11-14 17:15:06,844 - __main__ - DEBUG - Sending TTS request for order 2, role female_2
2024-11-14 17:15:06,847 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 17:15:06,863 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 17:15:08,477 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 258638
2024-11-14 17:15:08,512 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_audio\2\female_2.wav
2024-11-14 17:15:08,513 - __main__ - DEBUG - Sending TTS request for order 2, role male_2
2024-11-14 17:15:08,515 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 17:15:08,529 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 17:15:10,482 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 313934
2024-11-14 17:15:10,530 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_audio\2\male_2.wav
2024-11-14 17:15:10,530 - __main__ - INFO - Audio generation complete
2024-11-14 17:15:10,530 - __main__ - INFO - Processing complete. Final output saved to: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story.xlsx
2024-11-14 17:15:10,638 - httpcore.connection - DEBUG - close.started
2024-11-14 17:15:10,639 - httpcore.connection - DEBUG - close.complete
2024-11-14 17:15:12,530 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 14 Nov 2024 10:15:08 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'step-up-ognepk'), (b'openai-processing-ms', b'9729'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'448148'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'246ms'), (b'x-request-id', b'req_441a0898c77df1d685c0f3460da66801'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=DVkrCDNN5_fTiwKhl4FxChu3D9BvJ4Rllz4ybZBKtds-1731579308-1.0.1.1-tChB99ab.Z4sbaMyjr6IkII8oDZSBxF6DwXGqK7zp6Pn0v.CMuD_PMsfqieRbD4mmFNrcFgJGT.mzKyJF5NhtA; path=/; expires=Thu, 14-Nov-24 10:45:08 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=FxhYFzMZvmYFToGJdZXHleK9JRN737NhGEWPO4Rg0fY-1731579308562-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e263cd7ff3c9c35-SIN'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-14 17:15:12,531 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-14 17:15:12,531 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-14 17:15:12,532 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-14 17:15:12,532 - httpcore.http11 - DEBUG - response_closed.started
2024-11-14 17:15:12,533 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-14 17:15:12,533 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 14 Nov 2024 10:15:08 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'step-up-ognepk'), ('openai-processing-ms', '9729'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '500'), ('x-ratelimit-limit-tokens', '450000'), ('x-ratelimit-remaining-requests', '499'), ('x-ratelimit-remaining-tokens', '448148'), ('x-ratelimit-reset-requests', '120ms'), ('x-ratelimit-reset-tokens', '246ms'), ('x-request-id', 'req_441a0898c77df1d685c0f3460da66801'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=DVkrCDNN5_fTiwKhl4FxChu3D9BvJ4Rllz4ybZBKtds-1731579308-1.0.1.1-tChB99ab.Z4sbaMyjr6IkII8oDZSBxF6DwXGqK7zp6Pn0v.CMuD_PMsfqieRbD4mmFNrcFgJGT.mzKyJF5NhtA; path=/; expires=Thu, 14-Nov-24 10:45:08 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=FxhYFzMZvmYFToGJdZXHleK9JRN737NhGEWPO4Rg0fY-1731579308562-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8e263cd7ff3c9c35-SIN'), ('content-encoding', 'br'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-11-14 17:15:12,533 - openai._base_client - DEBUG - request_id: req_441a0898c77df1d685c0f3460da66801
2024-11-14 17:15:12,540 - __main__ - DEBUG - Order 1, Input: 'Topic: talk about your family - Family size and type
Given vocabulary: Nuclear family
Situation: Sarah and Tom, neighbors, at a community park', Response received in 12.25s
2024-11-14 17:15:12,541 - __main__ - DEBUG - Processed row - Order: 1
2024-11-14 17:15:12,553 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-14 17:15:12,554 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-14 17:15:12,555 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-14 17:15:12,556 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-14 17:15:12,556 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-14 17:15:12,556 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-14 17:15:23,805 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 14 Nov 2024 10:15:19 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'step-up-ognepk'), (b'openai-processing-ms', b'10860'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'448146'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'247ms'), (b'x-request-id', b'req_8fea4fa66fac8d870aade1339bc1678b'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e263d174ac89c35-SIN'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-14 17:15:23,805 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-14 17:15:23,806 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-14 17:15:23,806 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-14 17:15:23,807 - httpcore.http11 - DEBUG - response_closed.started
2024-11-14 17:15:23,807 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-14 17:15:23,807 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 14 Nov 2024 10:15:19 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'step-up-ognepk', 'openai-processing-ms': '10860', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '450000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '448146', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '247ms', 'x-request-id': 'req_8fea4fa66fac8d870aade1339bc1678b', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8e263d174ac89c35-SIN', 'content-encoding': 'br', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-14 17:15:23,807 - openai._base_client - DEBUG - request_id: req_8fea4fa66fac8d870aade1339bc1678b
2024-11-14 17:15:23,808 - __main__ - DEBUG - Order 2, Input: 'Topic: talk about your family - Family size and type
Given vocabulary: Generational family
Situation: Aubrey and Isaac, engineers, at a construction site', Response received in 11.27s
2024-11-14 17:15:23,808 - __main__ - DEBUG - Processed row - Order: 2
2024-11-14 17:15:23,890 - __main__ - INFO - Output saved to D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_draft.xlsx
2024-11-14 17:15:23,891 - __main__ - INFO - Starting story data processing
2024-11-14 17:15:23,909 - __main__ - DEBUG - Processing story data for order 1
2024-11-14 17:15:23,909 - __main__ - DEBUG - Processing story data for order 2
2024-11-14 17:15:23,945 - __main__ - INFO - Story data processing complete, saved to D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story.xlsx
2024-11-14 17:15:23,945 - __main__ - INFO - Starting audio generation
2024-11-14 17:15:23,954 - __main__ - DEBUG - Generating audio for order 1
2024-11-14 17:15:23,954 - __main__ - DEBUG - Sending TTS request for order 1, role female_1
2024-11-14 17:15:23,957 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 17:15:23,969 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 17:15:25,048 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 166990
2024-11-14 17:15:25,072 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_audio\1\female_1.wav
2024-11-14 17:15:25,073 - __main__ - DEBUG - Sending TTS request for order 1, role male_1
2024-11-14 17:15:25,075 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 17:15:25,088 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 17:15:26,560 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 220750
2024-11-14 17:15:26,602 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_audio\1\male_1.wav
2024-11-14 17:15:26,602 - __main__ - DEBUG - Sending TTS request for order 1, role female_2
2024-11-14 17:15:26,604 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 17:15:26,616 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 17:15:28,504 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 298574
2024-11-14 17:15:28,555 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_audio\1\female_2.wav
2024-11-14 17:15:28,556 - __main__ - DEBUG - Sending TTS request for order 1, role male_2
2024-11-14 17:15:28,557 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 17:15:28,572 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 17:15:30,373 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 300622
2024-11-14 17:15:30,417 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_audio\1\male_2.wav
2024-11-14 17:15:30,418 - __main__ - DEBUG - Generating audio for order 2
2024-11-14 17:15:30,418 - __main__ - DEBUG - Sending TTS request for order 2, role female_1
2024-11-14 17:15:30,420 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 17:15:30,433 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 17:15:31,704 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 162382
2024-11-14 17:15:31,729 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_audio\2\female_1.wav
2024-11-14 17:15:31,729 - __main__ - DEBUG - Sending TTS request for order 2, role male_1
2024-11-14 17:15:31,730 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 17:15:31,746 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 17:15:33,046 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 200270
2024-11-14 17:15:33,136 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_audio\2\male_1.wav
2024-11-14 17:15:33,137 - __main__ - DEBUG - Sending TTS request for order 2, role female_2
2024-11-14 17:15:33,139 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 17:15:33,160 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 17:15:35,230 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 293966
2024-11-14 17:15:35,275 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_audio\2\female_2.wav
2024-11-14 17:15:35,275 - __main__ - DEBUG - Sending TTS request for order 2, role male_2
2024-11-14 17:15:35,277 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 17:15:35,289 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 17:15:37,217 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 327758
2024-11-14 17:15:37,274 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_audio\2\male_2.wav
2024-11-14 17:15:37,275 - __main__ - INFO - Audio generation complete
2024-11-14 17:15:37,275 - __main__ - INFO - Processing complete. Final output saved to: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story.xlsx
2024-11-14 17:15:37,387 - httpcore.connection - DEBUG - close.started
2024-11-14 17:15:37,388 - httpcore.connection - DEBUG - close.complete
2024-11-14 17:28:16,040 - __main__ - DEBUG - OpenAI API key loaded: ********************************************************************************************************************************************************************
2024-11-14 17:28:16,040 - __main__ - DEBUG - Upload folder path: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\uploads
2024-11-14 17:28:16,040 - __main__ - DEBUG - Output folder path: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output
2024-11-14 17:28:16,040 - __main__ - INFO - Starting main process
2024-11-14 17:28:16,041 - __main__ - INFO - Starting initial data processing
2024-11-14 17:28:16,562 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-11-14 17:28:16,564 - httpx - DEBUG - load_verify_locations cafile='C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\certifi\\cacert.pem'
2024-11-14 17:28:17,533 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-14 17:28:17,533 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-11-14 17:28:17,847 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000251BF5D6270>
2024-11-14 17:28:17,847 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000251BF648C50> server_hostname='api.openai.com' timeout=5.0
2024-11-14 17:28:18,216 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000251BF3A4350>
2024-11-14 17:28:18,217 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-14 17:28:18,217 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-14 17:28:18,217 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-14 17:28:18,217 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-14 17:28:18,218 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-14 17:28:28,848 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 14 Nov 2024 10:28:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'step-up-ognepk'), (b'openai-processing-ms', b'10270'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'448148'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'246ms'), (b'x-request-id', b'req_6a5515e4e08220a14129e2d066c7054a'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=hDVGR0YuT8k1hzRu3lzjA7QXafLX6YTxqQHXgMGM9Aw-1731580104-1.0.1.1-I.k2YTVnJP2oryjROmUZ81gwhcaTcVpDWyAD0tE36zdgW5nOL6ViquJAYSuI0RLtaEyr2MnF7jtZSnLQkiKtdg; path=/; expires=Thu, 14-Nov-24 10:58:24 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=VdwpdrRBJDsojtguATHfn1x1p_0HYL3gIGCnLnHEG.E-1731580104928-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e265045bc7f6004-SIN'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-14 17:28:28,850 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-14 17:28:28,850 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-14 17:28:28,851 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-14 17:28:28,851 - httpcore.http11 - DEBUG - response_closed.started
2024-11-14 17:28:28,851 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-14 17:28:28,851 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 14 Nov 2024 10:28:24 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'step-up-ognepk'), ('openai-processing-ms', '10270'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '500'), ('x-ratelimit-limit-tokens', '450000'), ('x-ratelimit-remaining-requests', '499'), ('x-ratelimit-remaining-tokens', '448148'), ('x-ratelimit-reset-requests', '120ms'), ('x-ratelimit-reset-tokens', '246ms'), ('x-request-id', 'req_6a5515e4e08220a14129e2d066c7054a'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=hDVGR0YuT8k1hzRu3lzjA7QXafLX6YTxqQHXgMGM9Aw-1731580104-1.0.1.1-I.k2YTVnJP2oryjROmUZ81gwhcaTcVpDWyAD0tE36zdgW5nOL6ViquJAYSuI0RLtaEyr2MnF7jtZSnLQkiKtdg; path=/; expires=Thu, 14-Nov-24 10:58:24 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=VdwpdrRBJDsojtguATHfn1x1p_0HYL3gIGCnLnHEG.E-1731580104928-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8e265045bc7f6004-SIN'), ('content-encoding', 'br'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-11-14 17:28:28,852 - openai._base_client - DEBUG - request_id: req_6a5515e4e08220a14129e2d066c7054a
2024-11-14 17:28:28,858 - __main__ - DEBUG - Order 1, Input: 'Topic: talk about your family - Family size and type
Given vocabulary: Nuclear family
Situation: Sarah and Tom, neighbors, at a community park', Response received in 12.30s
2024-11-14 17:28:28,858 - __main__ - DEBUG - Processed row - Order: 1
2024-11-14 17:28:28,867 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-14 17:28:28,867 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-14 17:28:28,868 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-14 17:28:28,868 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-14 17:28:28,868 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-14 17:28:28,868 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-14 17:28:39,246 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 14 Nov 2024 10:28:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'step-up-ognepk'), (b'openai-processing-ms', b'9951'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'448146'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'247ms'), (b'x-request-id', b'req_d0c2b6108bb766e5436acd4368d778b5'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e2650884e8a6004-SIN'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-14 17:28:39,246 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-14 17:28:39,247 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-14 17:28:39,247 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-14 17:28:39,247 - httpcore.http11 - DEBUG - response_closed.started
2024-11-14 17:28:39,247 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-14 17:28:39,247 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 14 Nov 2024 10:28:35 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'step-up-ognepk', 'openai-processing-ms': '9951', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '450000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '448146', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '247ms', 'x-request-id': 'req_d0c2b6108bb766e5436acd4368d778b5', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8e2650884e8a6004-SIN', 'content-encoding': 'br', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-14 17:28:39,248 - openai._base_client - DEBUG - request_id: req_d0c2b6108bb766e5436acd4368d778b5
2024-11-14 17:28:39,248 - __main__ - DEBUG - Order 2, Input: 'Topic: talk about your family - Family size and type
Given vocabulary: Generational family
Situation: Aubrey and Isaac, engineers, at a construction site', Response received in 10.39s
2024-11-14 17:28:39,249 - __main__ - DEBUG - Processed row - Order: 2
2024-11-14 17:28:39,338 - __main__ - INFO - Output saved to D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_draft.xlsx
2024-11-14 17:28:39,338 - __main__ - INFO - Starting story data processing
2024-11-14 17:28:39,356 - __main__ - DEBUG - Processing story data for order 1
2024-11-14 17:28:39,357 - __main__ - DEBUG - Processing story data for order 2
2024-11-14 17:28:39,398 - __main__ - INFO - Story data processing complete, saved to D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story.xlsx
2024-11-14 17:28:39,399 - __main__ - INFO - Starting audio generation
2024-11-14 17:28:39,407 - __main__ - DEBUG - Generating audio for order 1
2024-11-14 17:28:39,408 - __main__ - DEBUG - Sending TTS request for order 1, role female_1
2024-11-14 17:28:39,411 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 17:28:39,426 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 17:28:40,413 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 147022
2024-11-14 17:28:40,441 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_audio\1\female_1.wav
2024-11-14 17:28:40,441 - __main__ - DEBUG - Sending TTS request for order 1, role male_1
2024-11-14 17:28:40,444 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 17:28:40,456 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 17:28:41,912 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 224846
2024-11-14 17:28:41,954 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_audio\1\male_1.wav
2024-11-14 17:28:41,954 - __main__ - DEBUG - Sending TTS request for order 1, role female_2
2024-11-14 17:28:41,958 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 17:28:41,971 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 17:28:43,760 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 242766
2024-11-14 17:28:43,808 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_audio\1\female_2.wav
2024-11-14 17:28:43,808 - __main__ - DEBUG - Sending TTS request for order 1, role male_2
2024-11-14 17:28:43,811 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 17:28:43,826 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 17:28:45,488 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 265294
2024-11-14 17:28:45,579 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_audio\1\male_2.wav
2024-11-14 17:28:45,580 - __main__ - DEBUG - Generating audio for order 2
2024-11-14 17:28:45,580 - __main__ - DEBUG - Sending TTS request for order 2, role female_1
2024-11-14 17:28:45,583 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 17:28:45,601 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 17:28:47,118 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 160334
2024-11-14 17:28:47,187 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_audio\2\female_1.wav
2024-11-14 17:28:47,188 - __main__ - DEBUG - Sending TTS request for order 2, role male_1
2024-11-14 17:28:47,189 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 17:28:47,201 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 17:28:48,675 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 227406
2024-11-14 17:28:48,718 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_audio\2\male_1.wav
2024-11-14 17:28:48,718 - __main__ - DEBUG - Sending TTS request for order 2, role female_2
2024-11-14 17:28:48,719 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 17:28:48,738 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 17:28:50,635 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 309838
2024-11-14 17:28:50,683 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_audio\2\female_2.wav
2024-11-14 17:28:50,684 - __main__ - DEBUG - Sending TTS request for order 2, role male_2
2024-11-14 17:28:50,685 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-11-14 17:28:50,700 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/1.1" 307 0
2024-11-14 17:28:52,245 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/1.1" 200 240718
2024-11-14 17:28:52,621 - __main__ - DEBUG - Audio file saved: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_audio\2\male_2.wav
2024-11-14 17:28:52,621 - __main__ - INFO - Audio generation complete
2024-11-14 17:28:52,622 - __main__ - INFO - Processing complete. Final output saved to: D:\OneDrive - Hanoi University of Science and Technology\GIT\MiniProd_ContentEngFlow_IELTSStepUpE_T102024\deploy1.1\backend\output\output_story.xlsx
2024-11-14 17:28:52,734 - httpcore.connection - DEBUG - close.started
2024-11-14 17:28:52,734 - httpcore.connection - DEBUG - close.complete
2024-11-30 15:40:58,770 - __main__ - DEBUG - OpenAI API key loaded: ********************************************************************************************************************************************************************
2024-11-30 15:40:58,771 - __main__ - DEBUG - Upload folder path: /app/uploads
2024-11-30 15:40:58,771 - __main__ - DEBUG - Output folder path: /app/output
2024-11-30 15:40:58,772 - __main__ - INFO - Starting main process
2024-11-30 15:40:58,774 - __main__ - INFO - Starting initial data processing
2024-11-30 15:40:59,074 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Nuclear family\nSituation: Sarah and Tom, neighbors, at a community park'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 15:40:59,083 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 15:40:59,084 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-11-30 15:40:59,186 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff3a998abe0>
2024-11-30 15:40:59,187 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff3aa15bac0> server_hostname='api.openai.com' timeout=5.0
2024-11-30 15:40:59,273 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff3a998a970>
2024-11-30 15:40:59,274 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 15:40:59,275 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 15:40:59,275 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 15:40:59,276 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 15:40:59,276 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 15:40:59,654 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 15:41:03 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_0d59da080ec4d5e97c758c327396c6d6'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=OP7Ce1u.8Qt0OAD2Yraf.jd9JrTSyX13ReIDW5aWVqE-1732981263-1.0.1.1-D37HmBVd.q1GNgiTUSLtQiV07KvnuoPrPwlzGYnL1T.SFsvohaBL5D9Hz32rh3OWleahaF_m2jKNWF4fwiWdiA; path=/; expires=Sat, 30-Nov-24 16:11:03 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=5SHEVD5WWCSM37ZWMnlINle4bZnS.4dpQ3gRVtP1DRU-1732981263843-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eabf081196d1072-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 15:40:59,656 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 15:40:59,656 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 15:40:59,657 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 15:40:59,658 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 15:40:59,658 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 15:40:59,658 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers([('date', 'Sat, 30 Nov 2024 15:41:03 GMT'), ('content-type', 'application/json; charset=utf-8'), ('content-length', '337'), ('connection', 'keep-alive'), ('vary', 'Origin'), ('x-request-id', 'req_0d59da080ec4d5e97c758c327396c6d6'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=OP7Ce1u.8Qt0OAD2Yraf.jd9JrTSyX13ReIDW5aWVqE-1732981263-1.0.1.1-D37HmBVd.q1GNgiTUSLtQiV07KvnuoPrPwlzGYnL1T.SFsvohaBL5D9Hz32rh3OWleahaF_m2jKNWF4fwiWdiA; path=/; expires=Sat, 30-Nov-24 16:11:03 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=5SHEVD5WWCSM37ZWMnlINle4bZnS.4dpQ3gRVtP1DRU-1732981263843-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8eabf081196d1072-HKG'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-11-30 15:40:59,659 - openai._base_client - DEBUG - request_id: req_0d59da080ec4d5e97c758c327396c6d6
2024-11-30 15:40:59,660 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 15:40:59,663 - openai._base_client - DEBUG - Retrying due to status code 429
2024-11-30 15:40:59,664 - openai._base_client - DEBUG - 2 retries left
2024-11-30 15:40:59,664 - openai._base_client - INFO - Retrying request to /chat/completions in 0.428598 seconds
2024-11-30 15:41:00,094 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Nuclear family\nSituation: Sarah and Tom, neighbors, at a community park'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 15:41:00,095 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 15:41:00,096 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 15:41:00,096 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 15:41:00,097 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 15:41:00,098 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 15:41:00,098 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 15:41:00,447 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 15:41:04 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_781af286e405002f056e678e09e0cf90'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eabf08639981072-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 15:41:00,448 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 15:41:00,448 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 15:41:00,449 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 15:41:00,449 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 15:41:00,450 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 15:41:00,450 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 15:41:04 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_781af286e405002f056e678e09e0cf90', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eabf08639981072-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 15:41:00,451 - openai._base_client - DEBUG - request_id: req_781af286e405002f056e678e09e0cf90
2024-11-30 15:41:00,451 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 15:41:00,452 - openai._base_client - DEBUG - Retrying due to status code 429
2024-11-30 15:41:00,453 - openai._base_client - DEBUG - 1 retry left
2024-11-30 15:41:00,453 - openai._base_client - INFO - Retrying request to /chat/completions in 0.945888 seconds
2024-11-30 15:41:01,399 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Nuclear family\nSituation: Sarah and Tom, neighbors, at a community park'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 15:41:01,401 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 15:41:01,402 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 15:41:01,403 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 15:41:01,403 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 15:41:01,404 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 15:41:01,404 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 15:41:01,754 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 15:41:05 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_894fde9df1e44c5ecf8e062406e680bb'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eabf08e6f081072-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 15:41:01,755 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 15:41:01,756 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 15:41:01,756 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 15:41:01,757 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 15:41:01,757 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 15:41:01,758 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 15:41:05 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_894fde9df1e44c5ecf8e062406e680bb', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eabf08e6f081072-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 15:41:01,758 - openai._base_client - DEBUG - request_id: req_894fde9df1e44c5ecf8e062406e680bb
2024-11-30 15:41:01,759 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 15:41:01,760 - openai._base_client - DEBUG - Re-raising status error
2024-11-30 15:41:04,769 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Nuclear family\nSituation: Sarah and Tom, neighbors, at a community park'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 15:41:04,771 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 15:41:04,772 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 15:41:04,772 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 15:41:04,773 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 15:41:04,774 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 15:41:04,774 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 15:41:05,137 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 15:41:09 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_5e7b16ad69fbce6dd3cc5e957ed09111'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eabf0a37caf1072-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 15:41:05,138 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 15:41:05,138 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 15:41:05,139 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 15:41:05,139 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 15:41:05,140 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 15:41:05,140 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 15:41:09 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_5e7b16ad69fbce6dd3cc5e957ed09111', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eabf0a37caf1072-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 15:41:05,141 - openai._base_client - DEBUG - request_id: req_5e7b16ad69fbce6dd3cc5e957ed09111
2024-11-30 15:41:05,141 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 15:41:05,142 - openai._base_client - DEBUG - Retrying due to status code 429
2024-11-30 15:41:05,142 - openai._base_client - DEBUG - 2 retries left
2024-11-30 15:41:05,142 - openai._base_client - INFO - Retrying request to /chat/completions in 0.392294 seconds
2024-11-30 15:41:05,536 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Nuclear family\nSituation: Sarah and Tom, neighbors, at a community park'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 15:41:05,537 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 15:41:05,538 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 15:41:05,539 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 15:41:05,539 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 15:41:05,540 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 15:41:05,541 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 15:41:05,905 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 15:41:10 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_a2ef5773f49a73dedca6d69bbe2bb26e'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eabf0a83b3d1072-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 15:41:05,906 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 15:41:05,907 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 15:41:05,907 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 15:41:05,908 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 15:41:05,909 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 15:41:05,909 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 15:41:10 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_a2ef5773f49a73dedca6d69bbe2bb26e', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eabf0a83b3d1072-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 15:41:05,910 - openai._base_client - DEBUG - request_id: req_a2ef5773f49a73dedca6d69bbe2bb26e
2024-11-30 15:41:05,910 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 15:41:05,911 - openai._base_client - DEBUG - Retrying due to status code 429
2024-11-30 15:41:05,911 - openai._base_client - DEBUG - 1 retry left
2024-11-30 15:41:05,912 - openai._base_client - INFO - Retrying request to /chat/completions in 0.843232 seconds
2024-11-30 15:41:06,756 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Nuclear family\nSituation: Sarah and Tom, neighbors, at a community park'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 15:41:06,758 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 15:41:06,759 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 15:41:06,759 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 15:41:06,760 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 15:41:06,760 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 15:41:06,761 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 15:41:07,115 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 15:41:11 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_99fe65e36178e25ab75414454f707e11'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eabf0afec891072-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 15:41:07,116 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 15:41:07,117 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 15:41:07,117 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 15:41:07,118 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 15:41:07,118 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 15:41:07,119 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 15:41:11 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_99fe65e36178e25ab75414454f707e11', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eabf0afec891072-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 15:41:07,119 - openai._base_client - DEBUG - request_id: req_99fe65e36178e25ab75414454f707e11
2024-11-30 15:41:07,120 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 15:41:07,120 - openai._base_client - DEBUG - Re-raising status error
2024-11-30 15:41:10,130 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Nuclear family\nSituation: Sarah and Tom, neighbors, at a community park'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 15:41:10,131 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 15:41:10,132 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 15:41:10,133 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 15:41:10,133 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 15:41:10,134 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 15:41:10,134 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 15:41:10,487 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 15:41:14 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_93c281c2cdb4c590daa0bd6a71374e42'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eabf0c4ffb81072-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 15:41:10,488 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 15:41:10,489 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 15:41:10,489 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 15:41:10,490 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 15:41:10,490 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 15:41:10,491 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 15:41:14 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_93c281c2cdb4c590daa0bd6a71374e42', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eabf0c4ffb81072-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 15:41:10,491 - openai._base_client - DEBUG - request_id: req_93c281c2cdb4c590daa0bd6a71374e42
2024-11-30 15:41:10,492 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 15:41:10,492 - openai._base_client - DEBUG - Retrying due to status code 429
2024-11-30 15:41:10,493 - openai._base_client - DEBUG - 2 retries left
2024-11-30 15:41:10,493 - openai._base_client - INFO - Retrying request to /chat/completions in 0.434633 seconds
2024-11-30 15:41:10,929 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Nuclear family\nSituation: Sarah and Tom, neighbors, at a community park'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 15:41:10,930 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 15:41:10,931 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 15:41:10,932 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 15:41:10,932 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 15:41:10,933 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 15:41:10,933 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 15:41:11,888 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 15:41:15 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_ce30089e2cf00895a3dce39474dbfa27'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eabf0c9fdda1072-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 15:41:11,889 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 15:41:11,889 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 15:41:11,890 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 15:41:11,890 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 15:41:11,891 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 15:41:11,891 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 15:41:15 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_ce30089e2cf00895a3dce39474dbfa27', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eabf0c9fdda1072-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 15:41:11,892 - openai._base_client - DEBUG - request_id: req_ce30089e2cf00895a3dce39474dbfa27
2024-11-30 15:41:11,892 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 15:41:11,893 - openai._base_client - DEBUG - Retrying due to status code 429
2024-11-30 15:41:11,893 - openai._base_client - DEBUG - 1 retry left
2024-11-30 15:41:11,894 - openai._base_client - INFO - Retrying request to /chat/completions in 0.962467 seconds
2024-11-30 15:41:12,858 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Nuclear family\nSituation: Sarah and Tom, neighbors, at a community park'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 15:41:12,860 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 15:41:12,861 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 15:41:12,862 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 15:41:12,862 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 15:41:12,863 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 15:41:12,863 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 15:41:13,211 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 15:41:17 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_f2a86549b609e7740d2e1248ce7de927'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eabf0d60de71072-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 15:41:13,212 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 15:41:13,213 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 15:41:13,214 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 15:41:13,214 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 15:41:13,215 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 15:41:13,216 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 15:41:17 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_f2a86549b609e7740d2e1248ce7de927', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eabf0d60de71072-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 15:41:13,216 - openai._base_client - DEBUG - request_id: req_f2a86549b609e7740d2e1248ce7de927
2024-11-30 15:41:13,217 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 15:41:13,218 - openai._base_client - DEBUG - Re-raising status error
2024-11-30 15:41:13,219 - __main__ - ERROR - Order 1, Input: 'Topic: talk about your family - Family size and type
Given vocabulary: Nuclear family
Situation: Sarah and Tom, neighbors, at a community park', Response: 'Request failed after 2 retries.'
2024-11-30 15:41:13,220 - __main__ - DEBUG - Processed row - Order: 1
2024-11-30 15:41:13,220 - __main__ - DEBUG - Response: Request failed after 2 retries.
2024-11-30 15:41:13,230 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Generational family\nSituation: Aubrey and Isaac, engineers, at a construction site'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 15:41:13,232 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 15:41:13,233 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 15:41:13,234 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 15:41:13,234 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 15:41:13,235 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 15:41:13,236 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 15:41:13,580 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 15:41:17 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_c44e01908c60f2c7999cc60c6fbd307e'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eabf0d859571072-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 15:41:13,581 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 15:41:13,582 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 15:41:13,582 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 15:41:13,583 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 15:41:13,583 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 15:41:13,584 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 15:41:17 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_c44e01908c60f2c7999cc60c6fbd307e', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eabf0d859571072-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 15:41:13,585 - openai._base_client - DEBUG - request_id: req_c44e01908c60f2c7999cc60c6fbd307e
2024-11-30 15:41:13,585 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 15:41:13,586 - openai._base_client - DEBUG - Retrying due to status code 429
2024-11-30 15:41:13,587 - openai._base_client - DEBUG - 2 retries left
2024-11-30 15:41:13,587 - openai._base_client - INFO - Retrying request to /chat/completions in 0.479544 seconds
2024-11-30 15:41:14,068 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Generational family\nSituation: Aubrey and Isaac, engineers, at a construction site'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 15:41:14,070 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 15:41:14,071 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 15:41:14,072 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 15:41:14,072 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 15:41:14,073 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 15:41:14,073 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 15:41:14,417 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 15:41:18 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_8d05f050c3e42eae5e11466d15d110f7'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eabf0dd88561072-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 15:41:14,418 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 15:41:14,418 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 15:41:14,419 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 15:41:14,419 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 15:41:14,420 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 15:41:14,420 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 15:41:18 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_8d05f050c3e42eae5e11466d15d110f7', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eabf0dd88561072-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 15:41:14,421 - openai._base_client - DEBUG - request_id: req_8d05f050c3e42eae5e11466d15d110f7
2024-11-30 15:41:14,421 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 15:41:14,422 - openai._base_client - DEBUG - Retrying due to status code 429
2024-11-30 15:41:14,423 - openai._base_client - DEBUG - 1 retry left
2024-11-30 15:41:14,423 - openai._base_client - INFO - Retrying request to /chat/completions in 0.829140 seconds
2024-11-30 15:41:15,254 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Generational family\nSituation: Aubrey and Isaac, engineers, at a construction site'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 15:41:15,256 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 15:41:15,256 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 15:41:15,257 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 15:41:15,258 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 15:41:15,258 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 15:41:15,259 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 15:41:15,747 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 15:41:19 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_9b1aa10057c722f7ff1a9e19e4cf2b20'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eabf0e50b881072-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 15:41:15,748 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 15:41:15,748 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 15:41:15,749 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 15:41:15,749 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 15:41:15,750 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 15:41:15,750 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 15:41:19 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_9b1aa10057c722f7ff1a9e19e4cf2b20', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eabf0e50b881072-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 15:41:15,751 - openai._base_client - DEBUG - request_id: req_9b1aa10057c722f7ff1a9e19e4cf2b20
2024-11-30 15:41:15,751 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 15:41:15,752 - openai._base_client - DEBUG - Re-raising status error
2024-11-30 15:41:18,762 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Generational family\nSituation: Aubrey and Isaac, engineers, at a construction site'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 15:41:18,763 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 15:41:18,764 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 15:41:18,765 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 15:41:18,765 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 15:41:18,766 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 15:41:18,766 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 15:41:19,453 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 15:41:23 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_5d2b299b86c94b560e8d09a6cdb35b88'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eabf0faeaee1072-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 15:41:19,454 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 15:41:19,455 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 15:41:19,456 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 15:41:19,456 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 15:41:19,457 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 15:41:19,457 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 15:41:23 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_5d2b299b86c94b560e8d09a6cdb35b88', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eabf0faeaee1072-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 15:41:19,458 - openai._base_client - DEBUG - request_id: req_5d2b299b86c94b560e8d09a6cdb35b88
2024-11-30 15:41:19,459 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 15:41:19,459 - openai._base_client - DEBUG - Retrying due to status code 429
2024-11-30 15:41:19,460 - openai._base_client - DEBUG - 2 retries left
2024-11-30 15:41:19,461 - openai._base_client - INFO - Retrying request to /chat/completions in 0.396719 seconds
2024-11-30 15:41:19,858 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Generational family\nSituation: Aubrey and Isaac, engineers, at a construction site'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 15:41:19,860 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 15:41:19,860 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 15:41:19,861 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 15:41:19,862 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 15:41:19,862 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 15:41:19,863 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 15:41:20,207 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 15:41:24 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_afa860b267c4ec29575f5bc129be15d9'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eabf101cceb1072-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 15:41:20,208 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 15:41:20,209 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 15:41:20,210 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 15:41:20,210 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 15:41:20,211 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 15:41:20,211 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 15:41:24 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_afa860b267c4ec29575f5bc129be15d9', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eabf101cceb1072-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 15:41:20,212 - openai._base_client - DEBUG - request_id: req_afa860b267c4ec29575f5bc129be15d9
2024-11-30 15:41:20,212 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 15:41:20,213 - openai._base_client - DEBUG - Retrying due to status code 429
2024-11-30 15:41:20,213 - openai._base_client - DEBUG - 1 retry left
2024-11-30 15:41:20,213 - openai._base_client - INFO - Retrying request to /chat/completions in 0.918257 seconds
2024-11-30 15:41:21,133 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Generational family\nSituation: Aubrey and Isaac, engineers, at a construction site'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 15:41:21,135 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 15:41:21,136 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 15:41:21,138 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 15:41:21,138 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 15:41:21,139 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 15:41:21,140 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 15:41:21,481 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 15:41:25 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_9f5ede89c83cae8c53202745e643ba8f'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eabf109bfff1072-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 15:41:21,482 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 15:41:21,482 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 15:41:21,483 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 15:41:21,484 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 15:41:21,484 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 15:41:21,485 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 15:41:25 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_9f5ede89c83cae8c53202745e643ba8f', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eabf109bfff1072-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 15:41:21,486 - openai._base_client - DEBUG - request_id: req_9f5ede89c83cae8c53202745e643ba8f
2024-11-30 15:41:21,486 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 15:41:21,487 - openai._base_client - DEBUG - Re-raising status error
2024-11-30 15:41:24,496 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Generational family\nSituation: Aubrey and Isaac, engineers, at a construction site'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 15:41:24,497 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 15:41:24,498 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 15:41:24,499 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 15:41:24,499 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 15:41:24,500 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 15:41:24,500 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 15:41:25,166 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 15:41:29 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_9a24595406d6aeee054883a208d574b9'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eabf11ebd161072-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 15:41:25,167 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 15:41:25,167 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 15:41:25,168 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 15:41:25,168 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 15:41:25,169 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 15:41:25,169 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 15:41:29 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_9a24595406d6aeee054883a208d574b9', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eabf11ebd161072-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 15:41:25,170 - openai._base_client - DEBUG - request_id: req_9a24595406d6aeee054883a208d574b9
2024-11-30 15:41:25,170 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 15:41:25,171 - openai._base_client - DEBUG - Retrying due to status code 429
2024-11-30 15:41:25,172 - openai._base_client - DEBUG - 2 retries left
2024-11-30 15:41:25,172 - openai._base_client - INFO - Retrying request to /chat/completions in 0.430557 seconds
2024-11-30 15:41:25,604 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Generational family\nSituation: Aubrey and Isaac, engineers, at a construction site'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 15:41:25,605 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 15:41:25,606 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 15:41:25,607 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 15:41:25,607 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 15:41:25,608 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 15:41:25,608 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 15:41:25,956 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 15:41:30 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_7ae8c26b2eace8a14ab1f8eebed00f96'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eabf125ad9c1072-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 15:41:25,957 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 15:41:25,958 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 15:41:25,958 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 15:41:25,959 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 15:41:25,960 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 15:41:25,960 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 15:41:30 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_7ae8c26b2eace8a14ab1f8eebed00f96', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eabf125ad9c1072-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 15:41:25,961 - openai._base_client - DEBUG - request_id: req_7ae8c26b2eace8a14ab1f8eebed00f96
2024-11-30 15:41:25,961 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 15:41:25,962 - openai._base_client - DEBUG - Retrying due to status code 429
2024-11-30 15:41:25,963 - openai._base_client - DEBUG - 1 retry left
2024-11-30 15:41:25,963 - openai._base_client - INFO - Retrying request to /chat/completions in 0.971785 seconds
2024-11-30 15:41:26,937 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Generational family\nSituation: Aubrey and Isaac, engineers, at a construction site'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 15:41:26,938 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 15:41:26,939 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 15:41:26,940 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 15:41:26,940 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 15:41:26,941 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 15:41:26,941 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 15:41:27,282 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 15:41:31 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_d4179f2b9116f2340603e7ff72692a1c'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eabf12dff601072-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 15:41:27,283 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 15:41:27,283 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 15:41:27,284 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 15:41:27,284 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 15:41:27,285 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 15:41:27,285 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 15:41:31 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_d4179f2b9116f2340603e7ff72692a1c', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eabf12dff601072-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 15:41:27,286 - openai._base_client - DEBUG - request_id: req_d4179f2b9116f2340603e7ff72692a1c
2024-11-30 15:41:27,286 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 15:41:27,287 - openai._base_client - DEBUG - Re-raising status error
2024-11-30 15:41:27,288 - __main__ - ERROR - Order 2, Input: 'Topic: talk about your family - Family size and type
Given vocabulary: Generational family
Situation: Aubrey and Isaac, engineers, at a construction site', Response: 'Request failed after 2 retries.'
2024-11-30 15:41:27,288 - __main__ - DEBUG - Processed row - Order: 2
2024-11-30 15:41:27,289 - __main__ - DEBUG - Response: Request failed after 2 retries.
2024-11-30 15:41:27,316 - __main__ - INFO - Output saved to /app/output/output_draft.xlsx
2024-11-30 15:41:27,317 - __main__ - INFO - Starting story data processing
2024-11-30 15:41:27,337 - __main__ - DEBUG - Processing story data for order 1
2024-11-30 15:41:27,337 - __main__ - WARNING - Invalid JSON for order 1, skipping
2024-11-30 15:41:27,338 - __main__ - DEBUG - Processing story data for order 2
2024-11-30 15:41:27,339 - __main__ - WARNING - Invalid JSON for order 2, skipping
2024-11-30 15:41:27,363 - __main__ - INFO - Story data processing complete, saved to /app/output/output_story.xlsx
2024-11-30 15:41:27,363 - __main__ - INFO - Starting audio generation
2024-11-30 15:41:27,382 - __main__ - DEBUG - Generating audio for order 1
2024-11-30 15:41:27,383 - __main__ - ERROR - Error in generate_audio: Expecting value: line 1 column 1 (char 0)
Traceback (most recent call last):
  File "/app/scripts/generate_story.py", line 235, in generate_audio
    data = json.loads(row['json'])
  File "/usr/local/lib/python3.9/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.9/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.9/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
2024-11-30 15:41:27,389 - __main__ - ERROR - Error in main: Expecting value: line 1 column 1 (char 0)
Traceback (most recent call last):
  File "/app/scripts/generate_story.py", line 275, in main
    generate_audio()
  File "/app/scripts/generate_story.py", line 235, in generate_audio
    data = json.loads(row['json'])
  File "/usr/local/lib/python3.9/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.9/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.9/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
2024-11-30 15:42:32,327 - __main__ - DEBUG - OpenAI API key loaded: ********************************************************************************************************************************************************************
2024-11-30 15:42:32,328 - __main__ - DEBUG - Upload folder path: /app/uploads
2024-11-30 15:42:32,328 - __main__ - DEBUG - Output folder path: /app/output
2024-11-30 15:42:32,329 - __main__ - INFO - Starting main process
2024-11-30 15:42:32,332 - __main__ - INFO - Starting initial data processing
2024-11-30 15:42:32,633 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Nuclear family\nSituation: Sarah and Tom, neighbors, at a community park'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 15:42:32,641 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 15:42:32,643 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-11-30 15:42:32,752 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9ccc13cbe0>
2024-11-30 15:42:32,753 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9ccc90dac0> server_hostname='api.openai.com' timeout=5.0
2024-11-30 15:42:33,045 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9ccc13c970>
2024-11-30 15:42:33,046 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 15:42:33,047 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 15:42:33,047 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 15:42:33,048 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 15:42:33,048 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 15:42:33,440 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 15:42:37 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_cb42b5947edcbc58339a5ed2c4c74c7e'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=zq4WH9sNMBJmqZ.TjHbSrCx6QKgXUz9439mp5waP9as-1732981357-1.0.1.1-6IZxkr2Mmx5HtdFMy44Aqgj2eVwgKjvBcuPbbSOEtBAd_XRihTapNHrJwL.PVtgDHTtvbBn1zA4hImor_OeVtQ; path=/; expires=Sat, 30-Nov-24 16:12:37 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=jl1WhpAakaNhcLr3vjgQV4IKSJVg0qNhoUF92WKdL3o-1732981357590-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eabf2cb2ff82362-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 15:42:33,442 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 15:42:33,443 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 15:42:33,444 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 15:42:33,444 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 15:42:33,445 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 15:42:33,446 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers([('date', 'Sat, 30 Nov 2024 15:42:37 GMT'), ('content-type', 'application/json; charset=utf-8'), ('content-length', '337'), ('connection', 'keep-alive'), ('vary', 'Origin'), ('x-request-id', 'req_cb42b5947edcbc58339a5ed2c4c74c7e'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=zq4WH9sNMBJmqZ.TjHbSrCx6QKgXUz9439mp5waP9as-1732981357-1.0.1.1-6IZxkr2Mmx5HtdFMy44Aqgj2eVwgKjvBcuPbbSOEtBAd_XRihTapNHrJwL.PVtgDHTtvbBn1zA4hImor_OeVtQ; path=/; expires=Sat, 30-Nov-24 16:12:37 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=jl1WhpAakaNhcLr3vjgQV4IKSJVg0qNhoUF92WKdL3o-1732981357590-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8eabf2cb2ff82362-HKG'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-11-30 15:42:33,446 - openai._base_client - DEBUG - request_id: req_cb42b5947edcbc58339a5ed2c4c74c7e
2024-11-30 15:42:33,447 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 15:42:33,449 - openai._base_client - DEBUG - Retrying due to status code 429
2024-11-30 15:42:33,450 - openai._base_client - DEBUG - 2 retries left
2024-11-30 15:42:33,451 - openai._base_client - INFO - Retrying request to /chat/completions in 0.474751 seconds
2024-11-30 15:42:33,927 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Nuclear family\nSituation: Sarah and Tom, neighbors, at a community park'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 15:42:33,928 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 15:42:33,929 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 15:42:33,929 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 15:42:33,930 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 15:42:33,930 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 15:42:33,931 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 15:42:34,647 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 15:42:38 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_4054303d38d26d0bdb566d2fdcb118b3'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eabf2d0adc92362-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 15:42:34,648 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 15:42:34,648 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 15:42:34,649 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 15:42:34,650 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 15:42:34,650 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 15:42:34,651 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 15:42:38 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_4054303d38d26d0bdb566d2fdcb118b3', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eabf2d0adc92362-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 15:42:34,651 - openai._base_client - DEBUG - request_id: req_4054303d38d26d0bdb566d2fdcb118b3
2024-11-30 15:42:34,652 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 15:42:34,652 - openai._base_client - DEBUG - Retrying due to status code 429
2024-11-30 15:42:34,653 - openai._base_client - DEBUG - 1 retry left
2024-11-30 15:42:34,653 - openai._base_client - INFO - Retrying request to /chat/completions in 0.802107 seconds
2024-11-30 15:42:35,457 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Nuclear family\nSituation: Sarah and Tom, neighbors, at a community park'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 15:42:35,458 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 15:42:35,458 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 15:42:35,459 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 15:42:35,459 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 15:42:35,460 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 15:42:35,460 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 15:42:35,899 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 15:42:40 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_0427a366ddcfb92b5d921a9827416211'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eabf2da3f922362-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 15:42:35,900 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 15:42:35,901 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 15:42:35,901 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 15:42:35,902 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 15:42:35,902 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 15:42:35,902 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 15:42:40 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_0427a366ddcfb92b5d921a9827416211', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eabf2da3f922362-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 15:42:35,903 - openai._base_client - DEBUG - request_id: req_0427a366ddcfb92b5d921a9827416211
2024-11-30 15:42:35,903 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 15:42:35,904 - openai._base_client - DEBUG - Re-raising status error
2024-11-30 15:42:38,917 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Nuclear family\nSituation: Sarah and Tom, neighbors, at a community park'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 15:42:38,919 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 15:42:38,920 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 15:42:38,921 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 15:42:38,922 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 15:42:38,923 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 15:42:38,923 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 15:42:39,276 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 15:42:43 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_75a16e74890f1dc840c39873dd06240e'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eabf2efd8072362-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 15:42:39,277 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 15:42:39,278 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 15:42:39,278 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 15:42:39,279 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 15:42:39,279 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 15:42:39,280 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 15:42:43 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_75a16e74890f1dc840c39873dd06240e', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eabf2efd8072362-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 15:42:39,280 - openai._base_client - DEBUG - request_id: req_75a16e74890f1dc840c39873dd06240e
2024-11-30 15:42:39,281 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 15:42:39,282 - openai._base_client - DEBUG - Retrying due to status code 429
2024-11-30 15:42:39,283 - openai._base_client - DEBUG - 2 retries left
2024-11-30 15:42:39,283 - openai._base_client - INFO - Retrying request to /chat/completions in 0.411361 seconds
2024-11-30 15:42:39,696 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Nuclear family\nSituation: Sarah and Tom, neighbors, at a community park'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 15:42:39,697 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 15:42:39,698 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 15:42:39,699 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 15:42:39,700 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 15:42:39,700 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 15:42:39,701 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 15:42:40,048 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 15:42:44 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_abd7a0409e9f0d004578b57c26eee172'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eabf2f4bcca2362-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 15:42:40,049 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 15:42:40,050 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 15:42:40,050 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 15:42:40,051 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 15:42:40,051 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 15:42:40,052 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 15:42:44 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_abd7a0409e9f0d004578b57c26eee172', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eabf2f4bcca2362-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 15:42:40,052 - openai._base_client - DEBUG - request_id: req_abd7a0409e9f0d004578b57c26eee172
2024-11-30 15:42:40,052 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 15:42:40,053 - openai._base_client - DEBUG - Retrying due to status code 429
2024-11-30 15:42:40,054 - openai._base_client - DEBUG - 1 retry left
2024-11-30 15:42:40,054 - openai._base_client - INFO - Retrying request to /chat/completions in 0.928292 seconds
2024-11-30 15:42:40,984 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Nuclear family\nSituation: Sarah and Tom, neighbors, at a community park'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 15:42:40,985 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 15:42:40,986 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 15:42:40,987 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 15:42:40,987 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 15:42:40,988 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 15:42:40,988 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 15:42:41,341 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 15:42:45 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_697ba7ff165cac009bb4580af93fc709'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eabf2fcbdd62362-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 15:42:41,341 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 15:42:41,342 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 15:42:41,342 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 15:42:41,343 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 15:42:41,343 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 15:42:41,344 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 15:42:45 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_697ba7ff165cac009bb4580af93fc709', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eabf2fcbdd62362-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 15:42:41,344 - openai._base_client - DEBUG - request_id: req_697ba7ff165cac009bb4580af93fc709
2024-11-30 15:42:41,344 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 15:42:41,345 - openai._base_client - DEBUG - Re-raising status error
2024-11-30 15:42:44,355 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Nuclear family\nSituation: Sarah and Tom, neighbors, at a community park'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 15:42:44,356 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 15:42:44,357 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 15:42:44,358 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 15:42:44,359 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 15:42:44,359 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 15:42:44,360 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 15:42:45,036 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 15:42:48 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_16081143dcd90c42a01d6c5e5658a4f9'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eabf311cedb2362-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 15:42:45,037 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 15:42:45,038 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 15:42:45,039 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 15:42:45,039 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 15:42:45,040 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 15:42:45,040 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 15:42:48 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_16081143dcd90c42a01d6c5e5658a4f9', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eabf311cedb2362-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 15:42:45,041 - openai._base_client - DEBUG - request_id: req_16081143dcd90c42a01d6c5e5658a4f9
2024-11-30 15:42:45,042 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 15:42:45,043 - openai._base_client - DEBUG - Retrying due to status code 429
2024-11-30 15:42:45,043 - openai._base_client - DEBUG - 2 retries left
2024-11-30 15:42:45,044 - openai._base_client - INFO - Retrying request to /chat/completions in 0.403824 seconds
2024-11-30 15:42:45,449 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Nuclear family\nSituation: Sarah and Tom, neighbors, at a community park'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 15:42:45,450 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 15:42:45,451 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 15:42:45,452 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 15:42:45,452 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 15:42:45,453 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 15:42:45,453 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 15:42:45,807 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 15:42:49 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_d25ea9c8a44d3d70bc376344ebe8f169'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eabf318ae652362-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 15:42:45,809 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 15:42:45,809 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 15:42:45,811 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 15:42:45,812 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 15:42:45,813 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 15:42:45,814 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 15:42:49 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_d25ea9c8a44d3d70bc376344ebe8f169', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eabf318ae652362-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 15:42:45,814 - openai._base_client - DEBUG - request_id: req_d25ea9c8a44d3d70bc376344ebe8f169
2024-11-30 15:42:45,815 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 15:42:45,816 - openai._base_client - DEBUG - Retrying due to status code 429
2024-11-30 15:42:45,817 - openai._base_client - DEBUG - 1 retry left
2024-11-30 15:42:45,817 - openai._base_client - INFO - Retrying request to /chat/completions in 0.987585 seconds
2024-11-30 15:42:46,807 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Nuclear family\nSituation: Sarah and Tom, neighbors, at a community park'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 15:42:46,809 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 15:42:46,810 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 15:42:46,811 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 15:42:46,811 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 15:42:46,812 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 15:42:46,813 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 15:42:47,194 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 15:42:51 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_18b1330c84b7e331911312cc8923c86f'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eabf3212a9c2362-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 15:42:47,195 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 15:42:47,196 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 15:42:47,196 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 15:42:47,197 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 15:42:47,197 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 15:42:47,198 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 15:42:51 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_18b1330c84b7e331911312cc8923c86f', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eabf3212a9c2362-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 15:42:47,198 - openai._base_client - DEBUG - request_id: req_18b1330c84b7e331911312cc8923c86f
2024-11-30 15:42:47,199 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 15:42:47,200 - openai._base_client - DEBUG - Re-raising status error
2024-11-30 15:42:47,201 - __main__ - ERROR - Order 1, Input: 'Topic: talk about your family - Family size and type
Given vocabulary: Nuclear family
Situation: Sarah and Tom, neighbors, at a community park', Response: 'Request failed after 2 retries.'
2024-11-30 15:42:47,201 - __main__ - DEBUG - Processed row - Order: 1
2024-11-30 15:42:47,202 - __main__ - DEBUG - Response: Request failed after 2 retries.
2024-11-30 15:42:47,211 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Generational family\nSituation: Aubrey and Isaac, engineers, at a construction site'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 15:42:47,213 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 15:42:47,214 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 15:42:47,214 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 15:42:47,215 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 15:42:47,216 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 15:42:47,216 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 15:42:47,565 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 15:42:51 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_e5e7859df5d561a78dd639a1ff849e26'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eabf323adef2362-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 15:42:47,566 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 15:42:47,567 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 15:42:47,567 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 15:42:47,568 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 15:42:47,568 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 15:42:47,568 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 15:42:51 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_e5e7859df5d561a78dd639a1ff849e26', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eabf323adef2362-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 15:42:47,569 - openai._base_client - DEBUG - request_id: req_e5e7859df5d561a78dd639a1ff849e26
2024-11-30 15:42:47,569 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 15:42:47,570 - openai._base_client - DEBUG - Retrying due to status code 429
2024-11-30 15:42:47,570 - openai._base_client - DEBUG - 2 retries left
2024-11-30 15:42:47,571 - openai._base_client - INFO - Retrying request to /chat/completions in 0.387826 seconds
2024-11-30 15:42:47,960 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Generational family\nSituation: Aubrey and Isaac, engineers, at a construction site'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 15:42:47,961 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 15:42:47,962 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 15:42:47,962 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 15:42:47,963 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 15:42:47,963 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 15:42:47,964 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 15:42:48,335 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 15:42:52 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_6f539329faa7eef8fa64d091aa78e0e6'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eabf3285b3d2362-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 15:42:48,336 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 15:42:48,337 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 15:42:48,337 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 15:42:48,338 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 15:42:48,338 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 15:42:48,339 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 15:42:52 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_6f539329faa7eef8fa64d091aa78e0e6', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eabf3285b3d2362-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 15:42:48,339 - openai._base_client - DEBUG - request_id: req_6f539329faa7eef8fa64d091aa78e0e6
2024-11-30 15:42:48,340 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 15:42:48,340 - openai._base_client - DEBUG - Retrying due to status code 429
2024-11-30 15:42:48,341 - openai._base_client - DEBUG - 1 retry left
2024-11-30 15:42:48,341 - openai._base_client - INFO - Retrying request to /chat/completions in 0.993299 seconds
2024-11-30 15:42:49,336 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Generational family\nSituation: Aubrey and Isaac, engineers, at a construction site'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 15:42:49,338 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 15:42:49,338 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 15:42:49,339 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 15:42:49,340 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 15:42:49,340 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 15:42:49,341 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 15:42:49,868 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 15:42:54 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_54bb389a8f550b7cfca48926fddb4a51'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eabf3319e0a2362-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 15:42:49,869 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 15:42:49,870 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 15:42:49,871 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 15:42:49,871 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 15:42:49,872 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 15:42:49,873 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 15:42:54 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_54bb389a8f550b7cfca48926fddb4a51', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eabf3319e0a2362-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 15:42:49,873 - openai._base_client - DEBUG - request_id: req_54bb389a8f550b7cfca48926fddb4a51
2024-11-30 15:42:49,874 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 15:42:49,875 - openai._base_client - DEBUG - Re-raising status error
2024-11-30 15:42:52,883 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Generational family\nSituation: Aubrey and Isaac, engineers, at a construction site'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 15:42:52,885 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 15:42:52,885 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 15:42:52,886 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 15:42:52,886 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 15:42:52,887 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 15:42:52,887 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 15:42:53,350 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 15:42:57 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_f0359844f124318fc5200a6ba66a55fa'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eabf3471d802362-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 15:42:53,351 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 15:42:53,351 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 15:42:53,352 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 15:42:53,352 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 15:42:53,353 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 15:42:53,353 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 15:42:57 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_f0359844f124318fc5200a6ba66a55fa', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eabf3471d802362-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 15:42:53,353 - openai._base_client - DEBUG - request_id: req_f0359844f124318fc5200a6ba66a55fa
2024-11-30 15:42:53,354 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 15:42:53,354 - openai._base_client - DEBUG - Retrying due to status code 429
2024-11-30 15:42:53,355 - openai._base_client - DEBUG - 2 retries left
2024-11-30 15:42:53,355 - openai._base_client - INFO - Retrying request to /chat/completions in 0.383047 seconds
2024-11-30 15:42:53,739 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Generational family\nSituation: Aubrey and Isaac, engineers, at a construction site'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 15:42:53,740 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 15:42:53,741 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 15:42:53,742 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 15:42:53,742 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 15:42:53,743 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 15:42:53,743 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 15:42:54,109 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 15:42:58 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_d3d94772c3d88c82895fe05ec6ced3f3'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eabf34c8bb62362-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 15:42:54,110 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 15:42:54,110 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 15:42:54,111 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 15:42:54,111 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 15:42:54,111 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 15:42:54,112 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 15:42:58 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_d3d94772c3d88c82895fe05ec6ced3f3', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eabf34c8bb62362-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 15:42:54,112 - openai._base_client - DEBUG - request_id: req_d3d94772c3d88c82895fe05ec6ced3f3
2024-11-30 15:42:54,113 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 15:42:54,113 - openai._base_client - DEBUG - Retrying due to status code 429
2024-11-30 15:42:54,114 - openai._base_client - DEBUG - 1 retry left
2024-11-30 15:42:54,114 - openai._base_client - INFO - Retrying request to /chat/completions in 0.781566 seconds
2024-11-30 15:42:54,897 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Generational family\nSituation: Aubrey and Isaac, engineers, at a construction site'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 15:42:54,898 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 15:42:54,899 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 15:42:54,900 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 15:42:54,900 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 15:42:54,901 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 15:42:54,901 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 15:42:55,256 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 15:42:59 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_8c563e517e1f150eb5454591540bffa8'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eabf353ab412362-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 15:42:55,257 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 15:42:55,257 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 15:42:55,257 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 15:42:55,258 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 15:42:55,258 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 15:42:55,259 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 15:42:59 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_8c563e517e1f150eb5454591540bffa8', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eabf353ab412362-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 15:42:55,259 - openai._base_client - DEBUG - request_id: req_8c563e517e1f150eb5454591540bffa8
2024-11-30 15:42:55,259 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 15:42:55,260 - openai._base_client - DEBUG - Re-raising status error
2024-11-30 15:42:58,273 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Generational family\nSituation: Aubrey and Isaac, engineers, at a construction site'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 15:42:58,274 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 15:42:58,275 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 15:42:58,276 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 15:42:58,277 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 15:42:58,277 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 15:42:58,278 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 15:42:58,633 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 15:43:02 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_e22caaa416926bfa1abf3f2cd76f36f8'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eabf368cc462362-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 15:42:58,634 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 15:42:58,635 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 15:42:58,636 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 15:42:58,636 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 15:42:58,637 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 15:42:58,637 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 15:43:02 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_e22caaa416926bfa1abf3f2cd76f36f8', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eabf368cc462362-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 15:42:58,638 - openai._base_client - DEBUG - request_id: req_e22caaa416926bfa1abf3f2cd76f36f8
2024-11-30 15:42:58,639 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 15:42:58,639 - openai._base_client - DEBUG - Retrying due to status code 429
2024-11-30 15:42:58,640 - openai._base_client - DEBUG - 2 retries left
2024-11-30 15:42:58,640 - openai._base_client - INFO - Retrying request to /chat/completions in 0.427982 seconds
2024-11-30 15:42:59,069 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Generational family\nSituation: Aubrey and Isaac, engineers, at a construction site'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 15:42:59,072 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 15:42:59,073 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 15:42:59,074 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 15:42:59,075 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 15:42:59,076 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 15:42:59,076 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 15:42:59,423 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 15:43:03 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_11174cec4cd70b77e77a83389c26a451'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eabf36dc9602362-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 15:42:59,424 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 15:42:59,425 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 15:42:59,425 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 15:42:59,426 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 15:42:59,427 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 15:42:59,427 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 15:43:03 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_11174cec4cd70b77e77a83389c26a451', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eabf36dc9602362-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 15:42:59,428 - openai._base_client - DEBUG - request_id: req_11174cec4cd70b77e77a83389c26a451
2024-11-30 15:42:59,428 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 15:42:59,429 - openai._base_client - DEBUG - Retrying due to status code 429
2024-11-30 15:42:59,430 - openai._base_client - DEBUG - 1 retry left
2024-11-30 15:42:59,431 - openai._base_client - INFO - Retrying request to /chat/completions in 0.977806 seconds
2024-11-30 15:43:00,410 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Generational family\nSituation: Aubrey and Isaac, engineers, at a construction site'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 15:43:00,412 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 15:43:00,412 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 15:43:00,413 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 15:43:00,414 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 15:43:00,414 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 15:43:00,415 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 15:43:00,758 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 15:43:04 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_2d1bd52021e80ec58e6dda071610e78f'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eabf3762b5d2362-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 15:43:00,759 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 15:43:00,760 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 15:43:00,760 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 15:43:00,761 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 15:43:00,761 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 15:43:00,762 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 15:43:04 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_2d1bd52021e80ec58e6dda071610e78f', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eabf3762b5d2362-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 15:43:00,762 - openai._base_client - DEBUG - request_id: req_2d1bd52021e80ec58e6dda071610e78f
2024-11-30 15:43:00,763 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 15:43:00,763 - openai._base_client - DEBUG - Re-raising status error
2024-11-30 15:43:00,764 - __main__ - ERROR - Order 2, Input: 'Topic: talk about your family - Family size and type
Given vocabulary: Generational family
Situation: Aubrey and Isaac, engineers, at a construction site', Response: 'Request failed after 2 retries.'
2024-11-30 15:43:00,765 - __main__ - DEBUG - Processed row - Order: 2
2024-11-30 15:43:00,765 - __main__ - DEBUG - Response: Request failed after 2 retries.
2024-11-30 15:43:00,794 - __main__ - INFO - Output saved to /app/output/output_draft.xlsx
2024-11-30 15:43:00,794 - __main__ - INFO - Starting story data processing
2024-11-30 15:43:00,813 - __main__ - DEBUG - Processing story data for order 1
2024-11-30 15:43:00,813 - __main__ - WARNING - Invalid JSON for order 1, skipping
2024-11-30 15:43:00,814 - __main__ - DEBUG - Processing story data for order 2
2024-11-30 15:43:00,814 - __main__ - WARNING - Invalid JSON for order 2, skipping
2024-11-30 15:43:00,844 - __main__ - INFO - Story data processing complete, saved to /app/output/output_story.xlsx
2024-11-30 15:43:00,845 - __main__ - INFO - Starting audio generation
2024-11-30 15:43:00,874 - __main__ - DEBUG - Generating audio for order 1
2024-11-30 15:43:00,875 - __main__ - ERROR - Error in generate_audio: Expecting value: line 1 column 1 (char 0)
Traceback (most recent call last):
  File "/app/scripts/generate_story.py", line 235, in generate_audio
    data = json.loads(row['json'])
  File "/usr/local/lib/python3.9/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.9/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.9/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
2024-11-30 15:43:00,883 - __main__ - ERROR - Error in main: Expecting value: line 1 column 1 (char 0)
Traceback (most recent call last):
  File "/app/scripts/generate_story.py", line 275, in main
    generate_audio()
  File "/app/scripts/generate_story.py", line 235, in generate_audio
    data = json.loads(row['json'])
  File "/usr/local/lib/python3.9/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.9/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.9/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
2024-11-30 16:47:12,595 - __main__ - DEBUG - OpenAI API key loaded: ********************************************************************************************************************************************************************
2024-11-30 16:47:12,596 - __main__ - DEBUG - Upload folder path: /app/uploads
2024-11-30 16:47:12,597 - __main__ - DEBUG - Output folder path: /app/output
2024-11-30 16:47:12,597 - __main__ - INFO - Starting main process
2024-11-30 16:47:12,599 - __main__ - INFO - Starting initial data processing
2024-11-30 16:47:12,870 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Nuclear family\nSituation: Sarah and Tom, neighbors, at a community park'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 16:47:12,882 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 16:47:12,883 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-11-30 16:47:12,969 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9146aabbe0>
2024-11-30 16:47:12,971 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f91491ef6c0> server_hostname='api.openai.com' timeout=5.0
2024-11-30 16:47:13,106 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9146aab970>
2024-11-30 16:47:13,108 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 16:47:13,108 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 16:47:13,109 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 16:47:13,110 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 16:47:13,110 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 16:47:13,978 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 16:47:19 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_622dd9650be40dfea08df71050c86477'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=D4OxRdg7WyNUpuAv73lQzYEA.LYSmO6tZ1t8Vc6c0LI-1732985239-1.0.1.1-o2..y1ITlT4aNbLcCSGd.7P961CdVXX7PqHQB8MVVTvCFShfyR.9QpIMNacCb.BLIy6WfOyJx3C59Pzq4SR1bA; path=/; expires=Sat, 30-Nov-24 17:17:19 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=bQxuzEEfrbYNPC9jkmuzClrDovY0iAgrT2mw004BZNQ-1732985239058-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eac518b29de8617-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 16:47:13,980 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 16:47:13,981 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 16:47:13,981 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 16:47:13,982 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 16:47:13,982 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 16:47:13,983 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers([('date', 'Sat, 30 Nov 2024 16:47:19 GMT'), ('content-type', 'application/json; charset=utf-8'), ('content-length', '337'), ('connection', 'keep-alive'), ('vary', 'Origin'), ('x-request-id', 'req_622dd9650be40dfea08df71050c86477'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=D4OxRdg7WyNUpuAv73lQzYEA.LYSmO6tZ1t8Vc6c0LI-1732985239-1.0.1.1-o2..y1ITlT4aNbLcCSGd.7P961CdVXX7PqHQB8MVVTvCFShfyR.9QpIMNacCb.BLIy6WfOyJx3C59Pzq4SR1bA; path=/; expires=Sat, 30-Nov-24 17:17:19 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=bQxuzEEfrbYNPC9jkmuzClrDovY0iAgrT2mw004BZNQ-1732985239058-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8eac518b29de8617-HKG'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-11-30 16:47:13,984 - openai._base_client - DEBUG - request_id: req_622dd9650be40dfea08df71050c86477
2024-11-30 16:47:13,984 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 16:47:13,986 - openai._base_client - DEBUG - Retrying due to status code 429
2024-11-30 16:47:13,987 - openai._base_client - DEBUG - 2 retries left
2024-11-30 16:47:13,987 - openai._base_client - INFO - Retrying request to /chat/completions in 0.499743 seconds
2024-11-30 16:47:14,488 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Nuclear family\nSituation: Sarah and Tom, neighbors, at a community park'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 16:47:14,490 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 16:47:14,491 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 16:47:14,492 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 16:47:14,492 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 16:47:14,493 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 16:47:14,494 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 16:47:14,904 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 16:47:19 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_0f8775f64598589da173713355634488'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eac5193cf1f8617-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 16:47:14,905 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 16:47:14,905 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 16:47:14,906 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 16:47:14,907 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 16:47:14,907 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 16:47:14,908 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 16:47:19 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_0f8775f64598589da173713355634488', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eac5193cf1f8617-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 16:47:14,909 - openai._base_client - DEBUG - request_id: req_0f8775f64598589da173713355634488
2024-11-30 16:47:14,909 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 16:47:14,910 - openai._base_client - DEBUG - Retrying due to status code 429
2024-11-30 16:47:14,911 - openai._base_client - DEBUG - 1 retry left
2024-11-30 16:47:14,911 - openai._base_client - INFO - Retrying request to /chat/completions in 0.859982 seconds
2024-11-30 16:47:15,773 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Nuclear family\nSituation: Sarah and Tom, neighbors, at a community park'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 16:47:15,775 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 16:47:15,776 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 16:47:15,777 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 16:47:15,778 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 16:47:15,778 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 16:47:15,779 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 16:47:16,232 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 16:47:21 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_faffe44a0edeaaf470fd2f984c4b3989'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eac519bdb478617-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 16:47:16,233 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 16:47:16,234 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 16:47:16,234 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 16:47:16,235 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 16:47:16,235 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 16:47:16,236 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 16:47:21 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_faffe44a0edeaaf470fd2f984c4b3989', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eac519bdb478617-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 16:47:16,237 - openai._base_client - DEBUG - request_id: req_faffe44a0edeaaf470fd2f984c4b3989
2024-11-30 16:47:16,237 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 16:47:16,238 - openai._base_client - DEBUG - Re-raising status error
2024-11-30 16:47:19,250 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Nuclear family\nSituation: Sarah and Tom, neighbors, at a community park'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 16:47:19,252 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 16:47:19,253 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 16:47:19,254 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 16:47:19,255 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 16:47:19,256 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 16:47:19,256 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 16:47:19,717 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 16:47:24 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_b38727bd7726529ec5afd6aa66f781ab'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eac51b18eb58617-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 16:47:19,718 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 16:47:19,719 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 16:47:19,720 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 16:47:19,720 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 16:47:19,721 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 16:47:19,721 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 16:47:24 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_b38727bd7726529ec5afd6aa66f781ab', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eac51b18eb58617-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 16:47:19,722 - openai._base_client - DEBUG - request_id: req_b38727bd7726529ec5afd6aa66f781ab
2024-11-30 16:47:19,723 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 16:47:19,723 - openai._base_client - DEBUG - Retrying due to status code 429
2024-11-30 16:47:19,724 - openai._base_client - DEBUG - 2 retries left
2024-11-30 16:47:19,724 - openai._base_client - INFO - Retrying request to /chat/completions in 0.384326 seconds
2024-11-30 16:47:20,110 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Nuclear family\nSituation: Sarah and Tom, neighbors, at a community park'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 16:47:20,112 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 16:47:20,113 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 16:47:20,114 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 16:47:20,115 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 16:47:20,116 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 16:47:20,116 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 16:47:20,530 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 16:47:25 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_3e9acee2016ce0479ed98b92ab1f4124'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eac51b70f858617-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 16:47:20,531 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 16:47:20,532 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 16:47:20,533 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 16:47:20,534 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 16:47:20,534 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 16:47:20,535 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 16:47:25 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_3e9acee2016ce0479ed98b92ab1f4124', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eac51b70f858617-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 16:47:20,536 - openai._base_client - DEBUG - request_id: req_3e9acee2016ce0479ed98b92ab1f4124
2024-11-30 16:47:20,537 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 16:47:20,537 - openai._base_client - DEBUG - Retrying due to status code 429
2024-11-30 16:47:20,538 - openai._base_client - DEBUG - 1 retry left
2024-11-30 16:47:20,539 - openai._base_client - INFO - Retrying request to /chat/completions in 0.996211 seconds
2024-11-30 16:47:21,537 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Nuclear family\nSituation: Sarah and Tom, neighbors, at a community park'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 16:47:21,539 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 16:47:21,540 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 16:47:21,541 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 16:47:21,542 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 16:47:21,543 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 16:47:21,544 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 16:47:21,966 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 16:47:26 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_bd30142ff4ee0a2585c4f91eee6800d7'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eac51bfde9e8617-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 16:47:21,967 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 16:47:21,968 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 16:47:21,969 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 16:47:21,969 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 16:47:21,970 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 16:47:21,971 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 16:47:26 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_bd30142ff4ee0a2585c4f91eee6800d7', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eac51bfde9e8617-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 16:47:21,971 - openai._base_client - DEBUG - request_id: req_bd30142ff4ee0a2585c4f91eee6800d7
2024-11-30 16:47:21,972 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 16:47:21,973 - openai._base_client - DEBUG - Re-raising status error
2024-11-30 16:47:24,984 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Nuclear family\nSituation: Sarah and Tom, neighbors, at a community park'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 16:47:24,986 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 16:47:24,987 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 16:47:24,988 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 16:47:24,988 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 16:47:24,989 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 16:47:24,990 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 16:47:25,451 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 16:47:30 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_5afb3e15d4e538599c52d2df98250568'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eac51d56a778617-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 16:47:25,452 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 16:47:25,453 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 16:47:25,453 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 16:47:25,454 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 16:47:25,455 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 16:47:25,455 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 16:47:30 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_5afb3e15d4e538599c52d2df98250568', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eac51d56a778617-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 16:47:25,456 - openai._base_client - DEBUG - request_id: req_5afb3e15d4e538599c52d2df98250568
2024-11-30 16:47:25,457 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 16:47:25,458 - openai._base_client - DEBUG - Retrying due to status code 429
2024-11-30 16:47:25,458 - openai._base_client - DEBUG - 2 retries left
2024-11-30 16:47:25,459 - openai._base_client - INFO - Retrying request to /chat/completions in 0.446819 seconds
2024-11-30 16:47:25,907 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Nuclear family\nSituation: Sarah and Tom, neighbors, at a community park'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 16:47:25,909 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 16:47:25,910 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 16:47:25,911 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 16:47:25,912 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 16:47:25,913 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 16:47:25,913 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 16:47:26,268 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 16:47:31 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_179ac3815507c1480cbf006c8434a6a8'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eac51db2a9a8617-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 16:47:26,270 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 16:47:26,270 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 16:47:26,271 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 16:47:26,272 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 16:47:26,272 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 16:47:26,273 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 16:47:31 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_179ac3815507c1480cbf006c8434a6a8', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eac51db2a9a8617-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 16:47:26,273 - openai._base_client - DEBUG - request_id: req_179ac3815507c1480cbf006c8434a6a8
2024-11-30 16:47:26,274 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 16:47:26,275 - openai._base_client - DEBUG - Retrying due to status code 429
2024-11-30 16:47:26,275 - openai._base_client - DEBUG - 1 retry left
2024-11-30 16:47:26,276 - openai._base_client - INFO - Retrying request to /chat/completions in 0.992186 seconds
2024-11-30 16:47:27,270 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Nuclear family\nSituation: Sarah and Tom, neighbors, at a community park'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 16:47:27,272 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 16:47:27,273 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 16:47:27,273 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 16:47:27,274 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 16:47:27,275 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 16:47:27,275 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 16:47:27,700 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 16:47:32 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_367a0945fb7235fb8236ff1e3d5e3473'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eac51e3a8658617-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 16:47:27,701 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 16:47:27,702 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 16:47:27,703 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 16:47:27,703 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 16:47:27,704 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 16:47:27,704 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 16:47:32 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_367a0945fb7235fb8236ff1e3d5e3473', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eac51e3a8658617-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 16:47:27,705 - openai._base_client - DEBUG - request_id: req_367a0945fb7235fb8236ff1e3d5e3473
2024-11-30 16:47:27,706 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 16:47:27,706 - openai._base_client - DEBUG - Re-raising status error
2024-11-30 16:47:27,707 - __main__ - ERROR - Order 999, Input: 'Topic: talk about your family - Family size and type
Given vocabulary: Nuclear family
Situation: Sarah and Tom, neighbors, at a community park', Response: 'Request failed after 2 retries.'
2024-11-30 16:47:27,708 - __main__ - DEBUG - Processed row - Order: 999
2024-11-30 16:47:27,709 - __main__ - DEBUG - Response: Request failed after 2 retries.
2024-11-30 16:47:27,723 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Generational family\nSituation: Aubrey and Isaac, engineers, at a construction site'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 16:47:27,727 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 16:47:27,728 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 16:47:27,729 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 16:47:27,729 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 16:47:27,731 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 16:47:27,732 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 16:47:28,064 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 16:47:33 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_3dad9444362e6399b3ddc9bc61fc7329'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eac51e67cd38617-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 16:47:28,065 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 16:47:28,066 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 16:47:28,066 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 16:47:28,067 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 16:47:28,067 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 16:47:28,068 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 16:47:33 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_3dad9444362e6399b3ddc9bc61fc7329', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eac51e67cd38617-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 16:47:28,069 - openai._base_client - DEBUG - request_id: req_3dad9444362e6399b3ddc9bc61fc7329
2024-11-30 16:47:28,069 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 16:47:28,070 - openai._base_client - DEBUG - Retrying due to status code 429
2024-11-30 16:47:28,071 - openai._base_client - DEBUG - 2 retries left
2024-11-30 16:47:28,071 - openai._base_client - INFO - Retrying request to /chat/completions in 0.393155 seconds
2024-11-30 16:47:28,465 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Generational family\nSituation: Aubrey and Isaac, engineers, at a construction site'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 16:47:28,467 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 16:47:28,467 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 16:47:28,468 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 16:47:28,468 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 16:47:28,469 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 16:47:28,469 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 16:47:28,802 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 16:47:33 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_f4bcd1d6d7b03aee67850f14d60c3396'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eac51eb1c5f8617-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 16:47:28,803 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 16:47:28,804 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 16:47:28,804 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 16:47:28,804 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 16:47:28,805 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 16:47:28,805 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 16:47:33 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_f4bcd1d6d7b03aee67850f14d60c3396', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eac51eb1c5f8617-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 16:47:28,806 - openai._base_client - DEBUG - request_id: req_f4bcd1d6d7b03aee67850f14d60c3396
2024-11-30 16:47:28,806 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 16:47:28,807 - openai._base_client - DEBUG - Retrying due to status code 429
2024-11-30 16:47:28,807 - openai._base_client - DEBUG - 1 retry left
2024-11-30 16:47:28,808 - openai._base_client - INFO - Retrying request to /chat/completions in 0.803166 seconds
2024-11-30 16:47:29,612 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Generational family\nSituation: Aubrey and Isaac, engineers, at a construction site'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 16:47:29,613 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 16:47:29,614 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 16:47:29,614 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 16:47:29,615 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 16:47:29,616 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 16:47:29,616 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 16:47:29,950 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 16:47:35 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_9b24eabac5e6f8972a2cf8c00d32d06c'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eac51f24ff18617-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 16:47:29,951 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 16:47:29,952 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 16:47:29,953 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 16:47:29,954 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 16:47:29,954 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 16:47:29,955 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 16:47:35 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_9b24eabac5e6f8972a2cf8c00d32d06c', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eac51f24ff18617-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 16:47:29,955 - openai._base_client - DEBUG - request_id: req_9b24eabac5e6f8972a2cf8c00d32d06c
2024-11-30 16:47:29,956 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 16:47:29,957 - openai._base_client - DEBUG - Re-raising status error
2024-11-30 16:47:32,963 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Generational family\nSituation: Aubrey and Isaac, engineers, at a construction site'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 16:47:32,964 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 16:47:32,964 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 16:47:32,965 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 16:47:32,965 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 16:47:32,966 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 16:47:32,966 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 16:47:33,331 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 16:47:38 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_9caef85a0b7cfd972ee3b62272a6a320'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eac52076a018617-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 16:47:33,332 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 16:47:33,332 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 16:47:33,333 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 16:47:33,333 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 16:47:33,334 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 16:47:33,334 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 16:47:38 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_9caef85a0b7cfd972ee3b62272a6a320', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eac52076a018617-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 16:47:33,335 - openai._base_client - DEBUG - request_id: req_9caef85a0b7cfd972ee3b62272a6a320
2024-11-30 16:47:33,335 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 16:47:33,335 - openai._base_client - DEBUG - Retrying due to status code 429
2024-11-30 16:47:33,336 - openai._base_client - DEBUG - 2 retries left
2024-11-30 16:47:33,336 - openai._base_client - INFO - Retrying request to /chat/completions in 0.463252 seconds
2024-11-30 16:47:33,800 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Generational family\nSituation: Aubrey and Isaac, engineers, at a construction site'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 16:47:33,801 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 16:47:33,802 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 16:47:33,802 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 16:47:33,803 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 16:47:33,804 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 16:47:33,804 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 16:47:34,172 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 16:47:39 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_d9ab693b9510d05905c87b4e89052b40'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eac520c79d78617-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 16:47:34,172 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 16:47:34,173 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 16:47:34,174 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 16:47:34,174 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 16:47:34,175 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 16:47:34,175 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 16:47:39 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_d9ab693b9510d05905c87b4e89052b40', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eac520c79d78617-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 16:47:34,176 - openai._base_client - DEBUG - request_id: req_d9ab693b9510d05905c87b4e89052b40
2024-11-30 16:47:34,176 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 16:47:34,177 - openai._base_client - DEBUG - Retrying due to status code 429
2024-11-30 16:47:34,177 - openai._base_client - DEBUG - 1 retry left
2024-11-30 16:47:34,178 - openai._base_client - INFO - Retrying request to /chat/completions in 0.869761 seconds
2024-11-30 16:47:35,049 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Generational family\nSituation: Aubrey and Isaac, engineers, at a construction site'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 16:47:35,050 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 16:47:35,050 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 16:47:35,051 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 16:47:35,052 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 16:47:35,052 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 16:47:35,053 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 16:47:35,390 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 16:47:40 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_9363828fcb60362bf95677946280af91'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eac52144e158617-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 16:47:35,391 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 16:47:35,392 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 16:47:35,392 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 16:47:35,392 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 16:47:35,393 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 16:47:35,393 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 16:47:40 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_9363828fcb60362bf95677946280af91', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eac52144e158617-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 16:47:35,394 - openai._base_client - DEBUG - request_id: req_9363828fcb60362bf95677946280af91
2024-11-30 16:47:35,394 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 16:47:35,395 - openai._base_client - DEBUG - Re-raising status error
2024-11-30 16:47:38,403 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Generational family\nSituation: Aubrey and Isaac, engineers, at a construction site'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 16:47:38,405 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 16:47:38,406 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 16:47:38,407 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 16:47:38,407 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 16:47:38,408 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 16:47:38,409 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 16:47:38,783 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 16:47:43 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_96f38e37e84d3d9c09b9508671ea9d40'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eac52294f1d8617-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 16:47:38,784 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 16:47:38,784 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 16:47:38,785 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 16:47:38,785 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 16:47:38,785 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 16:47:38,786 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 16:47:43 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_96f38e37e84d3d9c09b9508671ea9d40', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eac52294f1d8617-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 16:47:38,787 - openai._base_client - DEBUG - request_id: req_96f38e37e84d3d9c09b9508671ea9d40
2024-11-30 16:47:38,787 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 16:47:38,788 - openai._base_client - DEBUG - Retrying due to status code 429
2024-11-30 16:47:38,788 - openai._base_client - DEBUG - 2 retries left
2024-11-30 16:47:38,789 - openai._base_client - INFO - Retrying request to /chat/completions in 0.499617 seconds
2024-11-30 16:47:39,290 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Generational family\nSituation: Aubrey and Isaac, engineers, at a construction site'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 16:47:39,291 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 16:47:39,292 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 16:47:39,293 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 16:47:39,293 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 16:47:39,294 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 16:47:39,294 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 16:47:39,637 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 16:47:44 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_bd8d0e8c5504169e7dd4cbcb8875012b'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eac522ec8908617-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 16:47:39,637 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 16:47:39,638 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 16:47:39,638 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 16:47:39,639 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 16:47:39,639 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 16:47:39,639 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 16:47:44 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_bd8d0e8c5504169e7dd4cbcb8875012b', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eac522ec8908617-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 16:47:39,640 - openai._base_client - DEBUG - request_id: req_bd8d0e8c5504169e7dd4cbcb8875012b
2024-11-30 16:47:39,640 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 16:47:39,641 - openai._base_client - DEBUG - Retrying due to status code 429
2024-11-30 16:47:39,641 - openai._base_client - DEBUG - 1 retry left
2024-11-30 16:47:39,642 - openai._base_client - INFO - Retrying request to /chat/completions in 0.918127 seconds
2024-11-30 16:47:40,561 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Generational family\nSituation: Aubrey and Isaac, engineers, at a construction site'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-11-30 16:47:40,563 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-30 16:47:40,563 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-30 16:47:40,564 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-30 16:47:40,565 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-30 16:47:40,565 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-30 16:47:40,566 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-30 16:47:40,914 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 30 Nov 2024 16:47:46 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_4f3545d8639901288a182eb0f1d2d32f'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eac5236bc5b8617-HKG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-30 16:47:40,915 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2024-11-30 16:47:40,915 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-30 16:47:40,916 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-30 16:47:40,916 - httpcore.http11 - DEBUG - response_closed.started
2024-11-30 16:47:40,917 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-30 16:47:40,917 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 30 Nov 2024 16:47:46 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_4f3545d8639901288a182eb0f1d2d32f', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eac5236bc5b8617-HKG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-30 16:47:40,918 - openai._base_client - DEBUG - request_id: req_4f3545d8639901288a182eb0f1d2d32f
2024-11-30 16:47:40,918 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/openai/_base_client.py", line 1040, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.9/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2024-11-30 16:47:40,919 - openai._base_client - DEBUG - Re-raising status error
2024-11-30 16:47:40,919 - __main__ - ERROR - Order 2, Input: 'Topic: talk about your family - Family size and type
Given vocabulary: Generational family
Situation: Aubrey and Isaac, engineers, at a construction site', Response: 'Request failed after 2 retries.'
2024-11-30 16:47:40,920 - __main__ - DEBUG - Processed row - Order: 2
2024-11-30 16:47:40,920 - __main__ - DEBUG - Response: Request failed after 2 retries.
2024-11-30 16:47:40,944 - __main__ - INFO - Output saved to /app/output/output_draft.xlsx
2024-11-30 16:47:40,945 - __main__ - INFO - Starting story data processing
2024-11-30 16:47:40,960 - __main__ - DEBUG - Processing story data for order 999
2024-11-30 16:47:40,960 - __main__ - WARNING - Invalid JSON for order 999, skipping
2024-11-30 16:47:40,961 - __main__ - DEBUG - Processing story data for order 2
2024-11-30 16:47:40,962 - __main__ - WARNING - Invalid JSON for order 2, skipping
2024-11-30 16:47:40,985 - __main__ - INFO - Story data processing complete, saved to /app/output/output_story.xlsx
2024-11-30 16:47:40,985 - __main__ - INFO - Starting audio generation
2024-11-30 16:47:41,003 - __main__ - DEBUG - Generating audio for order 999
2024-11-30 16:47:41,004 - __main__ - ERROR - Error in generate_audio: Expecting value: line 1 column 1 (char 0)
Traceback (most recent call last):
  File "/app/scripts/generate_story.py", line 235, in generate_audio
    data = json.loads(row['json'])
  File "/usr/local/lib/python3.9/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.9/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.9/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
2024-11-30 16:47:41,011 - __main__ - ERROR - Error in main: Expecting value: line 1 column 1 (char 0)
Traceback (most recent call last):
  File "/app/scripts/generate_story.py", line 275, in main
    generate_audio()
  File "/app/scripts/generate_story.py", line 235, in generate_audio
    data = json.loads(row['json'])
  File "/usr/local/lib/python3.9/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.9/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.9/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
2024-12-02 17:42:51,322 - __main__ - DEBUG - OpenAI API key loaded: ****
2024-12-02 17:42:51,323 - __main__ - DEBUG - Upload folder path: /app/uploads
2024-12-02 17:42:51,323 - __main__ - DEBUG - Output folder path: /app/output
2024-12-02 17:42:51,324 - __main__ - INFO - Starting main process
2024-12-02 17:42:51,326 - __main__ - INFO - Starting initial data processing
2024-12-02 17:42:57,555 - __main__ - ERROR - Order 999, Input: 'Topic: talk about your family - Family size and type
Given vocabulary: Nuclear family
Situation: Sarah and Tom, neighbors, at a community park', Response: 'Request failed after 2 retries.'
2024-12-02 17:42:57,556 - __main__ - DEBUG - Processed row - Order: 999
2024-12-02 17:42:57,556 - __main__ - DEBUG - Response: Request failed after 2 retries.
2024-12-02 17:43:03,562 - __main__ - ERROR - Order 2, Input: 'Topic: talk about your family - Family size and type
Given vocabulary: Generational family
Situation: Aubrey and Isaac, engineers, at a construction site', Response: 'Request failed after 2 retries.'
2024-12-02 17:43:03,563 - __main__ - DEBUG - Processed row - Order: 2
2024-12-02 17:43:03,563 - __main__ - DEBUG - Response: Request failed after 2 retries.
2024-12-02 17:43:03,593 - __main__ - INFO - Output saved to /app/output/output_draft.xlsx
2024-12-02 17:43:03,594 - __main__ - INFO - Starting story data processing
2024-12-02 17:43:03,612 - __main__ - DEBUG - Processing story data for order 999
2024-12-02 17:43:03,613 - __main__ - WARNING - Invalid JSON for order 999, skipping
2024-12-02 17:43:03,613 - __main__ - DEBUG - Processing story data for order 2
2024-12-02 17:43:03,614 - __main__ - WARNING - Invalid JSON for order 2, skipping
2024-12-02 17:43:03,634 - __main__ - INFO - Story data processing complete, saved to /app/output/output_story.xlsx
2024-12-02 17:43:03,635 - __main__ - INFO - Starting audio generation
2024-12-02 17:43:03,658 - __main__ - DEBUG - Generating audio for order 999
2024-12-02 17:43:03,659 - __main__ - ERROR - Error in generate_audio: Expecting value: line 1 column 1 (char 0)
Traceback (most recent call last):
  File "/app/scripts/generate_story.py", line 235, in generate_audio
    data = json.loads(row['json'])
  File "/usr/local/lib/python3.9/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.9/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.9/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
2024-12-02 17:43:03,664 - __main__ - ERROR - Error in main: Expecting value: line 1 column 1 (char 0)
Traceback (most recent call last):
  File "/app/scripts/generate_story.py", line 275, in main
    generate_audio()
  File "/app/scripts/generate_story.py", line 235, in generate_audio
    data = json.loads(row['json'])
  File "/usr/local/lib/python3.9/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.9/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.9/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
2024-12-02 18:02:27,019 - __main__ - DEBUG - OpenAI API key loaded: ********************************************************************************************************************************************************************
2024-12-02 18:02:27,020 - __main__ - DEBUG - Upload folder path: /app/uploads
2024-12-02 18:02:27,020 - __main__ - DEBUG - Output folder path: /app/output
2024-12-02 18:02:27,021 - __main__ - INFO - Starting main process
2024-12-02 18:02:27,023 - __main__ - INFO - Starting initial data processing
2024-12-02 18:02:27,347 - __main__ - ERROR - Error in process_initial_data: 'prompt'
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/pandas/core/indexes/base.py", line 3805, in get_loc
    return self._engine.get_loc(casted_key)
  File "index.pyx", line 167, in pandas._libs.index.IndexEngine.get_loc
  File "index.pyx", line 196, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 7081, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 7089, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'prompt'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/app/scripts/generate_story.py", line 111, in process_initial_data
    prompt = row['prompt']
  File "/usr/local/lib/python3.9/site-packages/pandas/core/series.py", line 1121, in __getitem__
    return self._get_value(key)
  File "/usr/local/lib/python3.9/site-packages/pandas/core/series.py", line 1237, in _get_value
    loc = self.index.get_loc(label)
  File "/usr/local/lib/python3.9/site-packages/pandas/core/indexes/base.py", line 3812, in get_loc
    raise KeyError(key) from err
KeyError: 'prompt'
2024-12-02 18:02:27,366 - __main__ - ERROR - Error in main: 'prompt'
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/pandas/core/indexes/base.py", line 3805, in get_loc
    return self._engine.get_loc(casted_key)
  File "index.pyx", line 167, in pandas._libs.index.IndexEngine.get_loc
  File "index.pyx", line 196, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 7081, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 7089, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'prompt'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/app/scripts/generate_story.py", line 269, in main
    process_initial_data()
  File "/app/scripts/generate_story.py", line 111, in process_initial_data
    prompt = row['prompt']
  File "/usr/local/lib/python3.9/site-packages/pandas/core/series.py", line 1121, in __getitem__
    return self._get_value(key)
  File "/usr/local/lib/python3.9/site-packages/pandas/core/series.py", line 1237, in _get_value
    loc = self.index.get_loc(label)
  File "/usr/local/lib/python3.9/site-packages/pandas/core/indexes/base.py", line 3812, in get_loc
    raise KeyError(key) from err
KeyError: 'prompt'
2024-12-02 18:06:32,230 - __main__ - DEBUG - OpenAI API key loaded: ********************************************************************************************************************************************************************
2024-12-02 18:06:32,231 - __main__ - DEBUG - Upload folder path: /app/uploads
2024-12-02 18:06:32,231 - __main__ - DEBUG - Output folder path: /app/output
2024-12-02 18:06:32,232 - __main__ - INFO - Starting main process
2024-12-02 18:06:32,234 - __main__ - INFO - Starting initial data processing
2024-12-02 18:06:32,469 - __main__ - ERROR - Error in process_initial_data: 'prompt'
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/pandas/core/indexes/base.py", line 3805, in get_loc
    return self._engine.get_loc(casted_key)
  File "index.pyx", line 167, in pandas._libs.index.IndexEngine.get_loc
  File "index.pyx", line 196, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 7081, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 7089, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'prompt'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/app/scripts/generate_story.py", line 111, in process_initial_data
    prompt = row['prompt']
  File "/usr/local/lib/python3.9/site-packages/pandas/core/series.py", line 1121, in __getitem__
    return self._get_value(key)
  File "/usr/local/lib/python3.9/site-packages/pandas/core/series.py", line 1237, in _get_value
    loc = self.index.get_loc(label)
  File "/usr/local/lib/python3.9/site-packages/pandas/core/indexes/base.py", line 3812, in get_loc
    raise KeyError(key) from err
KeyError: 'prompt'
2024-12-02 18:06:32,481 - __main__ - ERROR - Error in main: 'prompt'
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/pandas/core/indexes/base.py", line 3805, in get_loc
    return self._engine.get_loc(casted_key)
  File "index.pyx", line 167, in pandas._libs.index.IndexEngine.get_loc
  File "index.pyx", line 196, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 7081, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 7089, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'prompt'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/app/scripts/generate_story.py", line 269, in main
    process_initial_data()
  File "/app/scripts/generate_story.py", line 111, in process_initial_data
    prompt = row['prompt']
  File "/usr/local/lib/python3.9/site-packages/pandas/core/series.py", line 1121, in __getitem__
    return self._get_value(key)
  File "/usr/local/lib/python3.9/site-packages/pandas/core/series.py", line 1237, in _get_value
    loc = self.index.get_loc(label)
  File "/usr/local/lib/python3.9/site-packages/pandas/core/indexes/base.py", line 3812, in get_loc
    raise KeyError(key) from err
KeyError: 'prompt'
2024-12-02 18:54:55,741 - __main__ - DEBUG - OpenAI API key loaded: ********************************************************************************************************************************************************************
2024-12-02 18:54:55,742 - __main__ - DEBUG - Upload folder path: /app/uploads
2024-12-02 18:54:55,742 - __main__ - DEBUG - Output folder path: /app/output
2024-12-02 18:54:55,743 - __main__ - INFO - Starting main process
2024-12-02 18:54:55,746 - __main__ - INFO - Starting initial data processing
2024-12-02 18:54:56,017 - __main__ - WARNING - Empty input for order 999, skipping
2024-12-02 18:54:56,019 - __main__ - DEBUG - Processed row - Order: 999
2024-12-02 18:54:56,019 - __main__ - DEBUG - Response: 
2024-12-02 18:54:56,020 - __main__ - WARNING - Empty input for order 2, skipping
2024-12-02 18:54:56,021 - __main__ - DEBUG - Processed row - Order: 2
2024-12-02 18:54:56,021 - __main__ - DEBUG - Response: 
2024-12-02 18:54:56,064 - __main__ - INFO - Output saved to /app/output/output_draft.xlsx
2024-12-02 18:54:56,064 - __main__ - INFO - Starting story data processing
2024-12-02 18:54:56,095 - __main__ - ERROR - Error in process_story_data: 'week'
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/pandas/core/indexes/base.py", line 3805, in get_loc
    return self._engine.get_loc(casted_key)
  File "index.pyx", line 167, in pandas._libs.index.IndexEngine.get_loc
  File "index.pyx", line 196, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 7081, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 7089, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'week'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/app/scripts/generate_story.py", line 156, in process_story_data
    stt_week = row['week']  # Get the week value from the DataFrame
  File "/usr/local/lib/python3.9/site-packages/pandas/core/series.py", line 1121, in __getitem__
    return self._get_value(key)
  File "/usr/local/lib/python3.9/site-packages/pandas/core/series.py", line 1237, in _get_value
    loc = self.index.get_loc(label)
  File "/usr/local/lib/python3.9/site-packages/pandas/core/indexes/base.py", line 3812, in get_loc
    raise KeyError(key) from err
KeyError: 'week'
2024-12-02 18:54:56,113 - __main__ - ERROR - Error in main: 'week'
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/pandas/core/indexes/base.py", line 3805, in get_loc
    return self._engine.get_loc(casted_key)
  File "index.pyx", line 167, in pandas._libs.index.IndexEngine.get_loc
  File "index.pyx", line 196, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 7081, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 7089, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'week'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/app/scripts/generate_story.py", line 275, in main
    output_story_path = process_story_data()
  File "/app/scripts/generate_story.py", line 156, in process_story_data
    stt_week = row['week']  # Get the week value from the DataFrame
  File "/usr/local/lib/python3.9/site-packages/pandas/core/series.py", line 1121, in __getitem__
    return self._get_value(key)
  File "/usr/local/lib/python3.9/site-packages/pandas/core/series.py", line 1237, in _get_value
    loc = self.index.get_loc(label)
  File "/usr/local/lib/python3.9/site-packages/pandas/core/indexes/base.py", line 3812, in get_loc
    raise KeyError(key) from err
KeyError: 'week'
2024-12-03 07:33:04,274 - __main__ - DEBUG - OpenAI API key loaded: ********************************************************************************************************************************************************************
2024-12-03 07:33:04,275 - __main__ - DEBUG - Upload folder path: /app/uploads
2024-12-03 07:33:04,275 - __main__ - DEBUG - Output folder path: /app/output
2024-12-03 07:33:04,276 - __main__ - INFO - Starting main process
2024-12-03 07:33:04,277 - __main__ - INFO - Starting initial data processing
2024-12-03 07:33:04,398 - __main__ - WARNING - Empty input for order 999, skipping
2024-12-03 07:33:04,398 - __main__ - DEBUG - Processed row - Order: 999, Week: 1
2024-12-03 07:33:04,398 - __main__ - DEBUG - Response: 
2024-12-03 07:33:04,399 - __main__ - WARNING - Empty input for order 2, skipping
2024-12-03 07:33:04,399 - __main__ - DEBUG - Processed row - Order: 2, Week: 25
2024-12-03 07:33:04,400 - __main__ - DEBUG - Response: 
2024-12-03 07:33:04,424 - __main__ - INFO - Output saved to /app/output/output_story_draft.xlsx
2024-12-03 07:33:04,424 - __main__ - INFO - Starting story data processing
2024-12-03 07:33:04,427 - __main__ - ERROR - Error in process_story_data: [Errno 2] No such file or directory: '/app/output/.xlsx'
Traceback (most recent call last):
  File "/app/scripts/generate_story.py", line 153, in process_story_data
    df_input = pd.read_excel(input_path)
  File "/usr/local/lib/python3.9/site-packages/pandas/io/excel/_base.py", line 495, in read_excel
    io = ExcelFile(
  File "/usr/local/lib/python3.9/site-packages/pandas/io/excel/_base.py", line 1550, in __init__
    ext = inspect_excel_format(
  File "/usr/local/lib/python3.9/site-packages/pandas/io/excel/_base.py", line 1402, in inspect_excel_format
    with get_handle(
  File "/usr/local/lib/python3.9/site-packages/pandas/io/common.py", line 882, in get_handle
    handle = open(handle, ioargs.mode)
FileNotFoundError: [Errno 2] No such file or directory: '/app/output/.xlsx'
2024-12-03 07:33:04,432 - __main__ - ERROR - Error in main: [Errno 2] No such file or directory: '/app/output/.xlsx'
Traceback (most recent call last):
  File "/app/scripts/generate_story.py", line 281, in main
    output_story_path = process_story_data()
  File "/app/scripts/generate_story.py", line 153, in process_story_data
    df_input = pd.read_excel(input_path)
  File "/usr/local/lib/python3.9/site-packages/pandas/io/excel/_base.py", line 495, in read_excel
    io = ExcelFile(
  File "/usr/local/lib/python3.9/site-packages/pandas/io/excel/_base.py", line 1550, in __init__
    ext = inspect_excel_format(
  File "/usr/local/lib/python3.9/site-packages/pandas/io/excel/_base.py", line 1402, in inspect_excel_format
    with get_handle(
  File "/usr/local/lib/python3.9/site-packages/pandas/io/common.py", line 882, in get_handle
    handle = open(handle, ioargs.mode)
FileNotFoundError: [Errno 2] No such file or directory: '/app/output/.xlsx'
2024-12-03 07:33:44,653 - __main__ - DEBUG - OpenAI API key loaded: ********************************************************************************************************************************************************************
2024-12-03 07:33:44,653 - __main__ - DEBUG - Upload folder path: /app/uploads
2024-12-03 07:33:44,653 - __main__ - DEBUG - Output folder path: /app/output
2024-12-03 07:33:44,654 - __main__ - INFO - Starting main process
2024-12-03 07:33:44,655 - __main__ - INFO - Starting initial data processing
2024-12-03 07:33:44,770 - __main__ - WARNING - Empty input for order 999, skipping
2024-12-03 07:33:44,771 - __main__ - DEBUG - Processed row - Order: 999, Week: 1
2024-12-03 07:33:44,771 - __main__ - DEBUG - Response: 
2024-12-03 07:33:44,772 - __main__ - WARNING - Empty input for order 2, skipping
2024-12-03 07:33:44,772 - __main__ - DEBUG - Processed row - Order: 2, Week: 25
2024-12-03 07:33:44,773 - __main__ - DEBUG - Response: 
2024-12-03 07:33:44,797 - __main__ - INFO - Output saved to /app/output/output_story_draft.xlsx
2024-12-03 07:33:44,797 - __main__ - INFO - Starting story data processing
2024-12-03 07:33:44,799 - __main__ - ERROR - Error in process_story_data: [Errno 2] No such file or directory: '/app/output/.xlsx'
Traceback (most recent call last):
  File "/app/scripts/generate_story.py", line 153, in process_story_data
    df_input = pd.read_excel(input_path)
  File "/usr/local/lib/python3.9/site-packages/pandas/io/excel/_base.py", line 495, in read_excel
    io = ExcelFile(
  File "/usr/local/lib/python3.9/site-packages/pandas/io/excel/_base.py", line 1550, in __init__
    ext = inspect_excel_format(
  File "/usr/local/lib/python3.9/site-packages/pandas/io/excel/_base.py", line 1402, in inspect_excel_format
    with get_handle(
  File "/usr/local/lib/python3.9/site-packages/pandas/io/common.py", line 882, in get_handle
    handle = open(handle, ioargs.mode)
FileNotFoundError: [Errno 2] No such file or directory: '/app/output/.xlsx'
2024-12-03 07:33:44,804 - __main__ - ERROR - Error in main: [Errno 2] No such file or directory: '/app/output/.xlsx'
Traceback (most recent call last):
  File "/app/scripts/generate_story.py", line 281, in main
    output_story_path = process_story_data()
  File "/app/scripts/generate_story.py", line 153, in process_story_data
    df_input = pd.read_excel(input_path)
  File "/usr/local/lib/python3.9/site-packages/pandas/io/excel/_base.py", line 495, in read_excel
    io = ExcelFile(
  File "/usr/local/lib/python3.9/site-packages/pandas/io/excel/_base.py", line 1550, in __init__
    ext = inspect_excel_format(
  File "/usr/local/lib/python3.9/site-packages/pandas/io/excel/_base.py", line 1402, in inspect_excel_format
    with get_handle(
  File "/usr/local/lib/python3.9/site-packages/pandas/io/common.py", line 882, in get_handle
    handle = open(handle, ioargs.mode)
FileNotFoundError: [Errno 2] No such file or directory: '/app/output/.xlsx'
2024-12-03 07:34:20,560 - __main__ - DEBUG - OpenAI API key loaded: ********************************************************************************************************************************************************************
2024-12-03 07:34:20,560 - __main__ - DEBUG - Upload folder path: /app/uploads
2024-12-03 07:34:20,561 - __main__ - DEBUG - Output folder path: /app/output
2024-12-03 07:34:20,561 - __main__ - INFO - Starting main process
2024-12-03 07:34:20,563 - __main__ - INFO - Starting initial data processing
2024-12-03 07:34:20,796 - __main__ - WARNING - Empty input for order 999, skipping
2024-12-03 07:34:20,797 - __main__ - DEBUG - Processed row - Order: 999, Week: 1
2024-12-03 07:34:20,797 - __main__ - DEBUG - Response: 
2024-12-03 07:34:20,798 - __main__ - WARNING - Empty input for order 2, skipping
2024-12-03 07:34:20,798 - __main__ - DEBUG - Processed row - Order: 2, Week: 25
2024-12-03 07:34:20,799 - __main__ - DEBUG - Response: 
2024-12-03 07:34:20,830 - __main__ - INFO - Output saved to /app/output/output_story_draft.xlsx
2024-12-03 07:34:20,830 - __main__ - INFO - Starting story data processing
2024-12-03 07:34:20,850 - __main__ - DEBUG - Processing story data for order 999.0
2024-12-03 07:34:20,851 - __main__ - WARNING - Empty JSON for order 999.0, skipping
2024-12-03 07:34:20,851 - __main__ - DEBUG - Processing story data for order 2.0
2024-12-03 07:34:20,852 - __main__ - WARNING - Empty JSON for order 2.0, skipping
2024-12-03 07:34:20,884 - __main__ - INFO - Story data processing complete, saved to /app/output/output_story.xlsx
2024-12-03 07:34:20,884 - __main__ - INFO - Starting audio generation
2024-12-03 07:34:20,907 - __main__ - DEBUG - Generating audio for order 999.0, week 1.0
2024-12-03 07:34:20,908 - __main__ - ERROR - Error in generate_audio: the JSON object must be str, bytes or bytearray, not float64
Traceback (most recent call last):
  File "/app/scripts/generate_story.py", line 244, in generate_audio
    data = json.loads(row['json'])
  File "/usr/local/lib/python3.9/json/__init__.py", line 339, in loads
    raise TypeError(f'the JSON object must be str, bytes or bytearray, '
TypeError: the JSON object must be str, bytes or bytearray, not float64
2024-12-03 07:34:20,915 - __main__ - ERROR - Error in main: the JSON object must be str, bytes or bytearray, not float64
Traceback (most recent call last):
  File "/app/scripts/generate_story.py", line 284, in main
    generate_audio()
  File "/app/scripts/generate_story.py", line 244, in generate_audio
    data = json.loads(row['json'])
  File "/usr/local/lib/python3.9/json/__init__.py", line 339, in loads
    raise TypeError(f'the JSON object must be str, bytes or bytearray, '
TypeError: the JSON object must be str, bytes or bytearray, not float64
2024-12-03 07:36:28,805 - __main__ - DEBUG - OpenAI API key loaded: ********************************************************************************************************************************************************************
2024-12-03 07:36:28,806 - __main__ - DEBUG - Upload folder path: /app/uploads
2024-12-03 07:36:28,806 - __main__ - DEBUG - Output folder path: /app/output
2024-12-03 07:36:28,807 - __main__ - INFO - Starting main process
2024-12-03 07:36:28,809 - __main__ - INFO - Starting initial data processing
2024-12-03 07:36:28,967 - __main__ - WARNING - Empty input for order 999, skipping
2024-12-03 07:36:28,968 - __main__ - DEBUG - Processed row - Order: 999, Week: 1
2024-12-03 07:36:28,968 - __main__ - DEBUG - Response: 
2024-12-03 07:36:28,969 - __main__ - WARNING - Empty input for order 2, skipping
2024-12-03 07:36:28,970 - __main__ - DEBUG - Processed row - Order: 2, Week: 25
2024-12-03 07:36:28,970 - __main__ - DEBUG - Response: 
2024-12-03 07:36:29,009 - __main__ - INFO - Output saved to /app/output/output_story_draft.xlsx
2024-12-03 07:36:29,009 - __main__ - INFO - Starting story data processing
2024-12-03 07:36:29,042 - __main__ - DEBUG - Processing story data for order 999.0
2024-12-03 07:36:29,043 - __main__ - WARNING - Empty JSON for order 999.0, skipping
2024-12-03 07:36:29,043 - __main__ - DEBUG - Processing story data for order 2.0
2024-12-03 07:36:29,044 - __main__ - WARNING - Empty JSON for order 2.0, skipping
2024-12-03 07:36:29,073 - __main__ - INFO - Story data processing complete, saved to /app/output/output_story.xlsx
2024-12-03 07:36:29,074 - __main__ - INFO - Starting audio generation
2024-12-03 07:36:29,098 - __main__ - DEBUG - Generating audio for order 999.0, week 1.0
2024-12-03 07:36:29,099 - __main__ - WARNING - Empty JSON for order 999.0, skipping
2024-12-03 07:36:29,100 - __main__ - DEBUG - Generating audio for order 2.0, week 25.0
2024-12-03 07:36:29,100 - __main__ - WARNING - Empty JSON for order 2.0, skipping
2024-12-03 07:36:29,101 - __main__ - INFO - Audio generation complete
2024-12-03 07:36:29,101 - __main__ - INFO - Processing complete. Final output saved to: /app/output/output_story.xlsx
2024-12-03 07:54:29,669 - __main__ - DEBUG - OpenAI API key loaded: ********************************************************************************************************************************************************************
2024-12-03 07:54:29,670 - __main__ - DEBUG - Upload folder path: /app/uploads
2024-12-03 07:54:29,670 - __main__ - DEBUG - Output folder path: /app/output
2024-12-03 07:54:29,671 - __main__ - INFO - Starting main process
2024-12-03 07:54:29,672 - __main__ - INFO - Starting initial data processing
2024-12-03 07:54:29,800 - __main__ - WARNING - Empty input for order 999, skipping
2024-12-03 07:54:29,801 - __main__ - DEBUG - Processed row - Order: 999
2024-12-03 07:54:29,801 - __main__ - DEBUG - Response: 
2024-12-03 07:54:29,802 - __main__ - WARNING - Empty input for order 2, skipping
2024-12-03 07:54:29,803 - __main__ - DEBUG - Processed row - Order: 2
2024-12-03 07:54:29,803 - __main__ - DEBUG - Response: 
2024-12-03 07:54:29,835 - __main__ - INFO - Output saved to /app/output/output_draft.xlsx
2024-12-03 07:54:29,836 - __main__ - INFO - Starting story data processing
2024-12-03 07:54:29,859 - __main__ - DEBUG - Processing story data for order 999.0
2024-12-03 07:54:29,860 - __main__ - WARNING - Empty JSON for order 999.0, skipping
2024-12-03 07:54:29,861 - __main__ - DEBUG - Processing story data for order 2.0
2024-12-03 07:54:29,861 - __main__ - WARNING - Empty JSON for order 2.0, skipping
2024-12-03 07:54:29,899 - __main__ - INFO - Story data processing complete, saved to /app/output/output_story.xlsx
2024-12-03 07:54:29,899 - __main__ - INFO - Starting audio generation
2024-12-03 07:54:29,922 - __main__ - DEBUG - Generating audio for order 999.0
2024-12-03 07:54:29,923 - __main__ - ERROR - Error in generate_audio: the JSON object must be str, bytes or bytearray, not float64
Traceback (most recent call last):
  File "/app/scripts/generate_story.py", line 235, in generate_audio
    data = json.loads(row['json'])
  File "/usr/local/lib/python3.9/json/__init__.py", line 339, in loads
    raise TypeError(f'the JSON object must be str, bytes or bytearray, '
TypeError: the JSON object must be str, bytes or bytearray, not float64
2024-12-03 07:54:29,929 - __main__ - ERROR - Error in main: the JSON object must be str, bytes or bytearray, not float64
Traceback (most recent call last):
  File "/app/scripts/generate_story.py", line 275, in main
    generate_audio()
  File "/app/scripts/generate_story.py", line 235, in generate_audio
    data = json.loads(row['json'])
  File "/usr/local/lib/python3.9/json/__init__.py", line 339, in loads
    raise TypeError(f'the JSON object must be str, bytes or bytearray, '
TypeError: the JSON object must be str, bytes or bytearray, not float64
2024-12-03 07:55:37,298 - __main__ - DEBUG - OpenAI API key loaded: ********************************************************************************************************************************************************************
2024-12-03 07:55:37,298 - __main__ - DEBUG - Upload folder path: /app/uploads
2024-12-03 07:55:37,299 - __main__ - DEBUG - Output folder path: /app/output
2024-12-03 07:55:37,299 - __main__ - INFO - Starting main process
2024-12-03 07:55:37,302 - __main__ - INFO - Starting initial data processing
2024-12-03 07:55:37,422 - __main__ - WARNING - Empty input for order 999, skipping
2024-12-03 07:55:37,424 - __main__ - DEBUG - Processed row - Order: 999
2024-12-03 07:55:37,424 - __main__ - DEBUG - Response: 
2024-12-03 07:55:37,425 - __main__ - WARNING - Empty input for order 2, skipping
2024-12-03 07:55:37,426 - __main__ - DEBUG - Processed row - Order: 2
2024-12-03 07:55:37,426 - __main__ - DEBUG - Response: 
2024-12-03 07:55:37,452 - __main__ - INFO - Output saved to /app/output/output_draft.xlsx
2024-12-03 07:55:37,452 - __main__ - INFO - Starting story data processing
2024-12-03 07:55:37,472 - __main__ - DEBUG - Processing story data for order 999.0
2024-12-03 07:55:37,473 - __main__ - WARNING - Empty JSON for order 999.0, skipping
2024-12-03 07:55:37,474 - __main__ - DEBUG - Processing story data for order 2.0
2024-12-03 07:55:37,474 - __main__ - WARNING - Empty JSON for order 2.0, skipping
2024-12-03 07:55:37,497 - __main__ - INFO - Story data processing complete, saved to /app/output/output_story.xlsx
2024-12-03 07:55:37,498 - __main__ - INFO - Starting audio generation
2024-12-03 07:55:37,521 - __main__ - DEBUG - Generating audio for order 999.0
2024-12-03 07:55:37,521 - __main__ - ERROR - Error in generate_audio: the JSON object must be str, bytes or bytearray, not float64
Traceback (most recent call last):
  File "/app/scripts/generate_story.py", line 235, in generate_audio
    data = json.loads(row['json'])
  File "/usr/local/lib/python3.9/json/__init__.py", line 339, in loads
    raise TypeError(f'the JSON object must be str, bytes or bytearray, '
TypeError: the JSON object must be str, bytes or bytearray, not float64
2024-12-03 07:55:37,526 - __main__ - ERROR - Error in main: the JSON object must be str, bytes or bytearray, not float64
Traceback (most recent call last):
  File "/app/scripts/generate_story.py", line 275, in main
    generate_audio()
  File "/app/scripts/generate_story.py", line 235, in generate_audio
    data = json.loads(row['json'])
  File "/usr/local/lib/python3.9/json/__init__.py", line 339, in loads
    raise TypeError(f'the JSON object must be str, bytes or bytearray, '
TypeError: the JSON object must be str, bytes or bytearray, not float64
2024-12-03 07:57:06,217 - __main__ - DEBUG - OpenAI API key loaded: ********************************************************************************************************************************************************************
2024-12-03 07:57:06,217 - __main__ - DEBUG - Upload folder path: /app/uploads
2024-12-03 07:57:06,217 - __main__ - DEBUG - Output folder path: /app/output
2024-12-03 07:57:06,218 - __main__ - INFO - Starting main process
2024-12-03 07:57:06,220 - __main__ - INFO - Starting initial data processing
2024-12-03 07:57:06,327 - __main__ - WARNING - Empty input for order 999, skipping
2024-12-03 07:57:06,328 - __main__ - DEBUG - Processed row - Order: 999
2024-12-03 07:57:06,328 - __main__ - DEBUG - Response: 
2024-12-03 07:57:06,329 - __main__ - WARNING - Empty input for order 2, skipping
2024-12-03 07:57:06,329 - __main__ - DEBUG - Processed row - Order: 2
2024-12-03 07:57:06,329 - __main__ - DEBUG - Response: 
2024-12-03 07:57:06,351 - __main__ - INFO - Output saved to /app/output/output_draft.xlsx
2024-12-03 07:57:06,351 - __main__ - INFO - Starting story data processing
2024-12-03 07:57:06,370 - __main__ - DEBUG - Processing story data for order 999.0
2024-12-03 07:57:06,371 - __main__ - WARNING - Empty JSON for order 999.0, skipping
2024-12-03 07:57:06,371 - __main__ - DEBUG - Processing story data for order 2.0
2024-12-03 07:57:06,371 - __main__ - WARNING - Empty JSON for order 2.0, skipping
2024-12-03 07:57:06,398 - __main__ - INFO - Story data processing complete, saved to /app/output/output_story.xlsx
2024-12-03 07:57:06,399 - __main__ - INFO - Starting audio generation
2024-12-03 07:57:06,422 - __main__ - DEBUG - Generating audio for order 999.0
2024-12-03 07:57:06,423 - __main__ - ERROR - Error in generate_audio: the JSON object must be str, bytes or bytearray, not float64
Traceback (most recent call last):
  File "/app/scripts/generate_story.py", line 235, in generate_audio
    data = json.loads(row['json'])
  File "/usr/local/lib/python3.9/json/__init__.py", line 339, in loads
    raise TypeError(f'the JSON object must be str, bytes or bytearray, '
TypeError: the JSON object must be str, bytes or bytearray, not float64
2024-12-03 07:57:06,429 - __main__ - ERROR - Error in main: the JSON object must be str, bytes or bytearray, not float64
Traceback (most recent call last):
  File "/app/scripts/generate_story.py", line 275, in main
    generate_audio()
  File "/app/scripts/generate_story.py", line 235, in generate_audio
    data = json.loads(row['json'])
  File "/usr/local/lib/python3.9/json/__init__.py", line 339, in loads
    raise TypeError(f'the JSON object must be str, bytes or bytearray, '
TypeError: the JSON object must be str, bytes or bytearray, not float64
2024-12-03 08:18:43,760 - __main__ - DEBUG - OpenAI API key loaded: ********************************************************************************************************************************************************************
2024-12-03 08:18:43,760 - __main__ - DEBUG - Upload folder path: /app/uploads
2024-12-03 08:18:43,761 - __main__ - DEBUG - Output folder path: /app/output
2024-12-03 08:18:43,761 - __main__ - INFO - Starting main process
2024-12-03 08:18:43,762 - __main__ - INFO - ==================================================
2024-12-03 08:18:43,763 - __main__ - INFO - STARTING INITIAL DATA PROCESSING
2024-12-03 08:18:43,763 - __main__ - INFO - ==================================================
2024-12-03 08:18:43,763 - __main__ - INFO - Reading input file from: /app/uploads/data.xlsx
2024-12-03 08:18:43,893 - __main__ - INFO - Input data loaded successfully:
2024-12-03 08:18:43,893 - __main__ - INFO - - Total rows: 2
2024-12-03 08:18:43,894 - __main__ - INFO - - Columns: ['week', 'order', 'prompt', 'first', 'MAIN QUESTION', 'set', 'vocabulary', 'situation', 'prompt_meaning', 'prompt_ipa', 'prompt_image', 'vocabulary1', 'Unnamed: 12', 'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15']
2024-12-03 08:18:43,907 - __main__ - INFO - - First few rows:
   week  order                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              prompt  first           MAIN QUESTION                   set           vocabulary                                            situation                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                prompt_meaning                                                                                                                                                       prompt_ipa                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 prompt_image                                              vocabulary1  Unnamed: 12  Unnamed: 13                                                                                                        Unnamed: 14                                           Unnamed: 15
0     1    999  You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn't have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly 'male' and 'female'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]    NaN  talk about your family  Family size and type       Nuclear family        Sarah and Tom, neighbors, at a community park  You are now a exercise maker. Your task is to create a yes/no question to check user's ability to understand the phrase.\nOutput must include: exact given vocab and its correct/incorrect meaning/usage, and correct explanation\n"question": correct or incorrect statement about its meaning, easy to understand for new English learners\n"answer" Yes if correct, no if incorrect\n"explain": correctly and briefly tell Vietnamese meaning and explain why it correct.\n\nexample input:\nword: traffic jam\nresponse:\n{"question":"We can drive really fast when there is a traffic jam, is that correct?","answer":"No","explain":"<g>traffic jam</g> l tc ng, m tc ng th chu, khng phng nhanh c"}  You are now a English teach, from given english word, you give me Vietnamese meaning and IPA\n{"meaning":"<vietnamese meaning","ipa":<English IPA transcript>"}  You are now a quiz image prompt generator. Base from an input, you will generate image 2 prompts, \n- "prompt" vsualize the exact meaning of given input, so people can guess the word/phrase.\n- "opposite_prompt" will describe the same situation and concept with opposite or contrary meaning to the 'prompt' part.\n- both prompt start with 'an award-winning digital graphic art with depth and oil painting colors,'\n\nformat {"prompt":"image prompt","opposite_prompt":"oppostie image prompt"}       Topic: Family size and type\nVocab: Nuclear family          NaN          NaN  curl -L -X POST 'http://103.253.20.13:25010/api/text-to-speech' -H 'Content-Type: application/json' -d '{"text":   ,"voice": "en-CA-ClaraNeural","speed": 1}' --output 
1    25      2  You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn't have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly 'male' and 'female'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]    NaN  talk about your family  Family size and type  Generational family  Aubrey and Isaac, engineers, at a construction site  You are now a exercise maker. Your task is to create a yes/no question to check user's ability to understand the phrase.\nOutput must include: exact given vocab and its correct/incorrect meaning/usage, and correct explanation\n"question": correct or incorrect statement about its meaning, easy to understand for new English learners\n"answer" Yes if correct, no if incorrect\n"explain": correctly and briefly tell Vietnamese meaning and explain why it correct.\n\nexample input:\nword: traffic jam\nresponse:\n{"question":"We can drive really fast when there is a traffic jam, is that correct?","answer":"No","explain":"<g>traffic jam</g> l tc ng, m tc ng th chu, khng phng nhanh c"}  You are now a English teach, from given english word, you give me Vietnamese meaning and IPA\n{"meaning":"<vietnamese meaning","ipa":<English IPA transcript>"}  You are now a quiz image prompt generator. Base from an input, you will generate image 2 prompts, \n- "prompt" vsualize the exact meaning of given input, so people can guess the word/phrase.\n- "opposite_prompt" will describe the same situation and concept with opposite or contrary meaning to the 'prompt' part.\n- both prompt start with 'an award-winning digital graphic art with depth and oil painting colors,'\n\nformat {"prompt":"image prompt","opposite_prompt":"oppostie image prompt"}  Topic: Family size and type\nVocab: Generational family          NaN          NaN  curl -L -X POST 'http://103.253.20.13:25010/api/text-to-speech' -H 'Content-Type: application/json' -d '{"text":   ,"voice": "en-CA-ClaraNeural","speed": 1}' --output 
2024-12-03 08:18:43,908 - __main__ - INFO - 
Processing rows:
2024-12-03 08:18:43,908 - __main__ - INFO - ------------------------------
2024-12-03 08:18:43,909 - __main__ - INFO - 
Processing row 1/2
2024-12-03 08:18:43,909 - __main__ - DEBUG - Processing row 0:
2024-12-03 08:18:43,909 - __main__ - DEBUG - - First input (raw): nan
2024-12-03 08:18:43,910 - __main__ - DEBUG - - First input is NaN, using empty string
2024-12-03 08:18:43,910 - __main__ - INFO - Row details:
2024-12-03 08:18:43,910 - __main__ - INFO - - Order: 999
2024-12-03 08:18:43,911 - __main__ - INFO - - Prompt: You are now a award-winning writer. You write  conversations between a man an a woman.
- Language: V...
2024-12-03 08:18:43,911 - __main__ - INFO - - First input: 
2024-12-03 08:18:43,911 - __main__ - INFO - Processing conversation...
2024-12-03 08:18:43,912 - __main__ - WARNING - Empty input for order 999, skipping
2024-12-03 08:18:43,912 - __main__ - INFO - Conversation processed:
2024-12-03 08:18:43,912 - __main__ - INFO - - Response received: Yes
2024-12-03 08:18:43,913 - __main__ - INFO - - Response time: 
2024-12-03 08:18:43,913 - __main__ - INFO - Row 1 processed successfully
2024-12-03 08:18:43,913 - __main__ - INFO - 
Processing row 2/2
2024-12-03 08:18:43,914 - __main__ - DEBUG - Processing row 1:
2024-12-03 08:18:43,914 - __main__ - DEBUG - - First input (raw): nan
2024-12-03 08:18:43,914 - __main__ - DEBUG - - First input is NaN, using empty string
2024-12-03 08:18:43,915 - __main__ - INFO - Row details:
2024-12-03 08:18:43,915 - __main__ - INFO - - Order: 2
2024-12-03 08:18:43,915 - __main__ - INFO - - Prompt: You are now a award-winning writer. You write  conversations between a man an a woman.
- Language: V...
2024-12-03 08:18:43,915 - __main__ - INFO - - First input: 
2024-12-03 08:18:43,916 - __main__ - INFO - Processing conversation...
2024-12-03 08:18:43,916 - __main__ - WARNING - Empty input for order 2, skipping
2024-12-03 08:18:43,916 - __main__ - INFO - Conversation processed:
2024-12-03 08:18:43,916 - __main__ - INFO - - Response received: Yes
2024-12-03 08:18:43,917 - __main__ - INFO - - Response time: 
2024-12-03 08:18:43,917 - __main__ - INFO - Row 2 processed successfully
2024-12-03 08:18:43,918 - __main__ - INFO - 
==================================================
2024-12-03 08:18:43,918 - __main__ - INFO - PROCESSING SUMMARY
2024-12-03 08:18:43,919 - __main__ - INFO - ==================================================
2024-12-03 08:18:43,919 - __main__ - INFO - Total rows in input: 2
2024-12-03 08:18:43,920 - __main__ - INFO - Successfully processed: 2
2024-12-03 08:18:43,920 - __main__ - INFO - Skipped rows: 0
2024-12-03 08:18:43,921 - __main__ - INFO - Output shape: (2, 4)
2024-12-03 08:18:43,962 - __main__ - INFO - 
Output file verification:
2024-12-03 08:18:43,962 - __main__ - INFO - - File saved at: /app/output/output_draft.xlsx
2024-12-03 08:18:43,962 - __main__ - INFO - - Output rows: 2
2024-12-03 08:18:43,963 - __main__ - INFO - - Output columns: ['order', 'User Input', 'json', 'Response Time']
2024-12-03 08:18:43,963 - __main__ - INFO - ==================================================
2024-12-03 08:18:43,963 - __main__ - INFO - Starting story data processing
2024-12-03 08:18:43,980 - __main__ - DEBUG - Processing story data for order 999.0
2024-12-03 08:18:43,980 - __main__ - WARNING - Empty JSON for order 999.0, skipping
2024-12-03 08:18:43,980 - __main__ - DEBUG - Processing story data for order 2.0
2024-12-03 08:18:43,981 - __main__ - WARNING - Empty JSON for order 2.0, skipping
2024-12-03 08:18:44,003 - __main__ - INFO - Story data processing complete, saved to /app/output/output_story.xlsx
2024-12-03 08:18:44,003 - __main__ - INFO - Starting audio generation
2024-12-03 08:18:44,021 - __main__ - DEBUG - Generating audio for order 999.0
2024-12-03 08:18:44,022 - __main__ - WARNING - Empty JSON for order 999.0, skipping
2024-12-03 08:18:44,022 - __main__ - DEBUG - Generating audio for order 2.0
2024-12-03 08:18:44,023 - __main__ - WARNING - Empty JSON for order 2.0, skipping
2024-12-03 08:18:44,023 - __main__ - INFO - Audio generation complete
2024-12-03 08:18:44,023 - __main__ - INFO - Processing complete. Final output saved to: /app/output/output_story.xlsx
2024-12-03 08:23:12,085 - __main__ - DEBUG - OpenAI API key loaded: ********************************************************************************************************************************************************************
2024-12-03 08:23:12,085 - __main__ - DEBUG - Upload folder path: /app/uploads
2024-12-03 08:23:12,086 - __main__ - DEBUG - Output folder path: /app/output
2024-12-03 08:23:12,086 - __main__ - INFO - Starting main process
2024-12-03 08:23:12,088 - __main__ - INFO - ==================================================
2024-12-03 08:23:12,089 - __main__ - INFO - STARTING INITIAL DATA PROCESSING
2024-12-03 08:23:12,089 - __main__ - INFO - ==================================================
2024-12-03 08:23:12,090 - __main__ - INFO - Reading input file from: /app/uploads/data.xlsx
2024-12-03 08:23:12,203 - __main__ - INFO - Input data loaded successfully:
2024-12-03 08:23:12,203 - __main__ - INFO - - Total rows: 2
2024-12-03 08:23:12,204 - __main__ - INFO - - Columns: ['week', 'order', 'prompt', 'first', 'MAIN QUESTION', 'set', 'vocabulary', 'situation', 'prompt_meaning', 'prompt_ipa', 'prompt_image', 'vocabulary1', 'Unnamed: 12', 'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15']
2024-12-03 08:23:12,209 - __main__ - INFO - - First few rows:
   week  order                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              prompt  first           MAIN QUESTION                   set           vocabulary                                            situation                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                prompt_meaning                                                                                                                                                       prompt_ipa                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 prompt_image                                              vocabulary1  Unnamed: 12  Unnamed: 13                                                                                                        Unnamed: 14                                           Unnamed: 15
0     1    999  You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn't have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly 'male' and 'female'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]    NaN  talk about your family  Family size and type       Nuclear family        Sarah and Tom, neighbors, at a community park  You are now a exercise maker. Your task is to create a yes/no question to check user's ability to understand the phrase.\nOutput must include: exact given vocab and its correct/incorrect meaning/usage, and correct explanation\n"question": correct or incorrect statement about its meaning, easy to understand for new English learners\n"answer" Yes if correct, no if incorrect\n"explain": correctly and briefly tell Vietnamese meaning and explain why it correct.\n\nexample input:\nword: traffic jam\nresponse:\n{"question":"We can drive really fast when there is a traffic jam, is that correct?","answer":"No","explain":"<g>traffic jam</g> l tc ng, m tc ng th chu, khng phng nhanh c"}  You are now a English teach, from given english word, you give me Vietnamese meaning and IPA\n{"meaning":"<vietnamese meaning","ipa":<English IPA transcript>"}  You are now a quiz image prompt generator. Base from an input, you will generate image 2 prompts, \n- "prompt" vsualize the exact meaning of given input, so people can guess the word/phrase.\n- "opposite_prompt" will describe the same situation and concept with opposite or contrary meaning to the 'prompt' part.\n- both prompt start with 'an award-winning digital graphic art with depth and oil painting colors,'\n\nformat {"prompt":"image prompt","opposite_prompt":"oppostie image prompt"}       Topic: Family size and type\nVocab: Nuclear family          NaN          NaN  curl -L -X POST 'http://103.253.20.13:25010/api/text-to-speech' -H 'Content-Type: application/json' -d '{"text":   ,"voice": "en-CA-ClaraNeural","speed": 1}' --output 
1    25      2  You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn't have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly 'male' and 'female'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]    NaN  talk about your family  Family size and type  Generational family  Aubrey and Isaac, engineers, at a construction site  You are now a exercise maker. Your task is to create a yes/no question to check user's ability to understand the phrase.\nOutput must include: exact given vocab and its correct/incorrect meaning/usage, and correct explanation\n"question": correct or incorrect statement about its meaning, easy to understand for new English learners\n"answer" Yes if correct, no if incorrect\n"explain": correctly and briefly tell Vietnamese meaning and explain why it correct.\n\nexample input:\nword: traffic jam\nresponse:\n{"question":"We can drive really fast when there is a traffic jam, is that correct?","answer":"No","explain":"<g>traffic jam</g> l tc ng, m tc ng th chu, khng phng nhanh c"}  You are now a English teach, from given english word, you give me Vietnamese meaning and IPA\n{"meaning":"<vietnamese meaning","ipa":<English IPA transcript>"}  You are now a quiz image prompt generator. Base from an input, you will generate image 2 prompts, \n- "prompt" vsualize the exact meaning of given input, so people can guess the word/phrase.\n- "opposite_prompt" will describe the same situation and concept with opposite or contrary meaning to the 'prompt' part.\n- both prompt start with 'an award-winning digital graphic art with depth and oil painting colors,'\n\nformat {"prompt":"image prompt","opposite_prompt":"oppostie image prompt"}  Topic: Family size and type\nVocab: Generational family          NaN          NaN  curl -L -X POST 'http://103.253.20.13:25010/api/text-to-speech' -H 'Content-Type: application/json' -d '{"text":   ,"voice": "en-CA-ClaraNeural","speed": 1}' --output 
2024-12-03 08:23:12,209 - __main__ - INFO - 
Processing rows:
2024-12-03 08:23:12,210 - __main__ - INFO - ------------------------------
2024-12-03 08:23:12,211 - __main__ - INFO - 
Processing row 1/2
2024-12-03 08:23:12,212 - __main__ - DEBUG - Processing row 0:
2024-12-03 08:23:12,212 - __main__ - DEBUG - - First input (raw): nan
2024-12-03 08:23:12,212 - __main__ - DEBUG - - First input is NaN, using empty string
2024-12-03 08:23:12,213 - __main__ - INFO - Row details:
2024-12-03 08:23:12,213 - __main__ - INFO - - Order: 999
2024-12-03 08:23:12,214 - __main__ - INFO - - Prompt: You are now a award-winning writer. You write  conversations between a man an a woman.
- Language: V...
2024-12-03 08:23:12,214 - __main__ - INFO - - First input: 
2024-12-03 08:23:12,215 - __main__ - INFO - Processing conversation...
2024-12-03 08:23:12,215 - __main__ - WARNING - Empty input for order 999, skipping
2024-12-03 08:23:12,215 - __main__ - INFO - Conversation processed:
2024-12-03 08:23:12,216 - __main__ - INFO - - Response received: Yes
2024-12-03 08:23:12,216 - __main__ - INFO - - Response time: 
2024-12-03 08:23:12,217 - __main__ - INFO - Row 1 processed successfully
2024-12-03 08:23:12,217 - __main__ - INFO - 
Processing row 2/2
2024-12-03 08:23:12,218 - __main__ - DEBUG - Processing row 1:
2024-12-03 08:23:12,218 - __main__ - DEBUG - - First input (raw): nan
2024-12-03 08:23:12,219 - __main__ - DEBUG - - First input is NaN, using empty string
2024-12-03 08:23:12,219 - __main__ - INFO - Row details:
2024-12-03 08:23:12,220 - __main__ - INFO - - Order: 2
2024-12-03 08:23:12,220 - __main__ - INFO - - Prompt: You are now a award-winning writer. You write  conversations between a man an a woman.
- Language: V...
2024-12-03 08:23:12,220 - __main__ - INFO - - First input: 
2024-12-03 08:23:12,221 - __main__ - INFO - Processing conversation...
2024-12-03 08:23:12,221 - __main__ - WARNING - Empty input for order 2, skipping
2024-12-03 08:23:12,222 - __main__ - INFO - Conversation processed:
2024-12-03 08:23:12,222 - __main__ - INFO - - Response received: Yes
2024-12-03 08:23:12,223 - __main__ - INFO - - Response time: 
2024-12-03 08:23:12,223 - __main__ - INFO - Row 2 processed successfully
2024-12-03 08:23:12,224 - __main__ - INFO - 
==================================================
2024-12-03 08:23:12,224 - __main__ - INFO - PROCESSING SUMMARY
2024-12-03 08:23:12,224 - __main__ - INFO - ==================================================
2024-12-03 08:23:12,225 - __main__ - INFO - Total rows in input: 2
2024-12-03 08:23:12,225 - __main__ - INFO - Successfully processed: 2
2024-12-03 08:23:12,225 - __main__ - INFO - Skipped rows: 0
2024-12-03 08:23:12,226 - __main__ - INFO - Output shape: (2, 4)
2024-12-03 08:23:12,264 - __main__ - INFO - 
Output file verification:
2024-12-03 08:23:12,265 - __main__ - INFO - - File saved at: /app/output/output_draft.xlsx
2024-12-03 08:23:12,265 - __main__ - INFO - - Output rows: 2
2024-12-03 08:23:12,265 - __main__ - INFO - - Output columns: ['order', 'User Input', 'json', 'Response Time']
2024-12-03 08:23:12,266 - __main__ - INFO - ==================================================
2024-12-03 08:23:12,266 - __main__ - INFO - Starting story data processing
2024-12-03 08:23:12,281 - __main__ - DEBUG - Processing story data for order 999.0
2024-12-03 08:23:12,281 - __main__ - WARNING - Empty JSON for order 999.0, skipping
2024-12-03 08:23:12,282 - __main__ - DEBUG - Processing story data for order 2.0
2024-12-03 08:23:12,282 - __main__ - WARNING - Empty JSON for order 2.0, skipping
2024-12-03 08:23:12,311 - __main__ - INFO - Story data processing complete, saved to /app/output/output_story.xlsx
2024-12-03 08:23:12,312 - __main__ - INFO - Starting audio generation
2024-12-03 08:23:12,333 - __main__ - DEBUG - Generating audio for order 999.0
2024-12-03 08:23:12,333 - __main__ - WARNING - Empty JSON for order 999.0, skipping
2024-12-03 08:23:12,334 - __main__ - DEBUG - Generating audio for order 2.0
2024-12-03 08:23:12,334 - __main__ - WARNING - Empty JSON for order 2.0, skipping
2024-12-03 08:23:12,335 - __main__ - INFO - Audio generation complete
2024-12-03 08:23:12,335 - __main__ - INFO - Processing complete. Final output saved to: /app/output/output_story.xlsx
2024-12-09 10:52:12,069 - __main__ - DEBUG - OpenAI API key loaded: ********************************************************************************************************************************************************************
2024-12-09 10:52:12,070 - __main__ - DEBUG - Upload folder path: /app/uploads
2024-12-09 10:52:12,070 - __main__ - DEBUG - Output folder path: /app/output
2024-12-09 10:52:12,070 - __main__ - INFO - Starting main process
2024-12-09 10:52:12,072 - __main__ - INFO - Starting initial data processing
2024-12-09 10:52:12,352 - __main__ - WARNING - Empty input for order 999, skipping
2024-12-09 10:52:12,352 - __main__ - DEBUG - Processed row - Order: 999
2024-12-09 10:52:12,352 - __main__ - DEBUG - Response: 
2024-12-09 10:52:12,353 - __main__ - WARNING - Empty input for order 2, skipping
2024-12-09 10:52:12,353 - __main__ - DEBUG - Processed row - Order: 2
2024-12-09 10:52:12,354 - __main__ - DEBUG - Response: 
2024-12-09 10:52:12,381 - __main__ - INFO - Output saved to /app/output/output_draft.xlsx
2024-12-09 10:52:12,382 - __main__ - INFO - Starting story data processing
2024-12-09 10:52:12,398 - __main__ - DEBUG - Processing story data for order 999.0
2024-12-09 10:52:12,399 - __main__ - WARNING - Empty JSON for order 999.0, skipping
2024-12-09 10:52:12,399 - __main__ - DEBUG - Processing story data for order 2.0
2024-12-09 10:52:12,400 - __main__ - WARNING - Empty JSON for order 2.0, skipping
2024-12-09 10:52:12,421 - __main__ - INFO - Story data processing complete, saved to /app/output/output_story.xlsx
2024-12-09 10:52:12,421 - __main__ - INFO - Starting audio generation
2024-12-09 10:52:12,441 - __main__ - DEBUG - Generating audio for order 999.0
2024-12-09 10:52:12,441 - __main__ - ERROR - Error in generate_audio: the JSON object must be str, bytes or bytearray, not float64
Traceback (most recent call last):
  File "/app/scripts/generate_story.py", line 235, in generate_audio
    data = json.loads(row['json'])
  File "/usr/local/lib/python3.9/json/__init__.py", line 339, in loads
    raise TypeError(f'the JSON object must be str, bytes or bytearray, '
TypeError: the JSON object must be str, bytes or bytearray, not float64
2024-12-09 10:52:12,448 - __main__ - ERROR - Error in main: the JSON object must be str, bytes or bytearray, not float64
Traceback (most recent call last):
  File "/app/scripts/generate_story.py", line 275, in main
    generate_audio()
  File "/app/scripts/generate_story.py", line 235, in generate_audio
    data = json.loads(row['json'])
  File "/usr/local/lib/python3.9/json/__init__.py", line 339, in loads
    raise TypeError(f'the JSON object must be str, bytes or bytearray, '
TypeError: the JSON object must be str, bytes or bytearray, not float64
2024-12-09 11:17:53,386 - __main__ - DEBUG - OpenAI API key loaded: ********************************************************************************************************************************************************************
2024-12-09 11:17:53,387 - __main__ - DEBUG - Upload folder path: /app/uploads
2024-12-09 11:17:53,387 - __main__ - DEBUG - Output folder path: /app/output
2024-12-09 11:17:53,387 - __main__ - INFO - Starting main process
2024-12-09 11:17:53,389 - __main__ - INFO - Starting initial data processing
2024-12-09 11:17:53,603 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Nuclear family\nSituation: Sarah and Tom, neighbors, at a community park'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-12-09 11:17:53,612 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-12-09 11:17:53,613 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-12-09 11:17:54,046 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f7d32dc82e0>
2024-12-09 11:17:54,046 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f7d08b24bc0> server_hostname='api.openai.com' timeout=5.0
2024-12-09 11:17:54,116 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f7d32dc8070>
2024-12-09 11:17:54,116 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-09 11:17:54,117 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-12-09 11:17:54,117 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-09 11:17:54,118 - httpcore.http11 - DEBUG - send_request_body.complete
2024-12-09 11:17:54,118 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-09 11:18:04,711 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 09 Dec 2024 11:18:14 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'step-up-ognepk'), (b'openai-processing-ms', b'10240'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'598148'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'185ms'), (b'x-request-id', b'req_4d848aac5fe686b61bf3b904aaed8cbc'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=8p1trZHpOXTDIk7eDrOevXEyZe7GD3B6sznNSzWZ_UI-1733743094-1.0.1.1-PwlOndue9aYYdOoX2SjiD2NBCJEy8vs1Sl7OUXcbWoKqB5N0tBIILR1hAciElFLhyyDS8lrFInNDBoheFYx6nA; path=/; expires=Mon, 09-Dec-24 11:48:14 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=h8A2a3Zu3OFsrrPt5Nm_KV9IXokPJNhRurN324DLzYg-1733743094946-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ef497a59e68797e-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-09 11:18:04,712 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-09 11:18:04,713 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-09 11:18:04,714 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-12-09 11:18:04,714 - httpcore.http11 - DEBUG - response_closed.started
2024-12-09 11:18:04,714 - httpcore.http11 - DEBUG - response_closed.complete
2024-12-09 11:18:04,715 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Mon, 09 Dec 2024 11:18:14 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'step-up-ognepk'), ('openai-processing-ms', '10240'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '5000'), ('x-ratelimit-limit-tokens', '600000'), ('x-ratelimit-remaining-requests', '4999'), ('x-ratelimit-remaining-tokens', '598148'), ('x-ratelimit-reset-requests', '12ms'), ('x-ratelimit-reset-tokens', '185ms'), ('x-request-id', 'req_4d848aac5fe686b61bf3b904aaed8cbc'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=8p1trZHpOXTDIk7eDrOevXEyZe7GD3B6sznNSzWZ_UI-1733743094-1.0.1.1-PwlOndue9aYYdOoX2SjiD2NBCJEy8vs1Sl7OUXcbWoKqB5N0tBIILR1hAciElFLhyyDS8lrFInNDBoheFYx6nA; path=/; expires=Mon, 09-Dec-24 11:48:14 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=h8A2a3Zu3OFsrrPt5Nm_KV9IXokPJNhRurN324DLzYg-1733743094946-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8ef497a59e68797e-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-12-09 11:18:04,715 - openai._base_client - DEBUG - request_id: req_4d848aac5fe686b61bf3b904aaed8cbc
2024-12-09 11:18:04,720 - __main__ - DEBUG - Order 1000, Input: 'Topic: talk about your family - Family size and type
Given vocabulary: Nuclear family
Situation: Sarah and Tom, neighbors, at a community park', Response received in 11.19s
2024-12-09 11:18:04,721 - __main__ - DEBUG - Processed row - Order: 1000
2024-12-09 11:18:04,721 - __main__ - DEBUG - Response: [{"situation":"Sarah v Tom, hng xm, ti mt cng vin cng ng","situation_en":"Sarah and Tom, neighbors, at a community park","conversation":[{"role":"female_1","content":"Cu bit khng, t thc s thch khng kh  y. Gia nh t ch c bn ngi, mt gia nh ht nhn in hnh thi.","translation_en":"You know, I really like the atmosphere here. My family is just four people, a typical <r>nuclear family</r>."},{"role":"male_1","content":"Tht ? Gia nh t hi khc, b m t ly hn t khi t cn nh. Nhng mi bn gi u c gia nh mi ca mnh.","translation_en":"Really? My family is a bit different, my parents divorced when I was young. But each of them now has their own new family."},{"role":"female_2","content":"Vy ? T cm thy mi gia nh u c cu chuyn ring ca mnh. Quan trng l mnh cm thy hnh phc v c yu thng.","translation_en":"Is that so? I feel like every family has its own story. What matters is feeling happy and loved."},{"role":"male_2","content":"ng vy! D l gia nh ht nhn hay m rng, min l c tnh thng, mi th u tt p c.","translation_en":"Exactly! Whether it's a nuclear or extended family, as long as there is love, everything is good."}]}]
2024-12-09 11:18:04,727 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Generational family\nSituation: Aubrey and Isaac, engineers, at a construction site'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-12-09 11:18:04,729 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-12-09 11:18:04,729 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-09 11:18:04,730 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-12-09 11:18:04,730 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-09 11:18:04,731 - httpcore.http11 - DEBUG - send_request_body.complete
2024-12-09 11:18:04,731 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-09 11:18:13,211 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 09 Dec 2024 11:18:23 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'step-up-ognepk'), (b'openai-processing-ms', b'8124'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'598146'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'185ms'), (b'x-request-id', b'req_d4e391ab5ca33f0454eb1a1615045213'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ef497e7ea5a797e-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-09 11:18:13,211 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-09 11:18:13,212 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-09 11:18:13,217 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-12-09 11:18:13,217 - httpcore.http11 - DEBUG - response_closed.started
2024-12-09 11:18:13,218 - httpcore.http11 - DEBUG - response_closed.complete
2024-12-09 11:18:13,218 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Mon, 09 Dec 2024 11:18:23 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'step-up-ognepk', 'openai-processing-ms': '8124', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '600000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '598146', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '185ms', 'x-request-id': 'req_d4e391ab5ca33f0454eb1a1615045213', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ef497e7ea5a797e-SIN', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-09 11:18:13,227 - openai._base_client - DEBUG - request_id: req_d4e391ab5ca33f0454eb1a1615045213
2024-12-09 11:18:13,229 - __main__ - DEBUG - Order 2, Input: 'Topic: talk about your family - Family size and type
Given vocabulary: Generational family
Situation: Aubrey and Isaac, engineers, at a construction site', Response received in 8.51s
2024-12-09 11:18:13,229 - __main__ - DEBUG - Processed row - Order: 2
2024-12-09 11:18:13,229 - __main__ - DEBUG - Response: [{"situation":"Aubrey v Isaac, hai k s, ang  cng trng","situation_en":"Aubrey and Isaac, engineers, at a construction site","conversation":[{"role":"female_1","content":"Cu c bit  nh t c bao nhiu ngi khng?","translation_en":"Do you know how many people are in my house?"},{"role":"male_1","content":"Khng, t cha bao gi nghe cu k v gia nh c.","translation_en":"No, I've never heard you talk about your family."},{"role":"female_2","content":"Nh t l mt gia nh a th h y. T ng b, b m, cho n chng t v c m tr con na.","translation_en":"My house is a <r>Generational family</r>. From grandparents, parents, to us and even the kids."},{"role":"male_2","content":"Tht m p v vui v nh! Nh t ch c b m v hai anh em thi.","translation_en":"That sounds warm and fun! My house just has my parents and the two of us siblings."}]}]
2024-12-09 11:18:13,289 - __main__ - INFO - Output saved to /app/output/output_draft.xlsx
2024-12-09 11:18:13,289 - __main__ - INFO - Starting story data processing
2024-12-09 11:18:13,309 - __main__ - DEBUG - Processing story data for order 1000, week 10
2024-12-09 11:18:13,310 - __main__ - DEBUG - Processing story data for order 2, week 20
2024-12-09 11:18:13,341 - __main__ - INFO - Story data processing complete, saved to /app/output/output_story.xlsx
2024-12-09 11:18:13,341 - __main__ - INFO - Starting audio generation
2024-12-09 11:18:13,360 - __main__ - DEBUG - Generating audio for order 1000, week 10
2024-12-09 11:18:13,361 - __main__ - DEBUG - Sending TTS request for order 1000, week 10, role female_1
2024-12-09 11:18:13,364 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-12-09 11:18:13,381 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/11" 307 0
2024-12-09 11:18:15,117 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/11" 200 285262
2024-12-09 11:18:15,173 - __main__ - DEBUG - Audio file saved: /app/output/output_audio/week_10/1000/female_1.wav
2024-12-09 11:18:15,174 - __main__ - DEBUG - Sending TTS request for order 1000, week 10, role male_1
2024-12-09 11:18:15,176 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-12-09 11:18:15,192 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/11" 307 0
2024-12-09 11:18:17,262 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/11" 200 349774
2024-12-09 11:18:17,301 - __main__ - DEBUG - Audio file saved: /app/output/output_audio/week_10/1000/male_1.wav
2024-12-09 11:18:17,301 - __main__ - DEBUG - Sending TTS request for order 1000, week 10, role female_2
2024-12-09 11:18:17,303 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-12-09 11:18:17,315 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/11" 307 0
2024-12-09 11:18:19,242 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/11" 200 320590
2024-12-09 11:18:19,291 - __main__ - DEBUG - Audio file saved: /app/output/output_audio/week_10/1000/female_2.wav
2024-12-09 11:18:19,292 - __main__ - DEBUG - Sending TTS request for order 1000, week 10, role male_2
2024-12-09 11:18:19,293 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-12-09 11:18:19,308 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/11" 307 0
2024-12-09 11:18:21,049 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/11" 200 291918
2024-12-09 11:18:21,084 - __main__ - DEBUG - Audio file saved: /app/output/output_audio/week_10/1000/male_2.wav
2024-12-09 11:18:21,086 - __main__ - DEBUG - Generating audio for order 2, week 20
2024-12-09 11:18:21,087 - __main__ - DEBUG - Sending TTS request for order 2, week 20, role female_1
2024-12-09 11:18:21,089 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-12-09 11:18:21,105 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/11" 307 0
2024-12-09 11:18:21,961 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/11" 200 124494
2024-12-09 11:18:21,988 - __main__ - DEBUG - Audio file saved: /app/output/output_audio/week_20/2/female_1.wav
2024-12-09 11:18:21,988 - __main__ - DEBUG - Sending TTS request for order 2, week 20, role male_1
2024-12-09 11:18:21,990 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-12-09 11:18:22,019 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/11" 307 0
2024-12-09 11:18:22,995 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/11" 200 149070
2024-12-09 11:18:23,019 - __main__ - DEBUG - Audio file saved: /app/output/output_audio/week_20/2/male_1.wav
2024-12-09 11:18:23,020 - __main__ - DEBUG - Sending TTS request for order 2, week 20, role female_2
2024-12-09 11:18:23,022 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-12-09 11:18:23,038 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/11" 307 0
2024-12-09 11:18:24,704 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/11" 200 276046
2024-12-09 11:18:24,743 - __main__ - DEBUG - Audio file saved: /app/output/output_audio/week_20/2/female_2.wav
2024-12-09 11:18:24,743 - __main__ - DEBUG - Sending TTS request for order 2, week 20, role male_2
2024-12-09 11:18:24,744 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-12-09 11:18:24,769 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/11" 307 0
2024-12-09 11:18:26,443 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/11" 200 258638
2024-12-09 11:18:26,474 - __main__ - DEBUG - Audio file saved: /app/output/output_audio/week_20/2/male_2.wav
2024-12-09 11:18:26,474 - __main__ - INFO - Audio generation complete
2024-12-09 11:18:26,475 - __main__ - INFO - Processing complete. Final output saved to: /app/output/output_story.xlsx
2024-12-09 11:18:37,869 - __main__ - DEBUG - OpenAI API key loaded: ********************************************************************************************************************************************************************
2024-12-09 11:18:37,869 - __main__ - DEBUG - Upload folder path: /app/uploads
2024-12-09 11:18:37,869 - __main__ - DEBUG - Output folder path: /app/output
2024-12-09 11:18:37,870 - __main__ - INFO - Starting main process
2024-12-09 11:18:37,871 - __main__ - INFO - Starting initial data processing
2024-12-09 11:18:38,067 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Nuclear family\nSituation: Sarah and Tom, neighbors, at a community park'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-12-09 11:18:38,074 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-12-09 11:18:38,075 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-12-09 11:18:38,508 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f96457c82e0>
2024-12-09 11:18:38,509 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f961b550bc0> server_hostname='api.openai.com' timeout=5.0
2024-12-09 11:18:38,581 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f96457c8070>
2024-12-09 11:18:38,582 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-09 11:18:38,582 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-12-09 11:18:38,583 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-09 11:18:38,583 - httpcore.http11 - DEBUG - send_request_body.complete
2024-12-09 11:18:38,583 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-09 11:18:48,801 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 09 Dec 2024 11:18:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'step-up-ognepk'), (b'openai-processing-ms', b'9836'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'598148'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'185ms'), (b'x-request-id', b'req_6fe88fecb72d3de6c3654ff2b9c69738'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=_SPmkl7OfHg.atJKptA6Fh8rkoLMPayqVvsMEpft39Q-1733743139-1.0.1.1-tv.cAQNplOODFfg9m2erdvelLKbDJyZyjnODtnsuIhlMezL9RCQ4Su9yv4Ppo34cHMGnQdjIEYM.9fGDwTyKPQ; path=/; expires=Mon, 09-Dec-24 11:48:59 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=UXtYq6HWL1Cl.kOCiuPKjHaXJ0WMjBO8wMVhve8bgk8-1733743139035-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ef498bb8fb0a135-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-09 11:18:48,803 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-09 11:18:48,803 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-09 11:18:48,812 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-12-09 11:18:48,812 - httpcore.http11 - DEBUG - response_closed.started
2024-12-09 11:18:48,812 - httpcore.http11 - DEBUG - response_closed.complete
2024-12-09 11:18:48,813 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Mon, 09 Dec 2024 11:18:59 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'step-up-ognepk'), ('openai-processing-ms', '9836'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '5000'), ('x-ratelimit-limit-tokens', '600000'), ('x-ratelimit-remaining-requests', '4999'), ('x-ratelimit-remaining-tokens', '598148'), ('x-ratelimit-reset-requests', '12ms'), ('x-ratelimit-reset-tokens', '185ms'), ('x-request-id', 'req_6fe88fecb72d3de6c3654ff2b9c69738'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=_SPmkl7OfHg.atJKptA6Fh8rkoLMPayqVvsMEpft39Q-1733743139-1.0.1.1-tv.cAQNplOODFfg9m2erdvelLKbDJyZyjnODtnsuIhlMezL9RCQ4Su9yv4Ppo34cHMGnQdjIEYM.9fGDwTyKPQ; path=/; expires=Mon, 09-Dec-24 11:48:59 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=UXtYq6HWL1Cl.kOCiuPKjHaXJ0WMjBO8wMVhve8bgk8-1733743139035-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8ef498bb8fb0a135-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-12-09 11:18:48,813 - openai._base_client - DEBUG - request_id: req_6fe88fecb72d3de6c3654ff2b9c69738
2024-12-09 11:18:48,818 - __main__ - DEBUG - Order 1000, Input: 'Topic: talk about your family - Family size and type
Given vocabulary: Nuclear family
Situation: Sarah and Tom, neighbors, at a community park', Response received in 10.82s
2024-12-09 11:18:48,819 - __main__ - DEBUG - Processed row - Order: 1000
2024-12-09 11:18:48,819 - __main__ - DEBUG - Response: [{"situation":"Sarah v Tom, hng xm, ti cng vin cng ng","situation_en":"Sarah and Tom, neighbors, at a community park","conversation":[{"role":"female_1","content":"Cu bit khng, gia nh t l mt gia nh ht nhn y.","translation_en":"You know, my family is a <r>nuclear family</r>."},{"role":"male_1","content":"Tht ? Gia nh t cng vy. Ch c b m v hai a tr.","translation_en":"Really? My family is the same. Just parents and two kids."},{"role":"female_2","content":"Th v nh? T lun ngh rng gia nh nh gn gip mi ngi gn gi nhau hn.","translation_en":"Interesting, isn't it? I always think that a small family helps everyone be closer to each other."},{"role":"male_2","content":"ng vy. D dng hn trong vic qun l v dnh thi gian cho nhau. Cu thch iu  ch?","translation_en":"Exactly. It's easier to manage and spend time with each other. You like that, right?"}]}]
2024-12-09 11:18:48,825 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Generational family\nSituation: Aubrey and Isaac, engineers, at a construction site'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-12-09 11:18:48,826 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-12-09 11:18:48,826 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-09 11:18:48,827 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-12-09 11:18:48,827 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-09 11:18:48,828 - httpcore.http11 - DEBUG - send_request_body.complete
2024-12-09 11:18:48,828 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-09 11:18:57,232 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 09 Dec 2024 11:19:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'step-up-ognepk'), (b'openai-processing-ms', b'8046'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'598146'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'185ms'), (b'x-request-id', b'req_36d9e7eddc41d5ddd468065e07472e46'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ef498fb8cbca135-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-09 11:18:57,233 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-09 11:18:57,233 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-09 11:18:57,240 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-12-09 11:18:57,240 - httpcore.http11 - DEBUG - response_closed.started
2024-12-09 11:18:57,241 - httpcore.http11 - DEBUG - response_closed.complete
2024-12-09 11:18:57,241 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Mon, 09 Dec 2024 11:19:07 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'step-up-ognepk', 'openai-processing-ms': '8046', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '600000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '598146', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '185ms', 'x-request-id': 'req_36d9e7eddc41d5ddd468065e07472e46', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ef498fb8cbca135-SIN', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-09 11:18:57,242 - openai._base_client - DEBUG - request_id: req_36d9e7eddc41d5ddd468065e07472e46
2024-12-09 11:18:57,242 - __main__ - DEBUG - Order 2000, Input: 'Topic: talk about your family - Family size and type
Given vocabulary: Generational family
Situation: Aubrey and Isaac, engineers, at a construction site', Response received in 8.42s
2024-12-09 11:18:57,243 - __main__ - DEBUG - Processed row - Order: 2000
2024-12-09 11:18:57,243 - __main__ - DEBUG - Response: [{"situation":"Aubrey v Isaac, hai k s, ang  ti cng trng","situation_en":"Aubrey and Isaac, engineers, at a construction site","conversation":[{"role":"female_1","content":"Cu c bit  nh t c bao nhiu ngi khng?","translation_en":"Do you know how many people are in my family?"},{"role":"male_1","content":"Khng, t cha bao gi nghe cu k c. Gia nh cu th no?","translation_en":"No, I've never heard you talk about it. What's your family like?"},{"role":"female_2","content":"T sng trong mt gia nh a th h. T ng b, b m, cho n chng t.","translation_en":"I live in a <r>Generational family</r>. From grandparents, parents, to us."},{"role":"male_2","content":"Tht m p v vui v nh! Gia nh t ch c b m v hai anh em thi.","translation_en":"That sounds warm and fun! My family just has parents and two siblings."}]}]
2024-12-09 11:18:57,264 - __main__ - INFO - Output saved to /app/output/output_draft.xlsx
2024-12-09 11:18:57,264 - __main__ - INFO - Starting story data processing
2024-12-09 11:18:57,280 - __main__ - DEBUG - Processing story data for order 1000, week 10
2024-12-09 11:18:57,281 - __main__ - DEBUG - Processing story data for order 2000, week 20
2024-12-09 11:18:57,298 - __main__ - INFO - Story data processing complete, saved to /app/output/output_story.xlsx
2024-12-09 11:18:57,299 - __main__ - INFO - Starting audio generation
2024-12-09 11:18:57,313 - __main__ - DEBUG - Generating audio for order 1000, week 10
2024-12-09 11:18:57,314 - __main__ - DEBUG - Sending TTS request for order 1000, week 10, role female_1
2024-12-09 11:18:57,316 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-12-09 11:18:57,333 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/11" 307 0
2024-12-09 11:18:58,241 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/11" 200 129102
2024-12-09 11:18:58,272 - __main__ - DEBUG - Audio file saved: /app/output/output_audio/week_10/1000/female_1.wav
2024-12-09 11:18:58,273 - __main__ - DEBUG - Sending TTS request for order 1000, week 10, role male_1
2024-12-09 11:18:58,274 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-12-09 11:18:58,287 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/11" 307 0
2024-12-09 11:18:59,789 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/11" 200 204878
2024-12-09 11:18:59,816 - __main__ - DEBUG - Audio file saved: /app/output/output_audio/week_10/1000/male_1.wav
2024-12-09 11:18:59,816 - __main__ - DEBUG - Sending TTS request for order 1000, week 10, role female_2
2024-12-09 11:18:59,818 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-12-09 11:18:59,830 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/11" 307 0
2024-12-09 11:19:01,641 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/11" 200 254030
2024-12-09 11:19:01,712 - __main__ - DEBUG - Audio file saved: /app/output/output_audio/week_10/1000/female_2.wav
2024-12-09 11:19:01,712 - __main__ - DEBUG - Sending TTS request for order 1000, week 10, role male_2
2024-12-09 11:19:01,714 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-12-09 11:19:01,770 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/11" 307 0
2024-12-09 11:19:03,145 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/11" 200 222798
2024-12-09 11:19:03,213 - __main__ - DEBUG - Audio file saved: /app/output/output_audio/week_10/1000/male_2.wav
2024-12-09 11:19:03,214 - __main__ - DEBUG - Generating audio for order 2000, week 20
2024-12-09 11:19:03,214 - __main__ - DEBUG - Sending TTS request for order 2000, week 20, role female_1
2024-12-09 11:19:03,216 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-12-09 11:19:03,274 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/11" 307 0
2024-12-09 11:19:04,335 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/11" 200 160334
2024-12-09 11:19:04,360 - __main__ - DEBUG - Audio file saved: /app/output/output_audio/week_20/2000/female_1.wav
2024-12-09 11:19:04,361 - __main__ - DEBUG - Sending TTS request for order 2000, week 20, role male_1
2024-12-09 11:19:04,362 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-12-09 11:19:04,422 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/11" 307 0
2024-12-09 11:19:05,708 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/11" 200 200270
2024-12-09 11:19:05,737 - __main__ - DEBUG - Audio file saved: /app/output/output_audio/week_20/2000/male_1.wav
2024-12-09 11:19:05,738 - __main__ - DEBUG - Sending TTS request for order 2000, week 20, role female_2
2024-12-09 11:19:05,739 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-12-09 11:19:05,754 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/11" 307 0
2024-12-09 11:19:07,406 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/11" 200 265294
2024-12-09 11:19:07,448 - __main__ - DEBUG - Audio file saved: /app/output/output_audio/week_20/2000/female_2.wav
2024-12-09 11:19:07,449 - __main__ - DEBUG - Sending TTS request for order 2000, week 20, role male_2
2024-12-09 11:19:07,450 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-12-09 11:19:07,464 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/11" 307 0
2024-12-09 11:19:09,292 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/11" 200 262734
2024-12-09 11:19:09,333 - __main__ - DEBUG - Audio file saved: /app/output/output_audio/week_20/2000/male_2.wav
2024-12-09 11:19:09,334 - __main__ - INFO - Audio generation complete
2024-12-09 11:19:09,334 - __main__ - INFO - Processing complete. Final output saved to: /app/output/output_story.xlsx
2024-12-09 11:24:03,014 - __main__ - DEBUG - OpenAI API key loaded: ********************************************************************************************************************************************************************
2024-12-09 11:24:03,015 - __main__ - DEBUG - Upload folder path: /app/uploads
2024-12-09 11:24:03,015 - __main__ - DEBUG - Output folder path: /app/output
2024-12-09 11:24:03,015 - __main__ - INFO - Starting main process
2024-12-09 11:24:03,017 - __main__ - INFO - Starting initial data processing
2024-12-09 11:24:03,198 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Nuclear family\nSituation: Sarah and Tom, neighbors, at a community park'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-12-09 11:24:03,205 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-12-09 11:24:03,207 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-12-09 11:24:03,479 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f6eaadc82e0>
2024-12-09 11:24:03,479 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f6e80b29bc0> server_hostname='api.openai.com' timeout=5.0
2024-12-09 11:24:03,567 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f6eaadc8070>
2024-12-09 11:24:03,568 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-09 11:24:03,569 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-12-09 11:24:03,569 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-09 11:24:03,570 - httpcore.http11 - DEBUG - send_request_body.complete
2024-12-09 11:24:03,570 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-09 11:24:14,171 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 09 Dec 2024 11:24:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'step-up-ognepk'), (b'openai-processing-ms', b'10244'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'598149'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'185ms'), (b'x-request-id', b'req_6c348498a710db32351a945960090f12'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=t4kgLPKAQeIojenFa7O_33MtFaUFlak49sUDdKy1p44-1733743464-1.0.1.1-I1HGwEeoKlLo9Tsen4gYu4_LXGlPskdQgy9qTfMwwoSB5FSG_bfZU6FntTAZSB6dIYFWv_vfCXE9EMgvu4uWLg; path=/; expires=Mon, 09-Dec-24 11:54:24 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=0i8cdV6uviDzU7xBrjwdFU_xmFQDaVmpBqwTcxbNnSA-1733743464406-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ef4a0aaa9443d93-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-09 11:24:14,174 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-09 11:24:14,175 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-09 11:24:14,175 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-12-09 11:24:14,176 - httpcore.http11 - DEBUG - response_closed.started
2024-12-09 11:24:14,176 - httpcore.http11 - DEBUG - response_closed.complete
2024-12-09 11:24:14,176 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Mon, 09 Dec 2024 11:24:24 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'step-up-ognepk'), ('openai-processing-ms', '10244'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '5000'), ('x-ratelimit-limit-tokens', '600000'), ('x-ratelimit-remaining-requests', '4999'), ('x-ratelimit-remaining-tokens', '598149'), ('x-ratelimit-reset-requests', '12ms'), ('x-ratelimit-reset-tokens', '185ms'), ('x-request-id', 'req_6c348498a710db32351a945960090f12'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=t4kgLPKAQeIojenFa7O_33MtFaUFlak49sUDdKy1p44-1733743464-1.0.1.1-I1HGwEeoKlLo9Tsen4gYu4_LXGlPskdQgy9qTfMwwoSB5FSG_bfZU6FntTAZSB6dIYFWv_vfCXE9EMgvu4uWLg; path=/; expires=Mon, 09-Dec-24 11:54:24 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=0i8cdV6uviDzU7xBrjwdFU_xmFQDaVmpBqwTcxbNnSA-1733743464406-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8ef4a0aaa9443d93-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-12-09 11:24:14,177 - openai._base_client - DEBUG - request_id: req_6c348498a710db32351a945960090f12
2024-12-09 11:24:14,182 - __main__ - DEBUG - Order 3000, Input: 'Topic: talk about your family - Family size and type
Given vocabulary: Nuclear family
Situation: Sarah and Tom, neighbors, at a community park', Response received in 11.06s
2024-12-09 11:24:14,182 - __main__ - DEBUG - Processed row - Order: 3000
2024-12-09 11:24:14,183 - __main__ - DEBUG - Response: [{"situation":"Sarah v Tom, hng xm, ti mt cng vin cng ng","situation_en":"Sarah and Tom, neighbors, at a community park","conversation":[{"role":"female_1","content":"Cu bit khng, gia nh t l mt gia nh ht nhn y.","translation_en":"You know, my family is a <r>nuclear family</r>."},{"role":"male_1","content":"Tht ? Gia nh t cng vy. Ch c b m v hai a tr.","translation_en":"Really? My family is the same. Just parents and two kids."},{"role":"female_2","content":"Th v nh? T lun ngh rng sng trong gia nh ht nhn gip mi ngi gn gi nhau hn.","translation_en":"Interesting, isn't it? I always think that living in a nuclear family brings everyone closer together."},{"role":"male_2","content":"ng vy. M cu thy khng, cng vin ny cng ging nh mt gia nh ln vy.","translation_en":"Exactly. And you know, this park feels like one big family too."}]}]
2024-12-09 11:24:14,189 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are now a award-winning writer. You write  conversations between a man an a woman.\n- Language: Vietnamese. Setting: in the western countries.\n- use American names for 2 people.\n- Anh/ch - em, cu - t, b/m - con correspoding relationship between them.\n- The conversation will have 2 turns, each person talk twice\n- The conversation is intersting, dramatic, witty, humourous, and natural. \n- the content doesn\'t have <r> tag\n- The translation_en contain the given vocab in  <r> vocab </r>\n- The given word appear only once in translation_en.\n- <gender> are exactly \'male\' and \'female\'\n\nEXAMPLE:\ngo to school - i hc:\n"content":"T mun i hc c" \n"translation_en":"I really want to <r>go to school</r>!"\n\noutput format:\n[{"situation":"brief desctiption of 2 people name, their relation, where they are","situation_en":"translate situation to English","conversation":[{"role":"<gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_1","content":"their dialog","translation_en":"English translation"},{"role":"<gender>_2","content":"their dialog","translation_en":"English translation"},{"role":"<other_gender>_2","content":"their dialog","translation_en":"English translation"}]}]'}, {'role': 'user', 'content': 'Topic: talk about your family - Family size and type\nGiven vocabulary: Generational family\nSituation: Aubrey and Isaac, engineers, at a construction site'}], 'model': 'gpt-4-turbo-preview', 'frequency_penalty': 0.0, 'max_tokens': 1500, 'presence_penalty': 0.0, 'temperature': 0, 'top_p': 1}}
2024-12-09 11:24:14,190 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-12-09 11:24:14,191 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-09 11:24:14,191 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-12-09 11:24:14,192 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-09 11:24:14,192 - httpcore.http11 - DEBUG - send_request_body.complete
2024-12-09 11:24:14,193 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-09 11:24:25,770 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 09 Dec 2024 11:24:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'step-up-ognepk'), (b'openai-processing-ms', b'11212'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'598146'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'185ms'), (b'x-request-id', b'req_f2395d25db71f2a83e9c415a269df3bf'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ef4a0ed0e503d93-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-09 11:24:25,771 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-09 11:24:25,771 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-09 11:24:25,772 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-12-09 11:24:25,772 - httpcore.http11 - DEBUG - response_closed.started
2024-12-09 11:24:25,772 - httpcore.http11 - DEBUG - response_closed.complete
2024-12-09 11:24:25,773 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Mon, 09 Dec 2024 11:24:36 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'step-up-ognepk', 'openai-processing-ms': '11212', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '600000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '598146', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '185ms', 'x-request-id': 'req_f2395d25db71f2a83e9c415a269df3bf', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ef4a0ed0e503d93-SIN', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-09 11:24:25,773 - openai._base_client - DEBUG - request_id: req_f2395d25db71f2a83e9c415a269df3bf
2024-12-09 11:24:25,774 - __main__ - DEBUG - Order 2000, Input: 'Topic: talk about your family - Family size and type
Given vocabulary: Generational family
Situation: Aubrey and Isaac, engineers, at a construction site', Response received in 11.59s
2024-12-09 11:24:25,775 - __main__ - DEBUG - Processed row - Order: 2000
2024-12-09 11:24:25,775 - __main__ - DEBUG - Response: [{"situation":"Aubrey v Isaac, hai k s, ang  ti cng trng","situation_en":"Aubrey and Isaac, engineers, at a construction site","conversation":[{"role":"female_1","content":"Cu bit khng, gia nh t l mt gia nh a th h y.","translation_en":"You know, my family is a <r>Generational family</r>."},{"role":"male_1","content":"Tht ? Gia nh t ch c b m v hai anh em thi.","translation_en":"Really? My family just consists of my parents and my sibling."},{"role":"female_2","content":",  nh t c t ng b cho n chu cht. Mi ba cm nh mt ba tic vy.","translation_en":"Yeah, at my house, we have everyone from grandparents to grandchildren. Every meal is like a feast."},{"role":"male_2","content":"Nghe th v y! Gia nh t th yn tnh lm, i khi t cng mun th cm gic n o nh vy.","translation_en":"That sounds interesting! My family is very quiet, sometimes I also want to experience that kind of noise."}]}]
2024-12-09 11:24:25,795 - __main__ - INFO - Output saved to /app/output/output_draft.xlsx
2024-12-09 11:24:25,796 - __main__ - INFO - Starting story data processing
2024-12-09 11:24:25,810 - __main__ - DEBUG - Processing story data for order 3000, week 10
2024-12-09 11:24:25,810 - __main__ - DEBUG - Processing story data for order 2000, week 20
2024-12-09 11:24:25,828 - __main__ - INFO - Story data processing complete, saved to /app/output/output_story.xlsx
2024-12-09 11:24:25,828 - __main__ - INFO - Starting audio generation
2024-12-09 11:24:25,842 - __main__ - DEBUG - Generating audio for order 3000, week 10
2024-12-09 11:24:25,843 - __main__ - DEBUG - Sending TTS request for order 3000, week 10, role female_1
2024-12-09 11:24:25,845 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-12-09 11:24:25,861 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/11" 307 0
2024-12-09 11:24:26,897 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/11" 200 147022
2024-12-09 11:24:26,920 - __main__ - DEBUG - Audio file saved: /app/output/output_audio/week_10/3000/female_1.wav
2024-12-09 11:24:26,920 - __main__ - DEBUG - Sending TTS request for order 3000, week 10, role male_1
2024-12-09 11:24:26,921 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-12-09 11:24:26,935 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/11" 307 0
2024-12-09 11:24:28,526 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/11" 200 256078
2024-12-09 11:24:28,563 - __main__ - DEBUG - Audio file saved: /app/output/output_audio/week_10/3000/male_1.wav
2024-12-09 11:24:28,564 - __main__ - DEBUG - Sending TTS request for order 3000, week 10, role female_2
2024-12-09 11:24:28,566 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-12-09 11:24:28,581 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/11" 307 0
2024-12-09 11:24:30,495 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/11" 200 316494
2024-12-09 11:24:30,538 - __main__ - DEBUG - Audio file saved: /app/output/output_audio/week_10/3000/female_2.wav
2024-12-09 11:24:30,539 - __main__ - DEBUG - Sending TTS request for order 3000, week 10, role male_2
2024-12-09 11:24:30,540 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-12-09 11:24:30,554 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/11" 307 0
2024-12-09 11:24:32,117 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/11" 200 251470
2024-12-09 11:24:32,152 - __main__ - DEBUG - Audio file saved: /app/output/output_audio/week_10/3000/male_2.wav
2024-12-09 11:24:32,153 - __main__ - DEBUG - Generating audio for order 2000, week 20
2024-12-09 11:24:32,154 - __main__ - DEBUG - Sending TTS request for order 2000, week 20, role female_1
2024-12-09 11:24:32,155 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-12-09 11:24:32,178 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/11" 307 0
2024-12-09 11:24:33,208 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/11" 200 155726
2024-12-09 11:24:33,242 - __main__ - DEBUG - Audio file saved: /app/output/output_audio/week_20/2000/female_1.wav
2024-12-09 11:24:33,242 - __main__ - DEBUG - Sending TTS request for order 2000, week 20, role male_1
2024-12-09 11:24:33,244 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-12-09 11:24:33,271 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/11" 307 0
2024-12-09 11:24:34,776 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/11" 200 242766
2024-12-09 11:24:34,847 - __main__ - DEBUG - Audio file saved: /app/output/output_audio/week_20/2000/male_1.wav
2024-12-09 11:24:34,847 - __main__ - DEBUG - Sending TTS request for order 2000, week 20, role female_2
2024-12-09 11:24:34,849 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-12-09 11:24:34,871 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/11" 307 0
2024-12-09 11:24:36,733 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/11" 200 309838
2024-12-09 11:24:36,777 - __main__ - DEBUG - Audio file saved: /app/output/output_audio/week_20/2000/female_2.wav
2024-12-09 11:24:36,777 - __main__ - DEBUG - Sending TTS request for order 2000, week 20, role male_2
2024-12-09 11:24:36,779 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 103.253.20.13:25006
2024-12-09 11:24:36,793 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio HTTP/11" 307 0
2024-12-09 11:24:38,979 - urllib3.connectionpool - DEBUG - http://103.253.20.13:25006 "POST /tts_to_audio/ HTTP/11" 200 372302
2024-12-09 11:24:39,046 - __main__ - DEBUG - Audio file saved: /app/output/output_audio/week_20/2000/male_2.wav
2024-12-09 11:24:39,046 - __main__ - INFO - Audio generation complete
2024-12-09 11:24:39,047 - __main__ - INFO - Processing complete. Final output saved to: /app/output/output_story.xlsx
